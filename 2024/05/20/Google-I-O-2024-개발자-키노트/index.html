<!DOCTYPE html><html lang="ko-KR"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author"><title>Google I/O 2024 개발자 키노트 · TECH BLOG  by Dongyoung Kim   Ph.D.</title><meta name="description" content="1. 서론
제이닌 뱅크스가 16번째 Google I&amp;#x2F;O를 환영하며 시작, 수백만 명의 개발자들에게 Google과 함께 개발하는 것을 선택해줘서 감사 인사를 전달.
Google 생태계는 30억 개의 안드로이드 기기와 20억 개의 크롬 및 크로뮴 기반 브라우저에 "><meta name="keywords"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><!-- Google tag (gtag.js)--><script async src="https://www.googletagmanager.com/gtag/js?id=G-Y36E4JYRDG"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-Y36E4JYRDG');</script><meta name="generator" content="Hexo 7.2.0"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:157px;"><h3 title=""><a href="/">TECH BLOG  by Dongyoung Kim   Ph.D.</a></h3></div></div><ul class="social-links"></ul><div class="footer"><a target="_blank" href="/"></a><div class="by_farbox"><a href="https://dykim.dev/" target="_blank">© Dongyoung Kim, Ph.D. </a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">Home</a></li><li><a href="/about">Curriculum Vitae</a></li><li><a href="/archives">Archive</a></li></div><div class="information"><div class="back_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"> </a></li></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>Google I/O 2024 개발자 키노트</a></h3></div><div class="post-content"><p><strong>1. 서론</strong></p>
<p>제이닌 뱅크스가 16번째 Google I&#x2F;O를 환영하며 시작, 수백만 명의 개발자들에게 Google과 함께 개발하는 것을 선택해줘서 감사 인사를 전달.</p>
<p>Google 생태계는 30억 개의 안드로이드 기기와 20억 개의 크롬 및 크로뮴 기반 브라우저에 도달할 수 있는 잠재력을 제공하며, 개발자는 Firebase, Google Cloud 및 Gemini, Gemma와 같은 생성형 AI 모델을 사용하여 수백만 개의 유용한 앱을 만들었다고 강조.</p>
<p><strong>2. 생성형 AI: 개발 방식 변화</strong></p>
<p>Google은 모든 개발자가 생성형 AI를 사용할 수 있도록 노력하며, 소프트웨어 개발의 기본 원칙을 변화시키고 새로운 개발 방식과 아이디어를 제공한다고 설명.</p>
<p>AI는 코드 작성, 디버깅 및 테스트, 문서 생성 및 코드베이스 이해와 같은 다양한 개발 작업을 지원하여 생산성을 향상시킨다고 강조.</p>
<p>Gemini는 Android Studio, Chrome DevTools, Project IDX, Colab, VSCode, Intellij 및 Firebase에서 사용할 수 있으며, 앱 설정, 성능 데이터, 로그 및 소스 코드와 같은 맥락을 이해하여 더욱 유용하다고 설명.</p>
<p><strong>3. AI API: 개발자를 위한 새로운 가능성</strong></p>
<p>Jaclyn Konzelmann은 Google의 AI 연구 및 인프라 투자를 통해 개발자가 AI 앱을 쉽게 만들 수 있도록 AI API를 제공한다고 강조.</p>
<p>API 통합을 통해 개발자는 사용자를 위한 최상의 제품을 만드는 데 집중할 수 있다고 설명.</p>
<p>Gemini 1.5 Flash가 모든 개발자에게 공개되었으며, Google AI Studio를 통해 200개 이상의 국가 및 지역에서 사용할 수 있다고 발표.</p>
<p>AI 모델 선택뿐만 아니라 아이디어를 구현하기 위한 적절한 기술이 중요하다고 강조하며, Google AI Studio에서 모델 튜닝 및 200만 토큰 컨텍스트 윈도우 활용을 보여주는 데모 진행.</p>
<p><strong>4. 컨텍스트 캐싱: 효율적인 AI 활용</strong></p>
<p>컨텍스트 윈도우가 커지면서 모델과 상호 작용하여 작업을 해결하는 새로운 방법들이 발견되고 있으며, 컨텍스트 캐싱 기능을 통해 컨텍스트를 캐시하고 이후 턴에 활용하여 비용을 절감할 수 있다고 설명.</p>
<p>이 기능은 기존 컨텐츠를 활용하여 새로운 컨텐츠를 생성하는 다양한 애플리케이션에 적용될 수 있다고 강조.</p>
<p><strong>5. Gemini 모델: 다양한 분야에서 혁신</strong></p>
<p>Gemini 모델은 워크플로우를 변환하고 효율성을 높이며 사용자에게 즐거움을 더하는 데 도움이 된다고 소개.</p>
<p>Locofy.ai는 Figma 디자인을 사용하여 코드를 생성하는 데 Gemini 1.5 Pro의 100만 토큰 컨텍스트 윈도우를 활용하여 컨텍스트를 이해하고 의미있는 이름으로 코드를 생성한다고 설명.</p>
<p>Envision은 시각 장애인이 주변 환경을 이해하고 질문할 수 있도록 1.5 Flash의 속도를 활용하여 빠르게 응답을 제공한다고 소개.</p>
<p>Zapier는 Gemini를 사용하여 팟캐스트 편집과 같은 반복적인 작업을 자동화하고, Google Drive에 파일이 업로드되면 자동으로 음성에서 ‘아’ 또는 ‘음’과 같은 발화 오류를 제거하는 워크플로우를 구축했다고 소개.</p>
<p><strong>6. 모바일: AI로 더 강력해진 안드로이드</strong></p>
<p>Matthew McCullough는 Gemini 모델이 모든 개발자에게 이익을 주는 방법을 설명한 후, 안드로이드에서 AI가 어떻게 뛰어난 경험을 제공하는지 예시를 보여주었다고 설명.</p>
<p>안드로이드는 AI를 중심으로 재구상되고 있으며, 이를 통해 몇 년 전에는 불가능했던 새로운 앱을 개발할 수 있다고 강조.</p>
<p>Google AI Studio를 통해 Gemini API를 앱에 직접 통합하여 Gemini 모델을 활용할 수 있으며, Google Cloud의 Vertex AI를 통해 Gemini의 기능에 액세스할 수 있다고 소개.</p>
<p>Gemini Nano는 온디바이스 작업에 가장 효율적인 모델이며, 모바일에서 직접 실행되어 저지연 응답과 데이터 프라이버시를 보장한다고 설명.</p>
<p>Gemini Nano는 메시징 앱의 제안 답변과 같은 기능을 구현하는 데 유용하며, 셀룰러 네트워크 연결이 없는 경우에도 AI 모델을 사용할 수 있도록 보장한다고 강조.</p>
<p><strong>7. 개발 생산성 향상: Kotlin Multiplatform 및 Jetpack Compose</strong></p>
<p>Maru Ahues Bouza는 개발자들이 Kotlin을 얼마나 좋아하는지 언급하며, 안드로이드에서 Kotlin Multiplatform에 대한 1등급 툴링 및 라이브러리 지원을 강화한다고 발표.</p>
<p>Kotlin Multiplatform은 여러 플랫폼에서 비즈니스 로직을 공유하여 생산성을 높이는 데 도움이 된다고 설명.</p>
<p>Jetpack Compose는 뛰어난 경험을 구축하는 데 도움이 되며, Google Drive, Threads 및 Soundcloud와 같은 상위 1,000개 앱 중 40%가 Compose를 사용한다고 소개.</p>
<p>Compose는 꾸준히 성능이 향상되고 있으며, R8 및 베이스라인 프로파일과 함께 사용하면 앱 성능을 크게 향상시킬 수 있다고 강조.</p>
<p>새로운 Compose API를 사용하여 적응형 레이아웃을 구축하고, 스타일러스, 마우스 및 키보드 지원을 개선하여 사용자 경험을 향상시켰다고 설명.</p>
<p>Jetpack Glance를 사용하여 모든 화면 크기에 적응하는 위젯을 구축할 수 있으며, Android 15는 위젯 선택기에서 생성된 미리보기를 지원하여 사용자 발견성을 높인다고 강조.</p>
<p><strong>8. 테스트 및 디버깅: 효율적인 개발 환경</strong></p>
<p>Android Device Streaming(베타)을 통해 삼성, 픽셀 및 다른 OEM의 기기 랩을 Firebase에 연결하여 다양한 기기에서 적응형 앱을 검증할 수 있다고 발표.</p>
<p>Compose UI 검사 모드를 통해 적응성 및 접근성 문제를 식별하고 해결할 수 있도록 지원한다고 설명.</p>
<p><strong>9. 웹: AI로 더 강력하고 편리해진 웹 개발</strong></p>
<p>Jon Dahlke는 웹이 AI와 함께 새로운 시대를 맞이하고 있으며, Google은 모든 유형의 고객, 모델 크기, 플랫폼 및 환경에 걸쳐 AI 솔루션을 제공하는 데 유리한 위치에 있다고 설명.</p>
<p>WebGPU와 Web Assembly는 웹에서 온디바이스 AI를 가능하게 하는 핵심 기술이며, Google은 이러한 기술을 개선하여 모델이 빠르고 효율적으로 실행되도록 투자했다고 강조.</p>
<p>Bilibili는 WASM과 MediaPipe의 이미지 인식 기술을 사용하여 스피커 뒤의 텍스트를 이동하여 세션 지속 시간을 30% 향상시키고 클릭률을 19% 높였다고 소개.</p>
<p>Chrome 126부터 Gemini Nano가 Chrome 데스크톱 클라이언트에 내장될 예정이며, ‘도와주세요’와 같은 기능을 통해 사용자가 제품 리뷰, 소셜 미디어 게시물 및 고객 피드백 양식과 같은 단문 콘텐츠를 작성하는 데 도움이 된다고 설명.</p>
<p>Google은 개발자가 프롬프트 엔지니어링, 미세 조정, 용량 및 비용에 대해 걱정할 필요 없이 Chrome의 수십억 명의 사용자에게 강력한 AI 기능을 제공할 수 있도록 노력하고 있으며, 개발자와 함께 웹의 미래를 만들어나가고자 한다고 강조.</p>
<p>Adobe 및 CyberAgent는 웹에서 AI 기능을 사용하여 강력한 경험을 구축하고 있다고 소개.</p>
<p><strong>10. 웹 개발의 혁신: 새로운 API 및 Chrome DevTools</strong></p>
<p>AI 기능은 UI가 얼마나 잘 구축되었는지에 따라 그 가치가 결정되며, Google은 웹에서 앱과 같은 경험을 만들 수 있도록 강력한 새로운 기능을 제공한다고 설명.</p>
<p>새로운 Speculation Rules API는 웹사이트 내에서 페이지를 미리 가져오고 미리 렌더링하여 페이지 로딩 속도를 밀리초 단위로 줄이는 데 도움이 된다고 소개.</p>
<p>NitroPack은 Speculation Rules를 통해 Core Web Vitals 로딩 점수를 75% 개선했다고 소개.</p>
<p>View Transitions API는 단일 페이지 앱에 부드러운 전환을 제공하며, Airbnb는 이 API를 사용하여 목록 편집 사이드바에서 사진 편집 및 편의 시설 추가로 원활하게 이동할 수 있는 경험을 만들었다고 소개.</p>
<p>Chrome Canary 126에서는 View Transitions API를 다중 페이지 앱에서도 사용할 수 있게 되어 앱 아키텍처에 관계없이 부드러운 탐색을 제공한다고 설명.</p>
<p>Chrome DevTools는 AI를 활용하여 개발자가 문제를 더 쉽게 이해하고 해결할 수 있도록 지원하며, 콘솔 인사이트는 현재 미국에서 실험적 기능으로 제공되고 있으며, 곧 더 많은 국가에 출시될 예정이라고 강조.</p>
<p><strong>11. 크로스 플랫폼: 통합 개발 워크스페이스</strong></p>
<p>Erin Kidwell은 Google이 개발자가 AI 지원 앱을 구축하고 안드로이드, 웹 및 모든 플랫폼에서 잘 실행되도록 테스트하고 배포할 수 있도록 지원하는 데 전념하고 있다고 설명.</p>
<p>Google은 여러 제품과 툴을 결합하고 확장성을 확보하여 풀스택 AI 지원 멀티 플랫폼 개발을 위한 통합 개발 워크스페이스인 Project IDX를 개발했다고 소개.</p>
<p>Project IDX는 공개 베타 버전으로 출시되었으며, 개발자는 기존 GitHub 리포지토리를 가져오거나 빈 슬레이트에서 시작할 수 있다고 설명.</p>
<p>Google Maps Platform, DevTools, Lighthouse, Cloud Run과 같은 새로운 통합 기능을 제공하며, Checks Code Compliance를 통해 개발 중에 컴플라이언스 문제를 감지하고 해결할 수 있다고 강조.</p>
<p><strong>12. 플러터 및 Firebase: 강력한 크로스 플랫폼 솔루션</strong></p>
<p>플러터는 앱과 게임을 개발하기 위한 세계에서 가장 인기 있는 오픈 소스 프레임워크이며, 하나의 코드베이스를 통해 네이티브 성능으로 다양한 플랫폼에 앱을 빠르게 배포할 수 있다고 설명.</p>
<p>플러터를 통해 텍스트 생성, 요약 및 채팅과 같은 AI 기능을 모든 플랫폼에 빠르고 쉽게 배포할 수 있다고 강조.</p>
<p>Brickit은 기존 플레이 브릭의 잠재력을 재발견하는 데 도움이 되는 앱이며, Google의 온디바이스 AI 툴을 사용하여 브릭을 인식하고 분류한다고 소개.</p>
<p>Brickit은 iOS 앱으로 시작했지만 플러터로 전환하면서 안드로이드 사용자를 두 배 이상 늘렸으며, 몇 달 만에 글로벌 히트를 기록했다고 설명.</p>
<p>WASM 지원은 플러터 웹 앱에 대한 안정적인 채널인 Flutter 3.22 및 Dart 3.4에서 사용할 수 있으며, WASM으로 컴파일하면 JavaScript로 컴파일한 플러터 웹 앱보다 프레임 시간이 최대 2배까지 향상된다고 설명.</p>
<p><strong>13. Firebase: AI 지원 앱 개발 가속화</strong></p>
<p>David East는 개발자가 Firebase를 사용하여 앱 개발 속도를 높이고 앱을 안정적으로 실행하는 데 의존하고 있다고 설명하며, Firebase가 풀 앱 플랫폼으로 변화되었고 이제 AI 지원 앱 개발을 위한 진화를 거듭하고 있다고 강조.</p>
<p>Firebase Data Connect with Google Cloud SQL(미리보기)을 통해 SQL 데이터베이스를 Firebase에 사용할 수 있게 되었으며, 앱 코드를 줄이고 데이터 구조와 앱 코드를 동기화하여 AI 개발을 위한 기능을 제공한다고 소개.</p>
<p>Firebase App Hosting(미리보기)은 Angular, Next.js와 같은 JavaScript 프레임워크를 사용하는 개발자가 현대 웹 앱을 글로벌 규모로 배포할 수 있도록 지원한다고 설명.</p>
<p>Firebase Genkit는 앱 개발자를 위한 새로운 AI 통합 프레임워크이며, Node.js를 위해 베타 버전으로 제공되고 있으며, 곧 Go 지원이 추가될 예정이라고 발표.</p>
<p><strong>14. AI 모델: 더 큰 유연성과 제어</strong></p>
<p>Sharbani Roy는 개발자가 직면한 가장 어려운 문제에 대해 질문하며, Google의 오픈 모델에 대해 이야기하고 기본 프레임워크와 툴을 소개했다고 설명.</p>
<p>Google은 Gemini API를 통해 복잡한 모델을 학습하고 유지 관리하는 작업을 처리하여 개발자가 AI 기능 구축에 집중할 수 있도록 지원하며, 더 큰 유연성과 제어가 필요한 경우 Gemma 오픈 모델을 사용할 수 있다고 설명.</p>
<p>Gemma 모델은 Gemini 모델과 동일한 최첨단 인프라 및 툴링을 기반으로 구축되었으며, 지난 달 코드 및 재귀 작업을 더 잘 지원하기 위해 CodeGemma 및 RecurrentGemma를 출시했다고 소개.</p>
<p>Gemma 2는 새로운 아키텍처를 통해 뛰어난 성능을 달성했으며, 단일 TPU v5e에 맞는 크기로 제공된다고 설명.</p>
<p><strong>15. Colab: AI 개발을 위한 강력한 툴</strong></p>
<p>Laurence Moroney는 Google Colab이 개발자와 연구자가 Keras와 같은 소프트웨어가 사전 설치되어 있고 GPU와 TPU가 무료로 제공되는 등 AI 개발 환경을 쉽게 구축할 수 있도록 지원한다고 소개.</p>
<p>Colab에서 Rapids CuDF가 제공되면서 개발자는 PANDAs 코드를 변경하지 않고도 속도를 크게 높일 수 있다고 설명.</p>
<p>Sharbani Roy는 Laurence Moroney와 함께 가족 북클럽을 위한 AI 기반 앱을 구축하는 과정을 시연했으며, 이는 Gemma 모델을 개인화하기 위해 Colab에서 LoRA를 사용하는 방법을 보여주었다고 설명.</p>
<p><strong>16. Google AI Edge: 온디바이스 AI를 위한 솔루션</strong></p>
<p>Google AI Edge는 생성형 AI를 포함한 모든 최상의 모델에 쉽게 액세스할 수 있도록 지원하며, TensorFlow Lite에 대한 지원이 확장되어 개발자가 Pytorch 모델도 온디바이스에서 실행할 수 있게 되었다고 설명.</p>
<p>Laurence Moroney는 MediaPipe를 사용하여 Gemma 모델을 기기에 배포하는 과정을 보여주었으며, Sharbani Roy는 MediaPipe를 사용하여 프롬프트를 개인화하여 더 나은 답변을 얻는 방법을 설명했다고 설명.</p>
<p>Laurence Moroney는 Project Game Face를 소개하며, 사용자가 얼굴 표정으로 장치를 제어할 수 있도록 지원하는 기술이 발전하여 Android에서도 사용할 수 있게 되었다고 설명.</p>
<p><strong>17. AI 에이전트: 개발의 새로운 지평</strong></p>
<p>제이닌 뱅크스는 Sundar Pichai의 기조 연설에서 언급된 AI 에이전트에 대한 구체적인 예시로 데이터 과학 에이전트를 소개했다고 설명.</p>
<p>데이터 과학 에이전트는 Gemini 1.5 Pro를 기반으로 구축되었으며, 사용자가 데이터셋에 대한 질문을 간단한 언어로 할 수 있도록 지원한다고 설명.</p>
<p>데이터 과학 에이전트는 모델이 코드를 완성하는 것을 넘어 전체 계획을 세우고 실행하는 기능을 제공하며, 결과를 바탕으로 Colab 노트북을 생성하여 실시간 협업을 가능하게 한다고 강조.</p>
<p><strong>18. 미래를 위한 약속: Google 개발자 프로그램 및 I&#x2F;O Connect</strong></p>
<p>Google은 개발자가 생성형 AI를 사용하여 대담하고 책임감 있게 개발할 수 있도록 지원하며, Google의 기기, 앱 경험 및 플랫폼 생태계를 통해 누구에게나 어디에서나 도달할 수 있는 기회를 제공한다고 강조.</p>
<p>Google은 Google 개발자 프로필을 진화시켜 Google 개발자 프로그램을 출시했으며, 프로그램 회원은 Gemini에 대한 액세스 권한, IDX 워크스테이션 확장 및 Google Cloud Skills Boost에서 크레딧을 얻을 수 있다고 설명.</p>
<p>Google은 Google I&#x2F;O Connect 이벤트를 통해 현장 경험을 더 많은 지역으로 확대하여 개발자들과 소통할 예정이며, 6월 27일 베를린을 시작으로 7월 벵갈루루, 8월 베이징에서 개최될 예정이라고 발표.</p>
<p><strong>19. 결론</strong></p>
<p>제이닌 뱅크스는 Google I&#x2F;O에 참여해준 모든 개발자들에게 감사 인사를 전하고, 놀라운 것을 만들어내자는 메시지로 마무리했다고 설명.</p>
<p>Google I&#x2F;O는 키노트뿐만 아니라 세션, 워크샵 및 데모 등 다양한 프로그램을 통해 개발자들에게 새로운 기술과 정보를 제공하는 행사라고 소개.</p>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2024-05-20</span><i class="fa fa-tag"></i><a class="tag" href="/tags/Google-I-O-Developer-Keynote-AI/" title="Google I/O, Developer Keynote, AI">Google I/O, Developer Keynote, AI </a></div></div></div></div><div class="share"><div class="evernote"><a class="fa fa-bookmark" href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank"></a></div><div class="twitter"><a class="fa fa-twitter" target="_blank" rel="noopener" href="http://twitter.com/home?status=,https://dongyoungkim2.github.io/2024/05/20/Google-I-O-2024-개발자-키노트/,TECH BLOG  by Dongyoung Kim   Ph.D.,Google I/O 2024 개발자 키노트,;"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/2024/05/20/README-md/" title="README.md">Previous</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/2024/05/20/Geoffrey-Hinton%E1%84%80%E1%85%AA-Joel-Hellermark%E1%84%8B%E1%85%B4-%E1%84%83%E1%85%A2%E1%84%92%E1%85%AA-%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%E1%84%8B%E1%85%B4-%E1%84%86%E1%85%B5%E1%84%85%E1%85%A2-%E1%84%8B%E1%85%B5%E1%86%AB%E1%84%80%E1%85%A1%E1%86%AB%E1%84%8B%E1%85%B4-%E1%84%83%E1%85%AE%E1%84%82%E1%85%AC-%E1%84%80%E1%85%B3%E1%84%85%E1%85%B5%E1%84%80%E1%85%A9-%E1%84%80%E1%85%B3-%E1%84%82%E1%85%A5%E1%84%86%E1%85%A5/" title="Geoffrey Hinton과 Joel Hellermark의 대화: 딥러닝의 미래, 인간의 두뇌, 그리고 그 너머">Next</a></li></ul></div></div></div></div></div><script src="/js/jquery.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script></body></html>