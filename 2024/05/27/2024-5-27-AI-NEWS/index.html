<!DOCTYPE html><html lang="ko-KR"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author"><title>2024ë…„ 5ì›” 27ì¼ AI ì†Œì‹ Â· TECH BLOG  by Dongyoung Kim   Ph.D.</title><meta name="description" content="Summaryì˜¤ëŠ˜ì˜ ì†Œì‹ì—ì„œëŠ” GPT-4â€™oâ€™ ëª¨ë¸ì˜ ì‘ë™ ì›ë¦¬ì™€ ìœ ì‚¬í•œ AIë¥¼ ë§Œë“œëŠ” ë°©ë²•ì— ëŒ€í•´ ë‹¤ë£¹ë‹ˆë‹¤. ë˜í•œ OpenGPT-4o ëª¨ë¸ì˜ ê°œë°œ ê³¼ì •ê³¼ Falcon 2-11B ëª¨ë¸ì— ëŒ€í•œ ë‚´ìš©ì„ í¬í•¨í•©ë‹ˆë‹¤.
Decoding GPT-4â€™oâ€™: In-Depth Expl"><meta name="keywords"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><!-- Google tag (gtag.js)--><script async src="https://www.googletagmanager.com/gtag/js?id=G-Y36E4JYRDG"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-Y36E4JYRDG');</script><meta name="generator" content="Hexo 7.2.0"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:157px;"><h3 title=""><a href="/">TECH BLOG  by Dongyoung Kim   Ph.D.</a></h3></div></div><ul class="social-links"></ul><div class="footer"><a target="_blank" href="/"></a><div class="by_farbox"><a href="https://dykim.dev/" target="_blank">Â© Dongyoung Kim, Ph.D. </a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">Home</a></li><li><a href="/about">Curriculum Vitae</a></li><li><a href="/archives">Archive</a></li></div><div class="information"><div class="back_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"> </a></li></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>2024ë…„ 5ì›” 27ì¼ AI ì†Œì‹</a></h3></div><div class="post-content"><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>ì˜¤ëŠ˜ì˜ ì†Œì‹ì—ì„œëŠ” GPT-4â€™oâ€™ ëª¨ë¸ì˜ ì‘ë™ ì›ë¦¬ì™€ ìœ ì‚¬í•œ AIë¥¼ ë§Œë“œëŠ” ë°©ë²•ì— ëŒ€í•´ ë‹¤ë£¹ë‹ˆë‹¤. ë˜í•œ OpenGPT-4o ëª¨ë¸ì˜ ê°œë°œ ê³¼ì •ê³¼ Falcon 2-11B ëª¨ë¸ì— ëŒ€í•œ ë‚´ìš©ì„ í¬í•¨í•©ë‹ˆë‹¤.</p>
<h2 id="Decoding-GPT-4â€™oâ€™-In-Depth-Exploration-of-Its-Mechanisms-and-Creating-Similar-AI"><a href="#Decoding-GPT-4â€™oâ€™-In-Depth-Exploration-of-Its-Mechanisms-and-Creating-Similar-AI" class="headerlink" title="Decoding GPT-4â€™oâ€™: In-Depth Exploration of Its Mechanisms and Creating Similar AI"></a>Decoding GPT-4â€™oâ€™: In-Depth Exploration of Its Mechanisms and Creating Similar AI</h2><p><a target="_blank" rel="noopener" href="https://huggingface.co/blog/KingNish/decoding-gpt-4o">Decoding GPT-4â€™oâ€™</a></p>
<ul>
<li><strong>ë‚ ì§œ</strong>: 2024ë…„ 5ì›” 21ì¼</li>
<li><strong>ì‘ì„±ì</strong>: KingNish (Nishith Jain)</li>
<li><strong>ë‚´ìš© ìš”ì•½</strong>:<ul>
<li>GPT-4â€™oâ€™ëŠ” ì—¬ëŸ¬ ëª¨ë¸ì„ í˜¼í•©í•œ í˜ì‹ ì ì¸ AI ëª¨ë¸ë¡œ, ë¹„ë””ì˜¤ ì±„íŒ…, ê°ì • í‘œí˜„ì´ ê°€ëŠ¥í•œ ìŒì„± ì±„íŒ…, í…ìŠ¤íŠ¸ ë° ì´ë¯¸ì§€ ìƒì„±, ë¬¸ì„œ ë° ë¹„ë””ì˜¤ QnA, ì´ë¯¸ì§€ì—ì„œ 3D ìƒì„± ë“±ì˜ ê¸°ëŠ¥ì„ í•˜ë‚˜ì˜ ëª¨ë“ˆì— í†µí•©í•œ ëª¨ë¸ì…ë‹ˆë‹¤.</li>
<li><strong>SuperChat</strong>: í…ìŠ¤íŠ¸ ìƒì„±, ì´ë¯¸ì§€ ìƒì„±, ì´ë¯¸ì§€ ë° ë¬¸ì„œ ë¶„ë¥˜, ë¹„ë””ì˜¤ ë¶„ë¥˜ ë“±ì„ ê²°í•©í•œ ëª¨ë¸ì…ë‹ˆë‹¤.</li>
<li><strong>Voice Chat</strong>: ì‹¤ì‹œê°„ìœ¼ë¡œ ê°ì •ì„ ë¶„ì„í•˜ê³  ìŒì„±ìœ¼ë¡œ ì‘ë‹µí•˜ëŠ” TTSì™€ STTë¥¼ ê²°í•©í•œ ëª¨ë“ˆì…ë‹ˆë‹¤.</li>
<li><strong>Video Chat</strong>: ì‚¬ìš©ìê°€ ëŒ€í™” ì‹œì‘ ì‹œ ì´ë¯¸ì§€ë¥¼ ìº¡ì²˜í•˜ê³  ì¶”ê°€ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ì—¬ ì‚¬ìš©ì ì§ˆì˜ì— ì‘ë‹µí•˜ëŠ” ì œë¡œ ìƒ· ì´ë¯¸ì§€ ë¶„ë¥˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.</li>
<li><strong>AI ëª¨ë¸ ì œì‘ ë°©ë²•</strong>:<ul>
<li><strong>MultiModalification Method</strong>: ê¸°ëŠ¥ì— ë”°ë¼ 2ê°œ ì´ìƒì˜ ëª¨ë¸ì„ ê²°í•©í•˜ì—¬ ë‹¤ê¸°ëŠ¥ ëª¨ë¸ì„ ìƒì„±í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.</li>
<li><strong>Duct Tape Method</strong>: ì¶”ê°€ í›ˆë ¨ ì—†ì´ ë‹¤ì–‘í•œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ ë‹¤ì–‘í•œ ëª¨ë¸ ë˜ëŠ” APIë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.</li>
</ul>
</li>
<li><strong>ì¶”ì²œ ëª¨ë¸</strong>:<ul>
<li>í…ìŠ¤íŠ¸ ìƒì„±: Llama 3 70B</li>
<li>ì´ë¯¸ì§€ ìƒì„±: Pixart Sigma ë˜ëŠ” RealVisXL</li>
<li>ì œë¡œ ìƒ· ì´ë¯¸ì§€ ë¶„ë¥˜: Sigslip</li>
<li>ë¹„ë””ì˜¤ ë¶„ë¥˜: Xclip</li>
<li>3D ìƒì„±: Instant Mesh</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="How-OpenGPT-4o-works"><a href="#How-OpenGPT-4o-works" class="headerlink" title="How OpenGPT 4o works"></a>How OpenGPT 4o works</h2><p><a target="_blank" rel="noopener" href="https://huggingface.co/blog/KingNish/opengpt-4o-working">How OpenGPT 4o works</a></p>
<ul>
<li><strong>ë‚ ì§œ</strong>: 2024ë…„ 5ì›” 21ì¼</li>
<li><strong>ì‘ì„±ì</strong>: KingNish (Nishith Jain)</li>
<li><strong>ë‚´ìš© ìš”ì•½</strong>:<ul>
<li>OpenGPT 4oëŠ” GPT-4â€™oâ€™ì˜ ì˜¤í”ˆ ì†ŒìŠ¤ ëŒ€ì•ˆìœ¼ë¡œ, ë‹¤ì–‘í•œ ëª¨ë¸ê³¼ APIë¥¼ ê²°í•©í•˜ì—¬ ë‹¤ê¸°ëŠ¥ ëª¨ë¸ì„ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤.</li>
<li><strong>Super Chat Module</strong>: ì‚¬ìš©ìì˜ ì…ë ¥ì„ Idefics 2ë¡œ ì²˜ë¦¬í•˜ì—¬ ì§ˆë¬¸ì— ì‘ë‹µí•˜ê³ , ì´ë¯¸ì§€ ìƒì„± ìš”ì²­ ì‹œ Pollination AIë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.</li>
<li><strong>Voice Chat</strong>: JARVIS ì½”ë“œ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¶•ëœ ìŒì„± ë¹„ì„œë¡œ, STT ëª¨ë“ˆì„ í†µí•´ ì‚¬ìš©ì ì§ˆë¬¸ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê³ , Mixtral 8x7B APIë¥¼ í†µí•´ ì‘ë‹µì„ ìƒì„±í•˜ì—¬ TTS ëª¨ë“ˆë¡œ ë³€í™˜í•©ë‹ˆë‹¤.</li>
<li><strong>Live Chat</strong>: uform gen2 dpo ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ ìƒí˜¸ì‘ìš©ì„ ì§€ì›í•©ë‹ˆë‹¤.</li>
<li><strong>í†µí•© ê³¼ì •</strong>: Gradioë¥¼ í†µí•´ ëª¨ë“  ëª¨ë“ˆì„ ì‹¤í–‰í•˜ë©°, GPU ì—†ì´ë„ ìš´ì˜ë©ë‹ˆë‹¤.</li>
</ul>
</li>
</ul>
<h2 id="Falcon-2-11B"><a href="#Falcon-2-11B" class="headerlink" title="Falcon 2-11B"></a>Falcon 2-11B</h2><p><a target="_blank" rel="noopener" href="https://huggingface.co/tiiuae/falcon-11B">Falcon 2-11B</a></p>
<ul>
<li><strong>ëª¨ë¸ ì„¤ëª…</strong>: Falcon2-11BëŠ” 11B íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§„ ì¸ê³¼ ë””ì½”ë” ì „ìš© ëª¨ë¸ë¡œ, RefinedWebê³¼ ì„ ë³„ëœ ë§ë­‰ì¹˜ë¡œ í›ˆë ¨ë˜ì—ˆìŠµë‹ˆë‹¤.</li>
<li><strong>ì§€ì› ì–¸ì–´</strong>: ì˜ì–´, ë…ì¼ì–´, ìŠ¤í˜ì¸ì–´, í”„ë‘ìŠ¤ì–´, ì´íƒˆë¦¬ì•„ì–´, ë„¤ëœë€ë“œì–´, í´ë€ë“œì–´, í¬ë¥´íˆ¬ê°ˆì–´, ë£¨ë§ˆë‹ˆì•„ì–´, ì²´ì½”ì–´ ë“± 11ê°œ ì–¸ì–´ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.</li>
<li><strong>ì£¼ìš” ê¸°ëŠ¥</strong>: í…ìŠ¤íŠ¸ ìƒì„± ë° íšŒí™”ì— ìµœì í™”ëœ ëª¨ë¸ì…ë‹ˆë‹¤.</li>
</ul>
<h2 id="SimPO-Simple-Preference-Optimization-with-a-Reference-Free-Reward"><a href="#SimPO-Simple-Preference-Optimization-with-a-Reference-Free-Reward" class="headerlink" title="SimPO: Simple Preference Optimization with a Reference-Free Reward"></a>SimPO: Simple Preference Optimization with a Reference-Free Reward</h2><p><a target="_blank" rel="noopener" href="https://huggingface.co/papers/2405.14734">SimPO</a></p>
<ul>
<li><strong>ë°œí‘œì¼</strong>: 2024ë…„ 5ì›” 24ì¼</li>
<li><strong>ì €ì</strong>: Yu Meng, Mengzhou Xia, Danqi Chen</li>
<li><strong>ë‚´ìš© ìš”ì•½</strong>:<ul>
<li>SimPOëŠ” Direct Preference Optimization(DPO) ì•Œê³ ë¦¬ì¦˜ì„ ë‹¨ìˆœí™”í•œ ë°©ë²•ìœ¼ë¡œ, ì‹œí€€ìŠ¤ì˜ í‰ê·  ë¡œê·¸ í™•ë¥ ì„ ì•”ë¬µì  ë³´ìƒìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ í›ˆë ¨ ì•ˆì •ì„±ì„ ë†’ì˜€ìŠµë‹ˆë‹¤.</li>
<li>Bradley-Terry ëª©í‘œì— íƒ€ê²Ÿ ë³´ìƒ ë§ˆì§„ì„ ë„ì…í•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.</li>
<li>Llama3-8B-Instruct ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ SimPOëŠ” AlpacaEval 2 ë° Arena-Hard ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.</li>
</ul>
</li>
</ul>
<p>ìœ„ ë§í¬ë¥¼ í†µí•´ ê° ê¸°ì‚¬ì— ëŒ€í•œ ë” ìì„¸í•œ ë‚´ìš©ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
<details>
  <summary>Sources</summary>
  This GPT assists users by creating a detailed daily newspaper in Korean based on provided links. It follows these steps: read the content, summarize each content with detailed points, and write a report. The report format is: # AI News for (today's date), ## Summary (overall short summary), ## Link1 Title, link, date - detailed summary1, - detailed summary2, - detailed summary..N, ## Link2 Title, link, date - detailed summary1, - detailed summary2, - detailed point..N, etc. The report should be written in Korean and use the ê°œì¡°ì‹ ë¬¸ì²´ style. give the very deep details for each link as much as possible.

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br></pre></td><td class="code"><pre><span class="line">###</span><br><span class="line">https://huggingface.co/blog/KingNish/decoding-gpt-4o</span><br><span class="line">Decoding GPT-4&#x27;o&#x27;: In-Depth Exploration of Its Mechanisms and Creating Similar AI.</span><br><span class="line">Community Article</span><br><span class="line">Published May 21, 2024</span><br><span class="line">Nishith Jain&#x27;s avatar</span><br><span class="line">KingNish</span><br><span class="line">Nishith Jain</span><br><span class="line">OpenAI has launched the groundbreaking AI GPT-4&#x27;o&#x27;, a model that is a mixture of many models. In this blog post, we will discuss how GPT-4&#x27;o&#x27; works and how to create this kind of model.</span><br><span class="line">0. GPT 4&#x27;o&#x27; Capabilities</span><br><span class="line">Video Chat. (First time introduced feature)</span><br><span class="line">Faster and Human Like Voice Chat. (It even shows emotions and change tones.)</span><br><span class="line">Text Generation, Image Generation, Image QnA, Document QnA, Video QnA ,Sequential Image Generation, Image to 3d and best thing is All these things are Packed in 1 Modal.</span><br><span class="line">Supports 50+ languages.</span><br><span class="line">See Examples in OpenAI Post</span><br><span class="line"></span><br><span class="line">1. How GPT 4&#x27;o&#x27; works.</span><br><span class="line">Firstly GPT 4o working is mainly Divided into 3 parts.</span><br><span class="line"></span><br><span class="line">1. SuperChat</span><br><span class="line">As, GPT 4 already achieved Sequential image generation and image QnA. They have to just add doc QnA ,Video QnA and 3d generation. For, tech Giant like OpenAI it is just a piece of cake for them. This can be possible with methods we discuss at end.</span><br><span class="line"></span><br><span class="line">2. Voice Chat</span><br><span class="line">OpenAI has integrated TTS (Text-to-Speech) and STT (Speech-to-Text) into a single module, removing the text generation component they previously used. This means that when you speak, the AI analyzes your tone and words to create response in audio in real-time, similar to how streaming is used in text generation. In my opinion, OpenAi made this model comparatively less powerful because it is primarily designed for human interaction, and thus, the AI is trained accordingly.</span><br><span class="line"></span><br><span class="line">3. Video Chat</span><br><span class="line">Video chat is not actually a live video interaction. The AI captures an image at the start of the conversation and takes additional images as needed or instructed. It then employs Zero Shot Image Classification to respond to user queries. This module utilizes a more powerful model than voice chat because the AI can address a wider range of requests when it has visual information. For example, it can identify people, places, solve complex mathematical problems, detect coding errors, and much more which means it can do many things as compared to simple voice chat.</span><br><span class="line"></span><br><span class="line">Image depicting what people thinks of how OpenGPT-4 works vs Reality.</span><br><span class="line"></span><br><span class="line">What you thinkimage/png</span><br><span class="line"></span><br><span class="line">How it actually worksimage/png</span><br><span class="line"></span><br><span class="line">2. Creating AI Like GPT 4o</span><br><span class="line">We, also make 3 models like OpenAI but before these There are two methods for creating every model. First, it&#x27;s important to understand them.</span><br><span class="line"></span><br><span class="line">1. MultiModalification or Mixture of Modal Method</span><br><span class="line">This method combines 2 or more modals according to their functionality to create a new, powerful, multifunctional model, It aso requires further training.</span><br><span class="line"></span><br><span class="line">2. Duct Tape Method</span><br><span class="line">In this method You just need to use different types of Modals or API for doing Different task without ANY TRAINING.</span><br><span class="line"></span><br><span class="line">Making of SuperChat Model</span><br><span class="line">MultiModalification or Mixture of Modal Method To create SuperChat model we need to combine Text Generation, Image Generation, Image Classification, Document Classification, Video Classification models. Use the same process used in Idefics 2. A model that combines zero-shot image classification and text generation modal, Idefics 2 can chat with you and answer questions based on images.</span><br><span class="line"></span><br><span class="line">Duct Tape Method Method without API - It include One base Modal which PROMPTED to identify which type of task is that and then send users prompt to that specific type of modal then send output to user. Optional: Use text gen modal at end to add some words, to make answer more realistic. Method with API - One base model prompted to use API on specific type of query. This method is utilized by Copilot. For instance, when it&#x27;s requested to create images, compose songs, conduct web searches, or answer questions from images, it uses an API of that task to accomplish that task.</span><br><span class="line"></span><br><span class="line">Recommended models from which you can create SuperChat Modal as powerful as GPT 4o</span><br><span class="line"></span><br><span class="line">Base Modal - Llama 3 70B</span><br><span class="line">Image Generation: Pixart Sigma or RealVisXL</span><br><span class="line">Zero Shot Image Classification: Sigslip</span><br><span class="line">Zero Shot Video Classification: Xclip</span><br><span class="line">Sequential Image Gen - Control SDxl</span><br><span class="line">Zero Shot Doc Classification - idf</span><br><span class="line">3d gen - Instant Mesh</span><br><span class="line">Other Models - Animate Diff lightning</span><br><span class="line">Making of VoiceChat Model</span><br><span class="line">MultiModalification or Mixture of Modal Method To develop a human-like speaking AI that also exhibits emotions, high-quality training data is essential. Additionally, an emotion identification model is necessary to recognize users&#x27; emotions and Text gen model who understands users emotion.</span><br><span class="line"></span><br><span class="line">Duct Tape Method It include One stt Modal to encode users prompt with emotion to text gen modal with emotion encoded in answer and utilizing a TTS such as Parler TTS Expresso can further infuse emotion into the output.</span><br><span class="line"></span><br><span class="line">Suggested Models</span><br><span class="line"></span><br><span class="line">Speech to Text - Whisper</span><br><span class="line">ChatModal - Llama3 8b</span><br><span class="line">Text to Speech - Parler tts Expresso</span><br><span class="line">Emotion identifier - Speech Emotion Recognition</span><br><span class="line">Making of VideoChat Model</span><br><span class="line">As previously mentioned, it only captures images. Thus, a zero-shot image classification model is necessary, while the rest remains the same as the voice chat model. However, it also requires a highly intelligent model, due to the increased use case with vision.</span><br><span class="line"></span><br><span class="line">Suggested Models</span><br><span class="line"></span><br><span class="line">ZeroShot Image Classification : Sigslip</span><br><span class="line">Speech to Text - Whisper</span><br><span class="line">ChatModal - Llama3 8b</span><br><span class="line">Text to Speech - Parler tts Expresso</span><br><span class="line">Optional - Speech Emotion Recognition</span><br><span class="line">Alternatively</span><br><span class="line"></span><br><span class="line">Image QnA Model - Idefics 2</span><br><span class="line">VoiceChat Model</span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">https://huggingface.co/blog/KingNish/opengpt-4o-working</span><br><span class="line">How OpenGPT 4o works</span><br><span class="line"></span><br><span class="line">How OpenGPT 4o works</span><br><span class="line">Community Article</span><br><span class="line">Published May 21, 2024</span><br><span class="line">Nishith Jain&#x27;s avatar</span><br><span class="line">KingNish</span><br><span class="line">Nishith Jain</span><br><span class="line">In the previous blog, we discussed how ChatGPT 4o works. Today, we&#x27;re going to talk about how I developed OpenGPT 4o, an open-source alternative to GPT 4o.</span><br><span class="line">(Suggestion: Read previous blog post as this blog contains interconnected topics. Link - https://huggingface.co/blog/KingNish/decoding-gpt-4o )</span><br><span class="line"></span><br><span class="line">Selecting the Method</span><br><span class="line">There are 2 methods to Creating AI like GPT 4o.</span><br><span class="line"></span><br><span class="line">1. MultiModalification or Mixture of Modal Method</span><br><span class="line">This method combines 2 or more modals according to their functionality to create a new, powerful, multifunctional model, It also requires further training.</span><br><span class="line"></span><br><span class="line">2. Duct Tape Method</span><br><span class="line">In this method You just need to use different types of Modals or API for doing Different task without ANY TRAINING.</span><br><span class="line"></span><br><span class="line">Since I don&#x27;t have access to a GPU for training models. So, I&#x27;ve choosed the Duct Tape Method.</span><br><span class="line"></span><br><span class="line">Next Step is to select the model/API based on their performance, speed and easy implementation.</span><br><span class="line"></span><br><span class="line">Models and API used are:</span><br><span class="line">Work	Model/API	Reason</span><br><span class="line">Super Chat Model	Idefics 2	Already made, eliminating the need to build from scratch.</span><br><span class="line">Image Generation Model	Pollination AI (API)	Implementation is fast and straightforward.</span><br><span class="line">Speech to Text	Nemo (API)	Already utilized in another project (JARVIS).</span><br><span class="line">Voice Chat (Base Model)	Mixtral 8x7b (Inference API)	Offers superior speed and power compared to GPT 3.5 Turbo.</span><br><span class="line">Text to Speech	Edge tts (API)	Provides exceptionally fast text-to-speech conversion.</span><br><span class="line">Live Chat (base model)	uform gen2 dpo	Its small size and rapid performance.</span><br><span class="line">As, discussed in Prev Blog ChatGPT working is divide into 3 modules. So, Now discuss each module.</span><br><span class="line"></span><br><span class="line">Super Chat Module</span><br><span class="line">Let&#x27;s Understand working with Visuals:image/png</span><br><span class="line"></span><br><span class="line">Explaination: When a user provides input, it is processed by Idefics 2, which interprets user prompts and responds to questions. If a user wishes to generate an image, it creates an image link of Pollination AI. The process for creating this link is explained in detail to AI in its system prompt. Once the link is created, Pollination AI begins generating the image, which becomes visible to the user upon completion.</span><br><span class="line"></span><br><span class="line">System Prompt I used</span><br><span class="line">Voice Chat</span><br><span class="line">As, I have already created JARVIS, a voice assistant, so I simply utilize the code from it.</span><br><span class="line"></span><br><span class="line">Here is the visuals demonstrating how the voice chat functions.image/png</span><br><span class="line"></span><br><span class="line">Explanation: When a user asks the AI a question, it is directed to the STT (Speech to Text) module, which converts it into text and sends it to the Mixtral 8x7B API. This API processes the request and generates a response that is sent to the TTS (Text to Speech) module. This module then converts the response into audio and sends it back to the user.</span><br><span class="line"></span><br><span class="line">Live Chat</span><br><span class="line">For real-time interactions, the uform gen2 dpo model powers the live chat feature.</span><br><span class="line"></span><br><span class="line">Illustration depicting the working of video chat features.image/pngExplaination: Initially, the user provides input via both webcam and text simultaneously. Then, the AI answers users query from the picture using &quot;UForm Gen2&quot; and the answer is sent back in text format as the output.</span><br><span class="line"></span><br><span class="line">The Integration Process</span><br><span class="line">Well, All 3 modules are running through Gradio on ZERO GPU.</span><br><span class="line"></span><br><span class="line">Source Code: - https://github.com/KingNishHF/OpenGPT-4o</span><br><span class="line"></span><br><span class="line">Conclusion</span><br><span class="line">The creation of OpenGPT 4o using the duct tape method is a prime example of how diverse AI models can be woven together to create a comprehensive and multifaceted tool. It stands as a beacon of possibility in the realm of AI development, showcasing the power of collaboration between different AI technologies.</span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">https://huggingface.co/tiiuae/falcon-11B</span><br><span class="line">tiiuae</span><br><span class="line">/</span><br><span class="line">falcon-11B</span><br><span class="line"></span><br><span class="line">like</span><br><span class="line">164</span><br><span class="line">Text Generation</span><br><span class="line">Transformers</span><br><span class="line">Safetensors</span><br><span class="line"></span><br><span class="line">tiiuae/falcon-refinedweb</span><br><span class="line">English</span><br><span class="line">German</span><br><span class="line">Spanish</span><br><span class="line">French</span><br><span class="line">Italian</span><br><span class="line">Dutch</span><br><span class="line">Polish</span><br><span class="line">Portuguese</span><br><span class="line">Romanian</span><br><span class="line">Czech</span><br><span class="line">falcon</span><br><span class="line">conversational</span><br><span class="line">custom_code</span><br><span class="line">text-generation-inference</span><br><span class="line">5 papers</span><br><span class="line"></span><br><span class="line">License:</span><br><span class="line">unknown</span><br><span class="line">Model card</span><br><span class="line">Files and versions</span><br><span class="line">Community</span><br><span class="line">7</span><br><span class="line">ğŸš€ Falcon2-11B</span><br><span class="line">Falcon2-11B is an 11B parameters causal decoder-only model built by TII and trained on over 5,000B tokens of RefinedWeb enhanced with curated corpora. The model is made available under the TII Falcon License 2.0, the permissive Apache 2.0-based software license which includes an acceptable use policy that promotes the responsible use of AI.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">https://huggingface.co/papers/2405.14734</span><br><span class="line">SimPO: Simple Preference Optimization with a Reference-Free Reward</span><br><span class="line">SimPO: Simple Preference Optimization with a Reference-Free Reward</span><br><span class="line">Published on May 24</span><br><span class="line">Authors:</span><br><span class="line"></span><br><span class="line">Yu Meng</span><br><span class="line">,</span><br><span class="line">Mengzhou Xia</span><br><span class="line">,</span><br><span class="line">Danqi Chen</span><br><span class="line">Abstract</span><br><span class="line">Direct Preference Optimization (DPO) is a widely used offline preference optimization algorithm that reparameterizes reward functions in reinforcement learning from human feedback (RLHF) to enhance simplicity and training stability. In this work, we propose SimPO, a simpler yet more effective approach. The effectiveness of SimPO is attributed to a key design: using the average log probability of a sequence as the implicit reward. This reward formulation better aligns with model generation and eliminates the need for a reference model, making it more compute and memory efficient. Additionally, we introduce a target reward margin to the Bradley-Terry objective to encourage a larger margin between the winning and losing responses, further enhancing the algorithm&#x27;s performance. We compare SimPO to DPO and its latest variants across various state-of-the-art training setups, including both base and instruction-tuned models like Mistral and Llama3. We evaluated on extensive instruction-following benchmarks, including AlpacaEval 2, MT-Bench, and the recent challenging Arena-Hard benchmark. Our results demonstrate that SimPO consistently and significantly outperforms existing approaches without substantially increasing response length. Specifically, SimPO outperforms DPO by up to 6.4 points on AlpacaEval 2 and by up to 7.5 points on Arena-Hard. Our top-performing model, built on Llama3-8B-Instruct, achieves a remarkable 44.7 length-controlled win rate on AlpacaEval 2 -- surpassing Claude 3 Opus on the leaderboard, and a 33.8 win rate on Arena-Hard -- making it the strongest 8B open-source model.</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

</details>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2024-05-27</span><i class="fa fa-tag"></i><a class="tag" href="/tags/AI-NEWS/" title="AI_NEWS">AI_NEWS </a></div></div></div></div><div class="share"><div class="evernote"><a class="fa fa-bookmark" href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank"></a></div><div class="twitter"><a class="fa fa-twitter" target="_blank" rel="noopener" href="http://twitter.com/home?status=,https://dongyoungkim2.github.io/2024/05/27/2024-5-27-AI-NEWS/,TECH BLOG  by Dongyoung Kim   Ph.D.,2024ë…„ 5ì›” 27ì¼ AI ì†Œì‹,;"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/2024/05/30/2024-5-30-AI-NEWS/" title="2024ë…„ 5ì›” 30ì¼ AI ì†Œì‹">Previous</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/2024/05/26/2024-5-26-AI-NEWS/" title="2024ë…„ 5ì›” 26ì¼ AI ì†Œì‹">Next</a></li></ul></div></div></div></div></div><script src="/js/jquery.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script></body></html>