<!DOCTYPE html><html lang="ko-KR"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author"><title>2024ë…„ 6ì›” 5ì¼ AI ì†Œì‹ Â· TECH BLOG  by Dongyoung Kim   Ph.D.</title><meta name="description" content="Summaryì˜¤ëŠ˜ì˜ ì†Œì‹ì—ì„œëŠ” ì¸ê³µì§€ëŠ¥ ëª¨ë¸ GLM-4-9Bì˜ ì„±ëŠ¥ê³¼ ë‹¤ì–¸ì–´ ì§€ì›, íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ì•Œê³ ë¦¬ì¦˜ì  ì¶”ë¡  ëŠ¥ë ¥, í•œêµ­ì–´ RAG í‰ê°€ ë°ì´í„°ì…‹, ì¸í…”ì˜ ì œì˜¨6 í”„ë¡œì„¸ì„œ ì¶œì‹œ, ì—”ë¹„ë””ì•„ì˜ ì°¨ì„¸ëŒ€ AI ì „ìš©ì¹©, AMDì˜ ìƒˆë¡œìš´ ë¼ì´ì   AI 300 ì¹©, LLMì˜ ì‹ ë¢°ë„"><meta name="keywords"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><!-- Google tag (gtag.js)--><script async src="https://www.googletagmanager.com/gtag/js?id=G-Y36E4JYRDG"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-Y36E4JYRDG');</script><meta name="generator" content="Hexo 7.2.0"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:157px;"><h3 title=""><a href="/">TECH BLOG  by Dongyoung Kim   Ph.D.</a></h3></div></div><ul class="social-links"></ul><div class="footer"><a target="_blank" href="/"></a><div class="by_farbox"><a href="https://dykim.dev/" target="_blank">Â© Dongyoung Kim, Ph.D. </a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">Home</a></li><li><a href="/about">Curriculum Vitae</a></li><li><a href="/archives">Archive</a></li></div><div class="information"><div class="back_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"> </a></li></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>2024ë…„ 6ì›” 5ì¼ AI ì†Œì‹</a></h3></div><div class="post-content"><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>ì˜¤ëŠ˜ì˜ ì†Œì‹ì—ì„œëŠ” ì¸ê³µì§€ëŠ¥ ëª¨ë¸ GLM-4-9Bì˜ ì„±ëŠ¥ê³¼ ë‹¤ì–¸ì–´ ì§€ì›, íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ì•Œê³ ë¦¬ì¦˜ì  ì¶”ë¡  ëŠ¥ë ¥, í•œêµ­ì–´ RAG í‰ê°€ ë°ì´í„°ì…‹, ì¸í…”ì˜ ì œì˜¨6 í”„ë¡œì„¸ì„œ ì¶œì‹œ, ì—”ë¹„ë””ì•„ì˜ ì°¨ì„¸ëŒ€ AI ì „ìš©ì¹©, AMDì˜ ìƒˆë¡œìš´ ë¼ì´ì   AI 300 ì¹©, LLMì˜ ì‹ ë¢°ë„ í‘œí˜„ ê°œì„  ì—°êµ¬, ê·¸ë¦¬ê³  Skywork-MoE ëª¨ë¸ì˜ ìµœì‹  ì—…ë°ì´íŠ¸ì— ëŒ€í•´ ë‹¤ë£¹ë‹ˆë‹¤.</p>
<h2 id="GLM-4-9B-ëª¨ë¸-ì†Œê°œ"><a href="#GLM-4-9B-ëª¨ë¸-ì†Œê°œ" class="headerlink" title="GLM-4-9B ëª¨ë¸ ì†Œê°œ"></a>GLM-4-9B ëª¨ë¸ ì†Œê°œ</h2><p><a target="_blank" rel="noopener" href="https://github.com/THUDM/GLM-4">ë§í¬</a><br>2024-06-04, Zhipu AI</p>
<ul>
<li>GLM-4-9BëŠ” Zhipu AIì—ì„œ ì¶œì‹œí•œ ìµœì‹  í”„ë¦¬íŠ¸ë ˆì¸ ëª¨ë¸ ì‹œë¦¬ì¦ˆì˜ ì˜¤í”ˆì†ŒìŠ¤ ë²„ì „.</li>
<li>ì˜ë¯¸, ìˆ˜í•™, ì¶”ë¡ , ì½”ë“œ ë° ì§€ì‹ ë°ì´í„°ì…‹ í‰ê°€ì—ì„œ Llama-3-8Bë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì„.</li>
<li>GLM-4-9B-Chat ë²„ì „ì€ ì›¹ ë¸Œë¼ìš°ì§•, ì½”ë“œ ì‹¤í–‰, ë§ì¶¤í˜• ë„êµ¬ í˜¸ì¶œ, ê¸´ í…ìŠ¤íŠ¸ ì¶”ë¡  ë“±ì˜ ê³ ê¸‰ ê¸°ëŠ¥ì„ í¬í•¨.</li>
<li>26ê°œ ì–¸ì–´ë¥¼ ì§€ì›í•˜ë©°, GLM-4V-9BëŠ” ë‹¤ì´ì–¼ë¡œê·¸ ëŠ¥ë ¥ì„ ê°–ì¶˜ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸.</li>
<li>GLM-4V-9BëŠ” GPT-4-turbo-2024-04-09, Gemini 1.0 Pro, Qwen-VL-Max, Claude 3 Opusë³´ë‹¤ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ì…ì¦.</li>
</ul>
<h2 id="Understanding-Transformer-Reasoning-Capabilities-via-Graph-Algorithms"><a href="#Understanding-Transformer-Reasoning-Capabilities-via-Graph-Algorithms" class="headerlink" title="Understanding Transformer Reasoning Capabilities via Graph Algorithms"></a>Understanding Transformer Reasoning Capabilities via Graph Algorithms</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.18512">ë§í¬</a><br>2024-05-28, Google Research</p>
<ul>
<li>íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ ì‹ ê²½ë§ì˜ ì•Œê³ ë¦¬ì¦˜ì  ì¶”ë¡  ëŠ¥ë ¥ì— ëŒ€í•œ ì´ë¡ ì  ì´í•´ë¥¼ ì¡°ì‚¬.</li>
<li>ë„¤íŠ¸ì›Œí¬ ê¹Šì´, í­, ì¶”ê°€ í† í° ìˆ˜ì— ë”°ë¥¸ ì•Œê³ ë¦¬ì¦˜ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ ë¶„ì„.</li>
<li>ê·¸ë˜í”„ ì—°ê²°ì„± ê°™ì€ ê³¼ì œì— ëŒ€í•´ ë¡œê·¸ ê¹Šì´ê°€ í•„ìš”í•˜ë©°, ì‘ì€ ì„ë² ë”© ì°¨ì›ì˜ ë‹¨ì¼ ë ˆì´ì–´ íŠ¸ëœìŠ¤í¬ë¨¸ê°€ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì‘ì—…ì„ í•´ê²° ê°€ëŠ¥.</li>
<li>GraphQA ë²¤ì¹˜ë§ˆí¬ë¥¼ ì‚¬ìš©í•œ ì‹¤ì¦ì  ì¦ê±° ì œì‹œ.</li>
</ul>
<h2 id="Allganize-RAG-ë¦¬ë”ë³´ë“œ"><a href="#Allganize-RAG-ë¦¬ë”ë³´ë“œ" class="headerlink" title="Allganize RAG ë¦¬ë”ë³´ë“œ"></a>Allganize RAG ë¦¬ë”ë³´ë“œ</h2><p><a target="_blank" rel="noopener" href="https://huggingface.co/datasets/allganize/RAG-Evaluation-Dataset-KO">ë§í¬</a><br>2024-06-04, Allganize</p>
<ul>
<li>5ê°œ ë„ë©”ì¸(ê¸ˆìœµ, ê³µê³µ, ì˜ë£Œ, ë²•ë¥ , ì»¤ë¨¸ìŠ¤)ì— ëŒ€í•œ í•œêµ­ì–´ RAG ì„±ëŠ¥ í‰ê°€.</li>
<li>ê¸°ì¡´ RAGëŠ” í…Œì´ë¸”ê³¼ ì´ë¯¸ì§€ì— ëŒ€í•œ ì§ˆë¬¸ ë‹µë³€ì— ì·¨ì•½.</li>
<li>AllganizeëŠ” RAG í‰ê°€ ë°ì´í„°ë¥¼ ê³µê°œí•˜ì—¬ ë„ë©”ì¸ ë§ì¶¤í˜• ì„±ëŠ¥ í‰ê°€ ê°€ëŠ¥.</li>
<li>ë¬¸ì„œ ì—…ë¡œë“œ í›„ ìì²´ ì§ˆë¬¸ ì‚¬ìš©í•´ ì„±ëŠ¥ ì¸¡ì •.</li>
</ul>
<h2 id="Fine-tune-Embedding-models-for-RAG"><a href="#Fine-tune-Embedding-models-for-RAG" class="headerlink" title="Fine-tune Embedding models for RAG"></a>Fine-tune Embedding models for RAG</h2><p><a target="_blank" rel="noopener" href="https://www.philschmid.de/fine-tune-embedding-model-for-rag">ë§í¬</a><br>2024-06-04, Phil Schmid</p>
<ul>
<li>RAG ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•œ ì„ë² ë”© ëª¨ë¸ ì»¤ìŠ¤í„°ë§ˆì´ì§• ë°©ë²• ì†Œê°œ.</li>
<li>Matryoshka Representation Learningì„ í™œìš©í•˜ì—¬ íš¨ìœ¨ì„± ì¦ëŒ€.</li>
<li>ê¸ˆìœµ RAG ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•œ ì„ë² ë”© ëª¨ë¸ íŒŒì¸íŠœë‹ ê³¼ì • ì„¤ëª….</li>
<li>ìƒˆë¡œìš´ Sentence Transformers 3 ë¦´ë¦¬ìŠ¤ë¡œ ì¸í•´ íŒŒì¸íŠœë‹ì´ ë”ìš± ê°„í¸í•´ì§.</li>
</ul>
<h2 id="ì¸í…”-ì œì˜¨6-â€˜ì‹œì—ë¼-í¬ë ˆìŠ¤íŠ¸â€™-ì¶œì‹œ"><a href="#ì¸í…”-ì œì˜¨6-â€˜ì‹œì—ë¼-í¬ë ˆìŠ¤íŠ¸â€™-ì¶œì‹œ" class="headerlink" title="ì¸í…”, ì œì˜¨6 â€˜ì‹œì—ë¼ í¬ë ˆìŠ¤íŠ¸â€™ ì¶œì‹œ"></a>ì¸í…”, ì œì˜¨6 â€˜ì‹œì—ë¼ í¬ë ˆìŠ¤íŠ¸â€™ ì¶œì‹œ</h2><p><a target="_blank" rel="noopener" href="https://m.ddaily.co.kr/page/view/2024060408520160213">ë§í¬</a><br>2024-06-04, ë””ì§€í„¸ë°ì¼ë¦¬</p>
<ul>
<li>ì¸í…”, íƒ€ì´ë² ì´ì—ì„œ ë°ì´í„°ì„¼í„° ë° AI ìƒíƒœê³„ í˜ì‹  ê¸°ìˆ  ê³µê°œ.</li>
<li>ì œì˜¨ 6 í”„ë¡œì„¸ì„œ, E-ì½”ì–´ ë° P-ì½”ì–´ ëª¨ë¸ ì„¤ê³„ë¡œ ê³ ë°€ë„ ìŠ¤ì¼€ì¼ì•„ì›ƒ ì›Œí¬ë¡œë“œ ì²˜ë¦¬ ê°€ëŠ¥.</li>
<li>ì¸í…” ì œì˜¨ 6 E-ì½”ì–´, ì „ë ¥ ë¹„ìš© ì ˆê°ê³¼ íš¨ìœ¨ì  ì»´í“¨íŒ… ì œê³µ.</li>
<li>DDR5, PCIe 5.0, UPI ë° CXL ê¸°ìˆ  ì§€ì›.</li>
</ul>
<h2 id="ì—”ë¹„ë””ì•„-ì°¨ì„¸ëŒ€-AI-ì „ìš©ì¹©-ê³µê°œ"><a href="#ì—”ë¹„ë””ì•„-ì°¨ì„¸ëŒ€-AI-ì „ìš©ì¹©-ê³µê°œ" class="headerlink" title="ì—”ë¹„ë””ì•„ ì°¨ì„¸ëŒ€ AI ì „ìš©ì¹© ê³µê°œ"></a>ì—”ë¹„ë””ì•„ ì°¨ì„¸ëŒ€ AI ì „ìš©ì¹© ê³µê°œ</h2><p><a target="_blank" rel="noopener" href="https://n.news.naver.com/article/050/0000075863?cds=news_edit">ë§í¬</a><br>2024-06-04, ê¹€ì •ìš° ê¸°ì</p>
<ul>
<li>ë±…í¬ì˜¤ë¸Œì•„ë©”ë¦¬ì¹´, ì—”ë¹„ë””ì•„ ëª©í‘œê°€ 1500ë‹¬ëŸ¬ë¡œ ìƒí–¥.</li>
<li>ì—”ë¹„ë””ì•„ì˜ ì°¨ì°¨ì„¸ëŒ€ AI ì „ìš©ì¹© ë°œí‘œë¡œ ì‹œì¥ ì§€ë°°ë ¥ ê°•í™” ì˜ˆìƒ.</li>
<li>ì—”ë¹„ë””ì•„ ì£¼ê°€ 1154ë‹¬ëŸ¬ë¡œ ìµœê³ ì¹˜ ê²½ì‹ .</li>
</ul>
<h2 id="NVIDIA-Collaborates-with-Hugging-Face-to-Simplify-Generative-AI-Model-Deployments"><a href="#NVIDIA-Collaborates-with-Hugging-Face-to-Simplify-Generative-AI-Model-Deployments" class="headerlink" title="NVIDIA Collaborates with Hugging Face to Simplify Generative AI Model Deployments"></a>NVIDIA Collaborates with Hugging Face to Simplify Generative AI Model Deployments</h2><p><a target="_blank" rel="noopener" href="https://developer.nvidia.com/blog/nvidia-collaborates-with-hugging-face-to-simplify-generative-ai-model-deployments/?ncid=so-link-334086&=&linkId=100000264631409/">ë§í¬</a><br>2024-06-03, NVIDIA</p>
<ul>
<li>NVIDIA, Hugging Faceì™€ í˜‘ë ¥í•˜ì—¬ ìƒì„± AI ëª¨ë¸ ë°°í¬ ê°„ì†Œí™”.</li>
<li>NVIDIA NIM, ì €ì§€ì—°, ê³ ì²˜ë¦¬ëŸ‰ AI ì¶”ë¡  ì œê³µ.</li>
<li>Llama 3 8B ë° Llama 3 70B ëª¨ë¸ Hugging Faceì—ì„œ ëª‡ ë²ˆì˜ í´ë¦­ìœ¼ë¡œ ë°°í¬ ê°€ëŠ¥.</li>
</ul>
<h2 id="xAI-ì‹œë¦¬ì¦ˆ-B-í€ë”©ì—ì„œ-60ì–µ-ë‹¬ëŸ¬-ì¡°ë‹¬"><a href="#xAI-ì‹œë¦¬ì¦ˆ-B-í€ë”©ì—ì„œ-60ì–µ-ë‹¬ëŸ¬-ì¡°ë‹¬" class="headerlink" title="xAI, ì‹œë¦¬ì¦ˆ B í€ë”©ì—ì„œ 60ì–µ ë‹¬ëŸ¬ ì¡°ë‹¬"></a>xAI, ì‹œë¦¬ì¦ˆ B í€ë”©ì—ì„œ 60ì–µ ë‹¬ëŸ¬ ì¡°ë‹¬</h2><p>2024-06-04</p>
<ul>
<li>xAI, ì‹œë¦¬ì¦ˆ B í€ë”© ë¼ìš´ë“œì—ì„œ 60ì–µ ë‹¬ëŸ¬ ì¡°ë‹¬, ê¸°ì—…ê°€ì¹˜ 180ì–µ ë‹¬ëŸ¬ë¡œ í‰ê°€.</li>
<li>í€ë”© ìê¸ˆì€ ì²« ì œí’ˆ ì¶œì‹œ, ê³ ê¸‰ ì¸í”„ë¼ êµ¬ì¶•, ì—°êµ¬ ê°œë°œ ê°€ì†í™”ì— ì‚¬ìš©ë  ì˜ˆì •.</li>
<li>OpenAI, Anthropic, ScaleAIì™€ ê²½ìŸ.</li>
</ul>
<h2 id="AMD-ìƒˆë¡œìš´-ë¼ì´ì  -AI-300-ì¹©-ê³µê°œ"><a href="#AMD-ìƒˆë¡œìš´-ë¼ì´ì  -AI-300-ì¹©-ê³µê°œ" class="headerlink" title="AMD, ìƒˆë¡œìš´ ë¼ì´ì   AI 300 ì¹© ê³µê°œ"></a>AMD, ìƒˆë¡œìš´ ë¼ì´ì   AI 300 ì¹© ê³µê°œ</h2><p><a target="_blank" rel="noopener" href="https://www.windowscentral.com/hardware/laptops/amd-ryzen-ai-300-announce">ë§í¬</a><br>2024-06-03, Windows Central</p>
<ul>
<li>AMD, ì»´í“¨í…ìŠ¤ 2024ì—ì„œ ë¼ì´ì   AI 300 ëª¨ë°”ì¼ í”„ë¡œì„¸ì„œ ê³µê°œ.</li>
<li>ìƒˆë¡œìš´ Zen 5 ì•„í‚¤í…ì²˜ ê¸°ë°˜, Copilot+ í˜¸í™˜.</li>
<li>ë¼ì´ì   AI 9 HX 370 ë° ë¼ì´ì   AI 9 365, ê°ê° 50 TOPS ì„±ëŠ¥ ì œê³µ.</li>
<li>Acer, ASUS, HP, Lenovo, MSIì˜ ë‹¤ì–‘í•œ ë…¸íŠ¸ë¶ ëª¨ë¸ì— ì±„íƒë  ì˜ˆì •.</li>
</ul>
<h2 id="SaySelf-Teaching-LLMs-to-Express-Confidence-with-Self-Reflective-Rationales"><a href="#SaySelf-Teaching-LLMs-to-Express-Confidence-with-Self-Reflective-Rationales" class="headerlink" title="SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales"></a>SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.20974v1">ë§í¬</a><br>2024-05-31, Tianyang Xu ì™¸</p>
<ul>
<li>SaySelfëŠ” LLMì´ ì •í™•í•œ ì‹ ë¢°ë„ ì¶”ì •ì¹˜ë¥¼ í‘œí˜„í•˜ë„ë¡ êµìœ¡í•˜ëŠ” í”„ë ˆì„ì›Œí¬.</li>
<li>ê°•í™” í•™ìŠµì„ í†µí•´ ì‹ ë¢°ë„ ì¶”ì •ì¹˜ë¥¼ ë³´ì •, ê³¼ë„í•œ ì‹ ë¢°ë„ íŒ¨ë„í‹° ë¶€ì—¬.</li>
<li>ì‹¤í—˜ ê²°ê³¼, ì‹ ë¢°ë„ ë³´ì • ì˜¤ë¥˜ ê°ì†Œ ë° ì‘ì—… ì„±ëŠ¥ ìœ ì§€.</li>
</ul>
<h2 id="Skywork-MoE-ëª¨ë¸-ì—…ë°ì´íŠ¸"><a href="#Skywork-MoE-ëª¨ë¸-ì—…ë°ì´íŠ¸" class="headerlink" title="Skywork-MoE ëª¨ë¸ ì—…ë°ì´íŠ¸"></a>Skywork-MoE ëª¨ë¸ ì—…ë°ì´íŠ¸</h2><p><a target="_blank" rel="noopener" href="https://github.com/SkyworkAI/Skywork-MoE/tree/main">ë§í¬</a><br>2024-06-03, SkyworkAI</p>
<ul>
<li>Skywork-MoEëŠ” 1460ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ì™€ 22ì–µ ê°œì˜ í™œì„±í™”ëœ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§„ ëª¨ë¸.</li>
<li>ì „ë¬¸ê°€ ë‹¤ë³€í™”ë¥¼ ì´‰ì§„í•˜ëŠ” Gating Logit Normalizationê³¼ ë³´ì¡° ì†ì‹¤ ê³„ìˆ˜ ì¡°ì •ì„ ìœ„í•œ Adaptive Auxiliary Loss Coefficients ë„ì….</li>
<li>Grok-1, DBRX, Mistral 8*22, Deepseek-V2ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë°œíœ˜.</li>
</ul>
<details>
  <summary>Sources</summary>
  This GPT assists users by creating a detailed daily newspaper in Korean based on provided links. It follows these steps: read the content, summarize each content with detailed points, and write a report. The report format is: # AI News for (today's date), ## Summary (overall short summary), ## Link1 Title, link, date - detailed summary1, - detailed summary2, - detailed summary..N, ## Link2 Title, link, date - detailed summary1, - detailed summary2, - detailed point..N, etc. The report should be written in Korean and use the ê°œì¡°ì‹ ë¬¸ì²´ style. give the very deep details for each link as much as possible.
  make summary with good details, note company name next to date if available.

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br></pre></td><td class="code"><pre><span class="line">###</span><br><span class="line">https://github.com/THUDM/GLM-4</span><br><span class="line">GLM-4</span><br><span class="line">ğŸ¤— HF Repo â€¢ ğŸ¤– ModelScope â€¢ ğŸ¦ Twitter â€¢ ğŸ‘‹ Join Slack and WeChat</span><br><span class="line"></span><br><span class="line">ğŸ“Experience and use a larger-scale GLM business model on the Zhipu AI Open Platform</span><br><span class="line"></span><br><span class="line">Model Introduction</span><br><span class="line">GLM-4-9B is the open-source version of the latest generation of pre-trained models in the GLM-4 series launched by Zhipu AI. In the evaluation of data sets in semantics, mathematics, reasoning, code, and knowledge, GLM-4-9B and its human preference-aligned version GLM-4-9B-Chat have shown superior performance beyond Llama-3-8B. In addition to multi-round conversations, GLM-4-9B-Chat also has advanced features such as web browsing, code execution, custom tool calls (Function Call), and long text reasoning (supporting up to 128K context). This generation of models has added multi-language support, supporting 26 languages including Japanese, Korean, and German. We have also launched the GLM-4-9B-Chat-1M model that supports 1M context length (about 2 million Chinese characters) and the multimodal model GLM-4V-9B based on GLM-4-9B. GLM-4V-9B possesses dialogue capabilities in both Chinese and English at a high resolution of 1120*1120. In various multimodal evaluations, including comprehensive abilities in Chinese and English, perception &amp; reasoning, text recognition, and chart understanding, GLM-4V-9B demonstrates superior performance compared to GPT-4-turbo-2024-04-09, Gemini 1.0 Pro, Qwen-VL-Max, and Claude 3 Opus.</span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">https://arxiv.org/abs/2405.18512</span><br><span class="line">google research</span><br><span class="line">[Submitted on 28 May 2024]</span><br><span class="line">Understanding Transformer Reasoning Capabilities via Graph Algorithms</span><br><span class="line">Clayton Sanford, Bahare Fatemi, Ethan Hall, Anton Tsitsulin, Mehran Kazemi, Jonathan Halcrow, Bryan Perozzi, Vahab Mirrokni</span><br><span class="line">Which transformer scaling regimes are able to perfectly solve different classes of algorithmic problems? While tremendous empirical advances have been attained by transformer-based neural networks, a theoretical understanding of their algorithmic reasoning capabilities in realistic parameter regimes is lacking. We investigate this question in terms of the network&#x27;s depth, width, and number of extra tokens for algorithm execution. Our novel representational hierarchy separates 9 algorithmic reasoning problems into classes solvable by transformers in different realistic parameter scaling regimes. We prove that logarithmic depth is necessary and sufficient for tasks like graph connectivity, while single-layer transformers with small embedding dimensions can solve contextual retrieval tasks. We also support our theoretical analysis with ample empirical evidence using the GraphQA benchmark. These results show that transformers excel at many graph reasoning tasks, even outperforming specialized graph neural networks.</span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">https://huggingface.co/datasets/allganize/RAG-Evaluation-Dataset-KO</span><br><span class="line">Allganize RAG Leaderboard</span><br><span class="line">Allganize RAG ë¦¬ë”ë³´ë“œëŠ” 5ê°œ ë„ë©”ì¸(ê¸ˆìœµ, ê³µê³µ, ì˜ë£Œ, ë²•ë¥ , ì»¤ë¨¸ìŠ¤)ì— ëŒ€í•´ì„œ í•œêµ­ì–´ RAGì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.</span><br><span class="line">ì¼ë°˜ì ì¸ RAGëŠ” ê°„ë‹¨í•œ ì§ˆë¬¸ì— ëŒ€í•´ì„œëŠ” ë‹µë³€ì„ ì˜ í•˜ì§€ë§Œ, ë¬¸ì„œì˜ í…Œì´ë¸”ê³¼ ì´ë¯¸ì§€ì— ëŒ€í•œ ì§ˆë¬¸ì€ ë‹µë³€ì„ ì˜ ëª»í•©ë‹ˆë‹¤.</span><br><span class="line"></span><br><span class="line">RAG ë„ì…ì„ ì›í•˜ëŠ” ìˆ˜ë§ì€ ê¸°ì—…ë“¤ì€ ìì‚¬ì— ë§ëŠ” ë„ë©”ì¸, ë¬¸ì„œ íƒ€ì…, ì§ˆë¬¸ í˜•íƒœë¥¼ ë°˜ì˜í•œ í•œêµ­ì–´ RAG ì„±ëŠ¥í‘œë¥¼ ì›í•˜ê³  ìˆìŠµë‹ˆë‹¤.</span><br><span class="line">í‰ê°€ë¥¼ ìœ„í•´ì„œëŠ” ê³µê°œëœ ë¬¸ì„œì™€ ì§ˆë¬¸, ë‹µë³€ ê°™ì€ ë°ì´í„° ì…‹ì´ í•„ìš”í•˜ì§€ë§Œ, ìì²´ êµ¬ì¶•ì€ ì‹œê°„ê³¼ ë¹„ìš©ì´ ë§ì´ ë“œëŠ” ì¼ì…ë‹ˆë‹¤.</span><br><span class="line">ì´ì œ ì˜¬ê±°ë‚˜ì´ì¦ˆëŠ” RAG í‰ê°€ ë°ì´í„°ë¥¼ ëª¨ë‘ ê³µê°œí•©ë‹ˆë‹¤.</span><br><span class="line"></span><br><span class="line">RAGëŠ” Parser, Retrieval, Generation í¬ê²Œ 3ê°€ì§€ íŒŒíŠ¸ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.</span><br><span class="line">í˜„ì¬, ê³µê°œë˜ì–´ ìˆëŠ” RAG ë¦¬ë”ë³´ë“œ ì¤‘, 3ê°€ì§€ íŒŒíŠ¸ë¥¼ ì „ì²´ì ìœ¼ë¡œ í‰ê°€í•˜ëŠ” í•œêµ­ì–´ë¡œ êµ¬ì„±ëœ ë¦¬ë”ë³´ë“œëŠ” ì—†ìŠµë‹ˆë‹¤.</span><br><span class="line"></span><br><span class="line">Allganize RAG ë¦¬ë”ë³´ë“œì—ì„œëŠ” ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê³ , ìì²´ì ìœ¼ë¡œ ë§Œë“  ì§ˆë¬¸ì„ ì‚¬ìš©í•´ ë‹µë³€ì„ ì–»ì—ˆìŠµë‹ˆë‹¤.</span><br><span class="line">ìƒì„±í•œ ë‹µë³€ê³¼ ì •ë‹µ ë‹µë³€ì„ ìë™ ì„±ëŠ¥ í‰ê°€ ë°©ë²•ì„ ì ìš©í•´ ê° RAG ë°©ë²•ë³„ ì„±ëŠ¥ ì¸¡ì •ì„ í–ˆìŠµë‹ˆë‹¤.</span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">https://www.philschmid.de/fine-tune-embedding-model-for-rag</span><br><span class="line">Fine-tune Embedding models for Retrieval Augmented Generation (RAG)</span><br><span class="line">June 4, 2024</span><br><span class="line">11 minute read</span><br><span class="line">View Code</span><br><span class="line">Embedding models are crucial for successful RAG applications, but they&#x27;re often trained on general knowledge, which limits their effectiveness for company or domain specific adoption. Customizing embedding for your domain specific data can significantly boost the retrieval performance of your RAG Application. With the new release of Sentence Transformers 3, it&#x27;s easier than ever to fine-tune embedding models.</span><br><span class="line"></span><br><span class="line">In this blog, we&#x27;ll show you how to fine-tune an embedding model for a financial RAG applications using a synthetic dataset from the 2023_10 NVIDIA SEC Filing. We&#x27;ll also leverage Matryoshka Representation Learning to boost efficiency. In the blog, we are going to:</span><br><span class="line"></span><br><span class="line">Create &amp; Prepare embedding dataset</span><br><span class="line">Create baseline and evaluate pretrained model</span><br><span class="line">Define loss function with Matryoshka Representation</span><br><span class="line">Fine-tune embedding model with SentenceTransformersTrainer</span><br><span class="line">Evaluate fine-tuned model against baseline</span><br><span class="line">ğŸª† Matryoshka Embeddings</span><br><span class="line"></span><br><span class="line">Matryoshka Representation Learning (MRL) is a technique designed to create embeddings that can be truncated to various dimensions without significant loss of performance. This approach frontloads important information into earlier dimensions of the embedding, allowing for efficient storage and processing while maintaining high accuracy in downstream tasks such as retrieval, classification, and clustering.</span><br><span class="line"></span><br><span class="line">For example, a Matryoshka model can preserve ~99.9% of its performance while needing 3x less storage. This is particularly useful for applications where storage and processing resources are limited, such as on-device applications or large-scale retrieval systems.</span><br><span class="line"></span><br><span class="line">Note: This blog was created to run on consumer size GPUs (24GB), e.g. NVIDIA A10G or RTX 4090/3090, but can be easily adapted to run on bigger GPUs.</span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">https://m.ddaily.co.kr/page/view/2024060408520160213</span><br><span class="line">PC/í”„ë¦°íŒ…/ë””ë°”ì´ìŠ¤</span><br><span class="line">ì¸í…”, ì œì˜¨6 â€˜ì‹œì—ë¼ í¬ë ˆìŠ¤íŠ¸â€™ ì „ê²© ì¶œì‹œâ€¦ì „ë ¥íš¨ìœ¨ ìµœëŒ€ [ì»´í“¨í…ìŠ¤ 2024]</span><br><span class="line">ë””ì§€í„¸ë°ì¼ë¦¬ ë°œí–‰ì¼ 2024-06-04 12:00:00</span><br><span class="line">íƒ€ì´ë² ì´(ëŒ€ë§Œ)=ê¹€ë¬¸ê¸° ê¸°ì</span><br><span class="line">íŒ» ê²”ì‹±ì–´ ì¸í…” CEOê°€ ê¸°ì¡´ ëŒ€ë¹„ ì½”ì–´ìˆ˜ê°€ 2ë°° ì¦ê°€í•œ ì¸í…” ì œì˜¨ ì‹œì—ë¼ í¬ë ˆìŠ¤íŠ¸ ì‹¤ë¬¼ì„ ê³µê°œí•œ ëª¨ìŠµ</span><br><span class="line">íŒ» ê²”ì‹±ì–´ ì¸í…” CEOê°€ ê¸°ì¡´ ëŒ€ë¹„ ì½”ì–´ìˆ˜ê°€ 2ë°° ì¦ê°€í•œ ì¸í…” ì œì˜¨ ì‹œì—ë¼ í¬ë ˆìŠ¤íŠ¸ ì‹¤ë¬¼ì„ ê³µê°œí•œ ëª¨ìŠµ</span><br><span class="line">[ë””ì§€í„¸ë°ì¼ë¦¬ ê¹€ë¬¸ê¸° ê¸°ì] ì¸í…”(ëŒ€í‘œ íŒ» ê²”ì‹±ì–´)ì€ 4ì¼(í˜„ì§€ì‹œê°„) ëŒ€ë§Œ íƒ€ì´ë² ì´ì—ì„œ ì§„í–‰ëœ ì»´í“¨í…ìŠ¤ 2024ì—ì„œ ë°ì´í„°ì„¼í„°, í´ë¼ìš°ë“œì™€ ë„¤íŠ¸ì›Œí¬ì—ì„œ ì—ì§€ ë° PCì— ì´ë¥´ê¸°ê¹Œì§€ AI ìƒíƒœê³„ë¥¼ íšê¸°ì ìœ¼ë¡œ ê°€ì†í™”í•  ìµœì²¨ë‹¨ ê¸°ìˆ  ë° ì•„í‚¤í…ì²˜ë¥¼ ê³µê°œí–ˆë‹¤.</span><br><span class="line"></span><br><span class="line">ê²”ì‹±ì–´ CEOì™€ ì—…ê³„ ë¦¬ë”ë“¤ì€ ì¸í…”ì´ AI í˜ì‹ ì„ ì´ëŒê³  ì°¨ì„¸ëŒ€ ê¸°ìˆ ì„ ì˜ˆì •ë³´ë‹¤ ì•ì„œ ì œê³µí•˜ê³  ìˆë‹¤ëŠ” ì ì„ ë¶„ëª…íˆ í–ˆë‹¤. ì¸í…”ì€ ë¶ˆê³¼ 6ê°œì›” ë§Œì— 5ì„¸ëŒ€ ì¸í…” ì œì˜¨(5th Gen Intel Xeon) í”„ë¡œì„¸ì„œë¥¼ ì¶œì‹œí•œë° ì´ì–´ ì œì˜¨ 6 ì²« ì œí’ˆì„ ì„ ë³´ì˜€ìœ¼ë©°, ê°€ìš°ë”” AI ê°€ì†ê¸°ë¥¼ ì„ ê³µê°œí•˜ê³  ê¸°ì—… ê³ ê°ì—ê²Œ ë¹„ìš© íš¨ìœ¨ì ì¸ ê³ ì„±ëŠ¥ ìƒì„±í˜• AI í›ˆë ¨ ë° ì¶”ë¡  ì‹œìŠ¤í…œì„ ì œê³µí–ˆë‹¤.</span><br><span class="line"></span><br><span class="line">ì´ëŸ¬í•œ ë°œì „ì„ í†µí•´ ì¸í…”ì€ ì‹¤í–‰ ì†ë„ë¥¼ ê°€ì†í™”í•˜ëŠ” ë™ì‹œì— í˜ì‹ ê³¼ ìƒì‚° ì†ë„ì˜ í•œê³„ë¥¼ ë„˜ì–´ AIë¥¼ ëŒ€ì¤‘í™”í•˜ê³  ì—…ê³„ë¥¼ í™œì„±í™”í•˜ê³  ìˆë‹¤ ì¸í…” ì œì˜¨ 6 í”„ë¡œì„¸ì„œë¥¼ í†µí•´ ê³ ë°€ë„ ìŠ¤ì¼€ì¼ì•„ì›ƒ ì›Œí¬ë¡œë“œë¥¼ ìœ„í•œ ì„±ëŠ¥ ë° ì „ë ¥ íš¨ìœ¨ì„±ì„ í–¥ìƒì‹œì¼°ë‹¤.</span><br><span class="line"></span><br><span class="line">ë””ì§€í„¸ í˜ì‹ ì´ ê°€ì†í™”ë¨ì— ë”°ë¼ ê¸°ì—…ë“¤ì€ ë…¸í›„í™”ëœ ë°ì´í„°ì„¼í„° ì‹œìŠ¤í…œì„ êµì²´í•´ ë¹„ìš© ì ˆê°, ì§€ì† ê°€ëŠ¥ì„± ëª©í‘œ ë‹¬ì„±, ë¬¼ë¦¬ì  ê³µê°„ ë° ë™ ê³µê°„ í™œìš© ê·¹ëŒ€í™”í•˜ê³  ê¸°ì—… ì „ë°˜ì— ê±¸ì³ ìƒˆë¡œìš´ ë””ì§€í„¸ ì—­ëŸ‰ì„ ì°½ì¶œí•´ì•¼ í•œë‹¤ëŠ” ì••ë°•ì— ì§ë©´í•´ ìˆë‹¤.</span><br><span class="line"></span><br><span class="line">ì´ì— ë”°ë¼ ëª¨ë“  ì œì˜¨ 6 í”Œë«í¼ ë° í”„ë¡œì„¸ì„œ ì œí’ˆêµ°ì€ ì´ëŸ¬í•œ ê³¼ì œë¥¼ í•´ê²°í•  ëª©ì ìœ¼ë¡œ E-ì½”ì–´(Efficient -core) ë° P-ì½”ì–´(Performance-core) ëª¨ë¸ì´ ì„¤ê³„ëë‹¤. AI ë° ê¸°íƒ€ ê³ ì„±ëŠ¥ ì»´í“¨íŒ… ìš”êµ¬ì‚¬í•­ë¶€í„° í™•ì¥ ê°€ëŠ¥í•œ í´ë¼ìš°ë“œ ë„¤ì´í‹°ë¸Œ ì• í”Œë¦¬ì¼€ì´ì…˜ì— ì´ë¥´ê¸°ê¹Œì§€ ê´‘ë²”ìœ„í•œ ì›Œí¬ë¡œë“œ ë° ì‚¬ìš© ì‚¬ë¡€ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤. E-ì½”ì–´ì™€ P-ì½”ì–´ëŠ” ëª¨ë‘ ê³µí†µì˜ ì†Œí”„íŠ¸ì›¨ì–´ ìŠ¤íƒê³¼ í•˜ë“œì›¨ì–´ ë° ì†Œí”„íŠ¸ì›¨ì–´ ê³µê¸‰ì—…ì²´ì˜ ê°œë°©í˜• ìƒíƒœê³„ì™€ í˜¸í™˜ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¶•ëë‹¤.</span><br><span class="line"></span><br><span class="line">ê°€ì¥ ë¨¼ì € ì¶œì‹œë˜ëŠ” ì œì˜¨ 6 í”„ë¡œì„¸ì„œëŠ” ì¸í…” ì œì˜¨ 6 E-ì½”ì–´ ê¸°ë°˜ ì½”ë“œëª… â€˜ì‹œì—ë¼ í¬ë ˆìŠ¤íŠ¸â€™ë‹¤. ë‹¹ì¥ ì‚¬ìš©ì´ ê°€ëŠ¥í•˜ë‹¤.</span><br><span class="line"></span><br><span class="line">ê³ ì§‘ì ë„ ì½”ì–´ ë° ë›°ì–´ë‚œ ì™€íŠ¸ë‹¹ ì„±ëŠ¥ì„ ê°–ì¶˜ ì¸í…” ì œì˜¨ 6 E-ì½”ì–´ëŠ” ì „ë ¥ ë¹„ìš©ì„ í¬ê²Œ ë‚®ì¶”ë©´ì„œ íš¨ìœ¨ì ì¸ ì»´í“¨íŒ…ì„ ì œê³µí•œë‹¤. í–¥ìƒëœ ì„±ëŠ¥ ë° ì „ë ¥ íš¨ìœ¨ì„±ì€ í´ë¼ìš°ë“œ ë„¤ì´í‹°ë¸Œ ì• í”Œë¦¬ì¼€ì´ì…˜ ë° ì½˜í…ì¸  ì „ì†¡ ë„¤íŠ¸ì›Œí¬, ë„¤íŠ¸ì›Œí¬ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤, ì†Œë¹„ì ë””ì§€í„¸ ì„œë¹„ìŠ¤ ë“± ê°€ì¥ ê¹Œë‹¤ë¡œìš´ ê³ ë°€ë„ ìŠ¤ì¼€ì¼ì•„ì›ƒ ì›Œí¬ë¡œë“œì— ì í•©í•˜ë‹¤. ì™€íŠ¸ë‹¹ ìµœëŒ€ 2.7ë°° ë†’ì€ 5G ì‚¬ìš©ì í‰ë©´ ê¸°ëŠ¥(5G-User Plane Function) ì„±ëŠ¥ ë° ì™€íŠ¸ë‹¹ ìµœëŒ€ 3.5ë°° ë†’ì€ ì°¨ì„¸ëŒ€ ë°©í™”ë²½ ì„±ëŠ¥3ì„ ì œê³µí•œë‹¤. ì´ëŠ” ì¸í…” ì´ë”ë„· 800 ì‹œë¦¬ì¦ˆ(Intel Ethernet 800 Series)ë¡œ í…ŒìŠ¤íŠ¸í•œ ê²°ê³¼ë‹¤.</span><br><span class="line"></span><br><span class="line">ë˜í•œ, ì œì˜¨ 6 E-ì½”ì–´ëŠ” ì§‘ì ë„ê°€ ë§¤ìš° ë›°ì–´ë‚˜ ë™ ìˆ˜ì¤€ì„ 3ëŒ€ 1ë¡œ í†µí•©í•  ìˆ˜ ìˆì–´ ë¯¸ë””ì–´ íŠ¸ëœìŠ¤ì½”ë”© ì›Œí¬ë¡œë“œì—ì„œ 2ì„¸ëŒ€ ì¸í…” ì œì˜¨ í”„ë¡œì„¸ì„œ ëŒ€ë¹„ ìµœëŒ€ 4.2ë°°ì˜ ë™ ë ˆë²¨ ì„±ëŠ¥ í–¥ìƒê³¼ ìµœëŒ€ 2.6ë°°ì˜ ì™€íŠ¸ë‹¹ ì„±ëŠ¥ í–¥ìƒì„ ê³ ê°ì—ê²Œ ì œê³µí•  ìˆ˜ ìˆë‹¤. ë” ì ì€ ì „ë ¥ê³¼ ë™ ê³µê°„ì„ ì‚¬ìš©í•˜ëŠ” ì œì˜¨ 6 í”„ë¡œì„¸ì„œëŠ” í˜ì‹ ì ì¸ ìƒˆë¡œìš´ AI í”„ë¡œì íŠ¸ë¥¼ ìœ„í•œ ì»´í“¨íŒ… ìš©ëŸ‰ê³¼ ì¸í”„ë¼ë¥¼ í™•ë³´í•œë‹¤.</span><br><span class="line"></span><br><span class="line">ì¸í…” ì œì˜¨ 6 í”„ë¡œì„¸ì„œëŠ” ë™ì¼í•œ í•˜ë“œì›¨ì–´ í”Œë«í¼ê³¼ ì†Œí”„íŠ¸ì›¨ì–´ ìŠ¤íƒì„ ê³µìœ í•˜ëŠ” 6700 ì‹œë¦¬ì¦ˆ ë° 6900 ì‹œë¦¬ì¦ˆ í”Œë«í¼ìœ¼ë¡œ ì œê³µëœë‹¤. ì´ì™€ ë”ë¶ˆì–´ DDR5, PCIe 5.0, UPI ë° CXL ë“± ê´€ë ¨ ê¸°ìˆ ì˜ ì„¸ëŒ€ë³„ ì„±ëŠ¥ í–¥ìƒì´ í¬í•¨ëœë‹¤</span><br><span class="line"></span><br><span class="line">6700 ì‹œë¦¬ì¦ˆëŠ” P-ì½”ì–´ì˜ MCR DIMMê³¼ í•¨ê»˜ ìµœëŒ€ 1.4ë°° ë” ì»¤ì§„ ë©”ëª¨ë¦¬ ëŒ€ì—­í­ì„ ì œê³µí•´ í•œ ë²ˆì— ë” ë§ì€ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆìœ¼ë©°, 5ì„¸ëŒ€ ì¸í…” ì œì˜¨ í”„ë¡œì„¸ì„œ ëŒ€ë¹„ ìµœëŒ€ 1.1ë°° ì¦ê°€í•œ ì…ì¶œë ¥(I/O) ëŒ€ì—­í­ì„ ì œê³µí•´ ë°ì´í„° ì…ë ¥ ë° ì¶œë ¥ ì‹œìŠ¤í…œì˜ ì†ë„ì™€ íš¨ìœ¨ì„ ë†’ì¸ë‹¤.</span><br><span class="line"></span><br><span class="line">6900 ì‹œë¦¬ì¦ˆëŠ” 5ì„¸ëŒ€ ì¸í…” ì œì˜¨ í”„ë¡œì„¸ì„œ ëŒ€ë¹„ ìµœëŒ€ 1.8ë°° ëŠ˜ì–´ë‚œ ì†Œì¼“ ê°„ ëŒ€ì—­í­ì„ ì œê³µí•œë‹¤. ì´ëŠ” ì‹œìŠ¤í…œ ìƒ ë‹¤ì–‘í•œ ë¶€ë¶„ ê°„ ë” ë¹ ë¥´ê³  íš¨ìœ¨ì ì¸ í†µì‹ ì„ ê°€ëŠ¥í•˜ê²Œ í•´, íŠ¹íˆ ë†’ì€ ì„±ëŠ¥ì„ í•„ìš”ë¡œ í•˜ëŠ” ê¹Œë‹¤ë¡œìš´ ì‘ì—…ì—ì„œ íš¨ê³¼ì ì´ë¼ëŠ” ì„¤ëª…ì´ë‹¤.</span><br><span class="line"></span><br><span class="line">6700 ë° 6900 ì‹œë¦¬ì¦ˆ ëª¨ë‘ CXL 2.0ë¥¼ ì§€ì›í•œë‹¤. ë‘ ì‹œë¦¬ì¦ˆê°€ ì„¸ìš´ ìƒˆ ê¸°ì¤€ì€ ê°€ì†ê¸°, ë©”ëª¨ë¦¬ í™•ì¥ê¸° ë° ê¸°íƒ€ ì¥ì¹˜ì™€ ê°™ì€ ì¶”ê°€ êµ¬ì„± ìš”ì†Œì™€ ì»´í“¨í„° ê°„ ì—°ê²°ê³¼ í†µì‹ ì„ ì§€ì›í•œë‹¤.</span><br><span class="line"></span><br><span class="line">í•œí¸, ì œì˜¨ 6 P-ì½”ì–´ ê¸°ë°˜ ì½”ë“œëª… ê·¸ë˜ë‚˜ì´íŠ¸ ë˜í”¼ì¦ˆëŠ” 4ë¶„ê¸° ì¶œì‹œë  ì˜ˆì •ì´ë‹¤.</span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">https://n.news.naver.com/article/050/0000075863?cds=news_edit</span><br><span class="line">ì²œë¹„ë””ì•„â€™ë„ ì˜›ë§...ì—”ë¹„ë””ì•„ ëª©í‘œê°€ 1500ë‹¬ëŸ¬ë¡œ ìƒí–¥</span><br><span class="line">ì…ë ¥2024.06.04. ì˜¤ì „ 9:19 ê¸°ì‚¬ì›ë¬¸</span><br><span class="line">ê¹€ì •ìš° ê¸°ì</span><br><span class="line">ê¹€ì •ìš° ê¸°ì</span><br><span class="line">  3</span><br><span class="line">8</span><br><span class="line">í…ìŠ¤íŠ¸ ìŒì„± ë³€í™˜ ì„œë¹„ìŠ¤ ì‚¬ìš©í•˜ê¸°</span><br><span class="line">ê¸€ì í¬ê¸° ë³€ê²½í•˜ê¸°</span><br><span class="line">SNS ë³´ë‚´ê¸°</span><br><span class="line">ì¸ì‡„í•˜ê¸°</span><br><span class="line">ì—”ë¹„ë””ì•„, ì°¨ì„¸ëŒ€ ì¸ê³µì§€ëŠ¥(AI) ì „ìš©ì¹© ê³µê°œ</span><br><span class="line">â€œì‹ ì œí’ˆ íš¨ê³¼ë¡œ ì‹œì¥ ì§€ë°°ë ¥ ë”ìš± ê°•í™”â€</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ë¯¸êµ­ì˜ íˆ¬ìì€í–‰ ë±…í¬ì˜¤ë¸Œì•„ë©”ë¦¬ì¹´(BoA)ê°€ ì—”ë¹„ë””ì•„ì˜ ëª©í‘œê°€ë¥¼ 1500ë‹¬ëŸ¬ë¡œ ìƒí–¥í–ˆë‹¤. ì—”ë¹„ë””ì•„ê°€ ì°¨ì„¸ëŒ€ ì¸ê³µì§€ëŠ¥(AI) ì „ìš©ì¹©ì„ ë°œí‘œí•œ ë° ë”°ë¥¸ ê²ƒì´ë‹¤.</span><br><span class="line"></span><br><span class="line">BoAëŠ” 3ì¼(í˜„ì§€ì‹œê°„) ë³´ê³ ì„œë¥¼ ë‚´ê³  ì—”ë¹„ë””ì•„ì˜ ëª©í‘œê°€ë¥¼ ê¸°ì¡´ì˜ 1320ë‹¬ëŸ¬ì—ì„œ 1500ë‹¬ëŸ¬ë¡œ ì¡°ì •í–ˆë‹¤. ì›”ê°€ì˜ íˆ¬ìì€í–‰ ì¤‘ ê°€ì¥ ë†’ì€ ëª©í‘œê°€ë‹¤.</span><br><span class="line"></span><br><span class="line">í˜„ì¬ ì—”ë¹„ë””ì•„ ì£¼ê°€ê°€ ì•½ 1150ë‹¬ëŸ¬ì„ ì¸ ê²ƒì„ ê°ì•ˆí•˜ë©´ í–¥í›„ 30% ë” ìƒìŠ¹í•œë‹¤ëŠ” ì˜ë¯¸ë‹¤.</span><br><span class="line"></span><br><span class="line">BoAëŠ” â€œì—”ë¹„ë””ì•„ê°€ ì°¨ì°¨ì„¸ëŒ€ AI ì „ìš©ì¹© ê³„íšì„ ë°œí‘œ, ì‹œì¥ ì§€ë°°ë ¥ì´ ë”ìš± ê°•í™”ë  ê²ƒâ€ì´ë¼ë©° ëª©í‘œê°€ ìƒí–¥ ì´ìœ ë¥¼ ì„¤ëª…í–ˆë‹¤.</span><br><span class="line"></span><br><span class="line">í•œí¸ ì—”ë¹„ë””ì•„ ì£¼ê°€ëŠ” ì§€ë‚œë‹¬ 30ì¼ 1154ë‹¬ëŸ¬ê¹Œì§€ ì¹˜ì†Ÿì•„ ì‚¬ìƒ ìµœê³ ì¹˜ë¥¼ ê²½ì‹ í•œ ë°” ìˆë‹¤.</span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">https://developer.nvidia.com/blog/nvidia-collaborates-with-hugging-face-to-simplify-generative-ai-model-deployments/?ncid=so-link-334086&amp;=&amp;linkId=100000264631409/</span><br><span class="line">Generative AI</span><br><span class="line">NVIDIA Collaborates with Hugging Face to Simplify Generative AI Model Deployments</span><br><span class="line">Jun 03, 2024</span><br><span class="line">By Jig Bhadaliya, Rohit Taneja and Chintan Patel</span><br><span class="line"></span><br><span class="line">+4</span><br><span class="line">Like</span><br><span class="line"> Discuss (0)</span><br><span class="line"></span><br><span class="line">LTFRE</span><br><span class="line">As generative AI experiences rapid growth, the community has stepped up to foster this expansion in two significant ways: swiftly publishing state-of-the-art foundational models, and streamlining their integration into application development and production.</span><br><span class="line"></span><br><span class="line">NVIDIA is aiding this effort by optimizing foundation models to enhance performance, allowing enterprises to generate tokens faster, reduce the costs of running the models, and improve end user experience with NVIDIA NIM.</span><br><span class="line"></span><br><span class="line">NVIDIA NIM</span><br><span class="line">NVIDIA NIM inference microservices are designed to streamline and accelerate the deployment of generative AI models across NVIDIA accelerated infrastructure anywhere, including cloud, data center, and workstations.</span><br><span class="line"></span><br><span class="line">NIM leverages TensorRT-LLM inference optimization engine, industry-standard APIs, and prebuilt containers to provide low-latency, high-throughput AI inference that scales with demand. It supports a wide range of LLMs including Llama 3, Mixtral 8x22B, Phi-3, and Gemma, as well as optimizations for domain-specific applications in speech, image, video, healthcare, and more.</span><br><span class="line"></span><br><span class="line">NIM delivers superior throughput, enabling enterprises to generate tokens up to 5x faster. For generative AI applications, token processing is the key performance metric, and increased token throughput directly translates to higher revenue for enterprises.</span><br><span class="line"></span><br><span class="line">By simplifying the integration and deployment process, NIM enables enterprises to rapidly move from AI model development to production, enhancing efficiency, reducing operational costs, and allowing businesses to focus on innovation and growth.</span><br><span class="line"></span><br><span class="line">And now, weâ€™re going a step further with Hugging Face to help developers run models in a matter of minutes.</span><br><span class="line"></span><br><span class="line">Deploy NIM on Hugging Face with a few clicks</span><br><span class="line">Hugging Face is a leading platform for AI models and has become the go-to destination for AI developers as it enhances the accessibility of AI models.</span><br><span class="line"></span><br><span class="line">Leverage the power of seamless deployment with NVIDIA NIM, starting with Llama 3 8B and Llama 3 70B, on your preferred cloud service provider, all directly accessible from Hugging Face.</span><br><span class="line"></span><br><span class="line">NIM delivers superior throughput and achieves near-100% utilization with multiple concurrent requests, enabling enterprises to generate text 3x faster. For generative AI applications, token processing is the key performance metric, and increased token throughput directly translates to higher revenue for enterprises.</span><br><span class="line"></span><br><span class="line">The Llama 3 NIM is performance optimized to deliver higher throughput, which translates to higher revenue and lower TCO. The Llama 3 8B NIM processes ~9300 tokens per second compared to the non-NIM version which processes ~2700 tokens per second on HF Endpoints.</span><br><span class="line">Figure 1. Llama 3 8B NIM on Hugging Face achieves 3x throughput</span><br><span class="line">The dedicated NIM endpoint on Hugging Face spins up instances on your preferred cloud, automatically fetches and deploys the NVIDIA optimized model, and enables you to start inference with just a few clicks, all in a matter of minutes.</span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">BREAKING: Elon Muskâ€™s</span><br><span class="line">OpenAI</span><br><span class="line">Rival,</span><br><span class="line">xAI</span><br><span class="line">, Raises $6 Billion At $18 Billion Valuation â€” Funding Secured ğŸ¤¯</span><br><span class="line"></span><br><span class="line">xAI has announced their Series B funding round of $6 billion at a $18 billion pre-money valuation.</span><br><span class="line"></span><br><span class="line">The round includes investors like:</span><br><span class="line">Valor Equity Partners</span><br><span class="line">,</span><br><span class="line">Andreessen Horowitz</span><br><span class="line">&amp;</span><br><span class="line">Sequoia Capital</span><br><span class="line">amongst others.</span><br><span class="line"></span><br><span class="line">What are they going to do with the money?</span><br><span class="line"></span><br><span class="line">â€œThe funds from the round will be used to take xAIâ€™s first products to market, build advanced infrastructure, and accelerate the research and development of future technologies.â€</span><br><span class="line"></span><br><span class="line">For comparison, OpenAI is valued at $86 billion and has 100m active users.</span><br><span class="line"></span><br><span class="line">Other AI competitors</span><br><span class="line">Anthropic</span><br><span class="line">and ScaleAI are valued at $18.4 billion and $13.8 billion respectively.</span><br><span class="line"></span><br><span class="line">Funding secured.</span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">https://www.windowscentral.com/hardware/laptops/amd-ryzen-ai-300-announce</span><br><span class="line">AMD just toppled Snapdragon X NPU dominance with its Ryzen AI 300 chips ready for Copilot+</span><br><span class="line">News</span><br><span class="line">By Cale Hunt published 2 days ago</span><br><span class="line">Zen 5 is here.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> Comments (1)</span><br><span class="line">AMD Ryzen AI 300 press image</span><br><span class="line">A render of AMD&#x27;s Ryzen AI 300 chip (Image credit: AMD)</span><br><span class="line">What you need to know</span><br><span class="line">AMD unveiled new Ryzen AI 300 mobile processors for laptops at Computex 2024.</span><br><span class="line">The new chips are built on AMD&#x27;s new &quot;Zen 5&quot; architecture and are compatible with Copilot+.</span><br><span class="line">The Ryzen AI 9 HX 370 and Ryzen AI 9 365 each have an NPU with 50 TOPS performance for local AI acceleration.</span><br><span class="line">Acer, ASUS, HP, Lenovo, and MSI have stated that the new Ryzen AI chips are coming to AI laptops.</span><br><span class="line">Computex 2024 is underway in Taipei, Taiwan, and AMD was one of the first to unveil a bunch of new hardware at its keynote address. Alongside the new Zen 5 Ryzen 9000 desktop processors (CPU), AMD took the wrapping off of its Ryzen AI 300 chips. These are the long-rumored &quot;Strix Point&quot; APUs complete with Zen 5 CPU cores, RDNA 3.5 graphics, and XDNA 2 Neural Processing Unit (NPU) for localized AI acceleration.</span><br><span class="line"></span><br><span class="line">The big news here if you&#x27;re following the emerging world of AI PCs is AMD&#x27;s offering of 50 TOPS (Trillion Operations Per Second) of power from the NPU, making it more than capable enough to handle the new Copilot+ AI features coming to Windows 11. That also makes it more powerful than the Hexagon NPU in Qualcomm&#x27;s Snapdragon X Elite and Snapdragon X Plus chips, which comes in at 45 TOPS.</span><br><span class="line"></span><br><span class="line">For anyone interested in Copilot+ without Windows on ARM, this is our first official look at what AMD has cooked up.</span><br><span class="line"></span><br><span class="line">Strix Point has arrived with a rebrand</span><br><span class="line">AMD Ryzen AI 300 breakdown</span><br><span class="line"></span><br><span class="line">A slide from AMD showing a breakdown of the Ryzen AI 300 chip. (Image credit: AMD)</span><br><span class="line">AMD unveiled two new chips from its Ryzen AI 300 series, which has been rebranded to hopefully help avoid some confusion when shopping for a new laptop.</span><br><span class="line"></span><br><span class="line">The Ryzen AI 9 HX 370 is the more powerful chip, offering a total of 12 cores and 24 threads. The cores are split into four standard Zen 5 and eight Zen 5c, which are essentially smaller Zen cores that are more efficient at the cost of overall performance, freeing up space for the GPU and NPU. The Ryzen AI 9 HX 370 has a base TDP of 28W, but the configurable TDP (cTDP) ranges from 15W to 54W.</span><br><span class="line"></span><br><span class="line">Header Cell - Column 0	Cores/Threads	Base/Boost Freq.	NPU TOPS	TDP/cTDP	Graphics</span><br><span class="line">AMD Ryzen AI 9 HX 370	12 / 24	2.0GHz / 5.1GHz	50	28W / 15-54W	AMD Radeon 890M</span><br><span class="line">AMD Ryzen AI 9 365	10 / 20	2.0GHz / 5.0GHz	50	28W / 15-54W	AMD Radeon 880M</span><br><span class="line">The Ryzen AI 9 365 is a tier below the flagship HX 370 model, offering 10 cores (four Zen 5 and six Zen 5c), 20 threads, and a boost clock up to 5.0GHz. It has the same 28W base TDP and wide configurable TDP range.</span><br><span class="line"></span><br><span class="line">AMD Ryzen AI 300 GPU performance</span><br><span class="line"></span><br><span class="line">A slide from AMD showing Ryzen AI 9 HX 370 integrated GPU performance compared to Intel&#x27;s Arc graphics. (Image credit: AMD)</span><br><span class="line">The Ryzen AI 9 HX 370 has the new RDNA 3.5 Radeon 890M integrated GPU with 16 Compute Units (CU), while the Ryzen AI 9 365 has a Raden 880M with 12 CUs. AMD claims up to an average of 36% better gaming performance compared to Intel&#x27;s integrated Arc graphics in its Core Ultra 185H CPU. That, of course, is comparing the top-tier Radeon 890M GPU. The Ryzen AI 9 365&#x27;s integrated GPU with fewer CUs will come in with lower performance.</span><br><span class="line"></span><br><span class="line">Get the Windows Central Newsletter</span><br><span class="line">All the latest news, reviews, and guides for Windows and Xbox diehards.</span><br><span class="line"></span><br><span class="line">Your Email Address</span><br><span class="line">Contact me with news and offers from other Future brands</span><br><span class="line">Receive email from us on behalf of our trusted partners or sponsors</span><br><span class="line">By submitting your information you agree to the Terms &amp; Conditions and Privacy Policy and are aged 16 or over.</span><br><span class="line">AMD Ryzen AI 300 chips have the fastest NPU so far</span><br><span class="line">AMD Ryzen AI 300 NPU performance slide</span><br><span class="line"></span><br><span class="line">An AMD slide showing Ryzen AI 300 NPU performance compared to Qualcomm, Intel, and Apple. (Image credit: AMD)</span><br><span class="line">What I&#x27;m most excited about is the Ryzen AI NPU that AMD says can hit up to 50 TOPS. May 20, 2024, was a huge day in the world of Windows laptops thanks to Qualcomm, Microsoft, and major laptop brands teaming up to deliver a long list of new Copilot+ PCs.</span><br><span class="line"></span><br><span class="line">Windows Central Editor-in-Chief Daniel Rubino called the combination of ARM64 and AI a &quot;Great Reset&quot; for Windows PCs, and we can&#x27;t wait to get our hands on new laptops with Snapdragon X chips to test their power and efficiency.</span><br><span class="line"></span><br><span class="line">A big part of Qualcomm&#x27;s magic is its NPU with 45 TOPS of power for local AI acceleration. Until today this was the most powerful NPU available in a laptop chip, and it was the only entry into the world of Copilot+. AMD has now pulled ahead in the TOPS race, and it has opened up new laptop options for those who don&#x27;t want a system running Windows on ARM.</span><br><span class="line"></span><br><span class="line">Copilot+ requires an AI PC with Windows 11 and an NPU with at least 40 TOPS of power. That leaves, at this time, Qualcomm and AMD as your only announced options. It&#x27;s said that Intel&#x27;s next-gen &quot;Lunar Lake&quot; mobile chips will have an NPU with 45 TOPS, but that still leaves AMD in the lead.</span><br><span class="line"></span><br><span class="line">Copilot+ features include Windows Recall, Live Caption, Windows Studio Effects improvements, Co-Creator local image and text creation, and more.</span><br><span class="line"></span><br><span class="line">AMD Ryzen AI 300 performance chart</span><br><span class="line"></span><br><span class="line">An AMD slide comparing Snapdragon X Elite and Ryzen AI 9 HX 370 performance. (Image credit: AMD)</span><br><span class="line">How much of a difference the extra 5 TOPS will make in local AI work remains to be seen, and AMD isn&#x27;t talking much about efficiency compared to Qualcomm&#x27;s ARM64 chips. AMD did, however, show off some graphs comparing the Snapdragon X Elite (no mention of SKU used to compare) and the Ryzen AI 9 HX 370 in a number of benchmarks.</span><br><span class="line"></span><br><span class="line">Part of AMD&#x27;s Ryzen AI 300 announcement includes quotes from major laptop brands like Acer, ASUS, HP, Lenovo, and MSI. We know that Acer&#x27;s Swift series will see the new Ryzen AI 300 chips, as will a wide range of ASUS laptops from the ROG Zephyrus, ProArt, Vivobook, Zenbook, and TUF Gaming brands.</span><br><span class="line"></span><br><span class="line">Furthermore, HP says an OmniBook AI PC is getting Ryzen AI 300. Lenovo also plans on adding Ryzen AI 300 chips to its Yoga, ThinkPad, and ThinkBook stables. Finally, MSI says its Stealth, Summit, Prestige, and Creator laptops will get the chips later this year.</span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">https://arxiv.org/abs/2405.20974v1</span><br><span class="line">[Submitted on 31 May 2024]</span><br><span class="line">SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales</span><br><span class="line">Tianyang Xu, Shujin Wu, Shizhe Diao, Xiaoze Liu, Xingyao Wang, Yangyi Chen, Jing Gao</span><br><span class="line">Large language models (LLMs) often generate inaccurate or fabricated information and generally fail to indicate their confidence, which limits their broader applications. Previous work elicits confidence from LLMs by direct or self-consistency prompting, or constructing specific datasets for supervised finetuning. The prompting-based approaches have inferior performance, and the training-based approaches are limited to binary or inaccurate group-level confidence estimates. In this work, we present the advanced SaySelf, a training framework that teaches LLMs to express more accurate fine-grained confidence estimates. In addition, beyond the confidence scores, SaySelf initiates the process of directing LLMs to produce self-reflective rationales that clearly identify gaps in their parametric knowledge and explain their uncertainty. This is achieved by using an LLM to automatically summarize the uncertainties in specific knowledge via natural language. The summarization is based on the analysis of the inconsistency in multiple sampled reasoning chains, and the resulting data is utilized for supervised fine-tuning. Moreover, we utilize reinforcement learning with a meticulously crafted reward function to calibrate the confidence estimates, motivating LLMs to deliver accurate, high-confidence predictions and to penalize overconfidence in erroneous outputs. Experimental results in both in-distribution and out-of-distribution datasets demonstrate the effectiveness of SaySelf in reducing the confidence calibration error and maintaining the task performance. We show that the generated self-reflective rationales are reasonable and can further contribute to the calibration. The code is made public at \url&#123;this https URL&#125;.</span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">https://github.com/SkyworkAI/Skywork-MoE/tree/main</span><br><span class="line">English | ç®€ä½“ä¸­æ–‡</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ğŸ¤— Hugging Face â€¢ ğŸ¤– ModelScope â€¢ ğŸ‘¾ Wisemodel â€¢ ğŸ’¬ WeChatâ€¢ ğŸ“œTech Report</span><br><span class="line"></span><br><span class="line">GitHub Stars GitHub Forks</span><br><span class="line"></span><br><span class="line">Project Introduction</span><br><span class="line">Skywork-MoE is a high-performance mixture-of-experts (MoE) model with 146 billion parameters, 16 experts, and 22 billion activated parameters. This model is initialized from the pre-existing dense checkpoints of our Skywork-13B model.</span><br><span class="line"></span><br><span class="line">We introduce two innovative techniques: Gating Logit Normalization, which enhances expert diversification, and Adaptive Auxiliary Loss Coefficients, which allow for layer-specific adjustment of auxiliary loss coefficients.</span><br><span class="line"></span><br><span class="line">Skywork-MoE demonstrates comparable or superior performance to models with more parameters or more activated parameters, such as Grok-1, DBRX, Mistral 8*22, and Deepseek-V2.</span><br><span class="line"></span><br><span class="line">News and Updates</span><br><span class="line">2024.6.3 We release the Skywork-MoE-Base model.</span><br><span class="line"></span><br></pre></td></tr></table></figure>

</details>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2024-06-05</span><i class="fa fa-tag"></i><a class="tag" href="/tags/AI-NEWS/" title="AI_NEWS">AI_NEWS </a></div></div></div></div><div class="share"><div class="evernote"><a class="fa fa-bookmark" href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank"></a></div><div class="twitter"><a class="fa fa-twitter" target="_blank" rel="noopener" href="http://twitter.com/home?status=,https://dongyoungkim2.github.io/2024/06/05/2024-6-5-AI-NEWS/,TECH BLOG  by Dongyoung Kim   Ph.D.,2024ë…„ 6ì›” 5ì¼ AI ì†Œì‹,;"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/2024/06/07/2024-6-7-AI-NEWS/" title="2024ë…„ 6ì›” 7ì¼ AI ì†Œì‹">Previous</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/2024/06/04/computex-2024/" title="NVIDIA CEO Jensen Huang Keynote at COMPUTEX 2024">Next</a></li></ul></div></div></div></div></div><script src="/js/jquery.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script></body></html>