<!DOCTYPE html><html lang="ko-KR"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author"><title>2024ë…„ 6ì›” 25ì¼ AI ì†Œì‹ Â· TECH BLOG  by Dongyoung Kim   Ph.D.</title><meta name="description" content="2024ë…„ 6ì›” 25ì¼ AI ì†Œì‹SummaryOpenAIì—ì„œëŠ” ë°ì´í„° ì¸ë±ì‹±ê³¼ ì¿¼ë¦¬ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” ì‹¤ì‹œê°„ ë¶„ì„ ë°ì´í„°ë² ì´ìŠ¤ì¸ Rocksetì„ ì¸ìˆ˜í•˜ì—¬ ìì‚¬ì˜ ê²€ìƒ‰ ì¸í”„ë¼ë¥¼ ê°•í™”í•  ì˜ˆì •ì…ë‹ˆë‹¤. Arcee.aiì—ì„œëŠ” ìƒˆë¡œìš´ Qwen2 7B ê¸°ë°˜ì˜ ì»¤ìŠ¤í…€ ëª¨ë¸ Arcee-"><meta name="keywords"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><!-- Google tag (gtag.js)--><script async src="https://www.googletagmanager.com/gtag/js?id=G-Y36E4JYRDG"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-Y36E4JYRDG');</script><meta name="generator" content="Hexo 7.2.0"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:157px;"><h3 title=""><a href="/">TECH BLOG  by Dongyoung Kim   Ph.D.</a></h3></div></div><ul class="social-links"></ul><div class="footer"><a target="_blank" href="/"></a><div class="by_farbox"><a href="https://dykim.dev/" target="_blank">Â© Dongyoung Kim, Ph.D. </a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">Home</a></li><li><a href="/about">Curriculum Vitae</a></li><li><a href="/archives">Archive</a></li></div><div class="information"><div class="back_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"> </a></li></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>2024ë…„ 6ì›” 25ì¼ AI ì†Œì‹</a></h3></div><div class="post-content"><h1 id="2024ë…„-6ì›”-25ì¼-AI-ì†Œì‹"><a href="#2024ë…„-6ì›”-25ì¼-AI-ì†Œì‹" class="headerlink" title="2024ë…„ 6ì›” 25ì¼ AI ì†Œì‹"></a>2024ë…„ 6ì›” 25ì¼ AI ì†Œì‹</h1><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>OpenAIì—ì„œëŠ” ë°ì´í„° ì¸ë±ì‹±ê³¼ ì¿¼ë¦¬ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” ì‹¤ì‹œê°„ ë¶„ì„ ë°ì´í„°ë² ì´ìŠ¤ì¸ Rocksetì„ ì¸ìˆ˜í•˜ì—¬ ìì‚¬ì˜ ê²€ìƒ‰ ì¸í”„ë¼ë¥¼ ê°•í™”í•  ì˜ˆì •ì…ë‹ˆë‹¤. Arcee.aiì—ì„œëŠ” ìƒˆë¡œìš´ Qwen2 7B ê¸°ë°˜ì˜ ì»¤ìŠ¤í…€ ëª¨ë¸ Arcee-Sparkë¥¼ ì¶œì‹œí•˜ì—¬ AGIEvalê³¼ MT-Bench ë“±ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë©°, Nous ResearchëŠ” Llama-3 Instructì™€ í†µí•©í•œ Hermes-2 Theta 70B ëª¨ë¸ì„ ë°œí‘œí•˜ì—¬ ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤. BBCëŠ” AIê°€ ì¸ê°„ì˜ ì¼ìë¦¬ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë³´ë„í•˜ë©°, AI ìë™í™”ë¡œ ì¸í•œ í•´ê³  ì‚¬ë¡€ë¥¼ ì¡°ëª…í–ˆìŠµë‹ˆë‹¤. ë˜í•œ GenQAëŠ” ë‹¤ì–‘í•œ ì£¼ì œì— ëŒ€í•´ ìë™ìœ¼ë¡œ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë°ì´í„°ì…‹ì„ ê³µê°œí–ˆìŠµë‹ˆë‹¤. MOFA-VideoëŠ” ì»¨íŠ¸ë¡¤ ê°€ëŠ¥í•œ ì´ë¯¸ì§€ ì• ë‹ˆë©”ì´ì…˜ ìƒì„± ê¸°ìˆ ì„ ì„ ë³´ì˜€ìœ¼ë©°, MARS5 TTSëŠ” ë›°ì–´ë‚œ í”„ë¡œì†Œë”” ì œì–´ ê¸°ëŠ¥ì„ ê°–ì¶˜ ì˜¤í”ˆ ì†ŒìŠ¤ ìŒì„± í•©ì„± ëª¨ë¸ì„ ë°œí‘œí–ˆìŠµë‹ˆë‹¤.</p>
<h2 id="OpenAI-Rockset-ì¸ìˆ˜"><a href="#OpenAI-Rockset-ì¸ìˆ˜" class="headerlink" title="OpenAI, Rockset ì¸ìˆ˜"></a>OpenAI, Rockset ì¸ìˆ˜</h2><h3 id="OpenAI-Rockset-ì¸ìˆ˜-1"><a href="#OpenAI-Rockset-ì¸ìˆ˜-1" class="headerlink" title="OpenAI, Rockset ì¸ìˆ˜"></a>OpenAI, Rockset ì¸ìˆ˜</h3><p><a target="_blank" rel="noopener" href="https://openai.com/index/openai-acquires-rockset/">ë§í¬</a>, 2024ë…„ 6ì›” 21ì¼,<br>OpenAI</p>
<ul>
<li>OpenAIëŠ” Rocksetì„ ì¸ìˆ˜í•˜ì—¬ ìì‚¬ì˜ ê²€ìƒ‰ ì¸í”„ë¼ë¥¼ ê°•í™”í•  ê³„íš</li>
<li>Rocksetì€ ì‹¤ì‹œê°„ ë°ì´í„° ì¸ë±ì‹± ë° ì¿¼ë¦¬ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” ë¶„ì„ ë°ì´í„°ë² ì´ìŠ¤</li>
<li>Rocksetì˜ ê¸°ìˆ ì€ OpenAI ì œí’ˆì˜ ê²€ìƒ‰ ì¸í”„ë¼ì— í†µí•©ë  ì˜ˆì •</li>
<li>Rockset íŒ€ì˜ ì¼ë¶€ ë©¤ë²„ë“¤ì´ OpenAIì— í•©ë¥˜</li>
<li>Brad Lightcap, OpenAI COOëŠ” Rocksetì˜ ì¸í”„ë¼ê°€ ê¸°ì—…ë“¤ì´ ë°ì´í„°ë¥¼ ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸í…”ë¦¬ì „ìŠ¤ë¡œ ë³€í™˜í•˜ëŠ” ë° ë„ì›€ì„ ì¤„ ê²ƒì´ë¼ê³  ë°œí‘œ</li>
<li>Venkat Venkataramani, Rockset CEOëŠ” OpenAIì™€ì˜ í˜‘ë ¥ì„ í†µí•´ ì‚¬ìš©ì, ê¸°ì—…, ê°œë°œìë“¤ì´ ë°ì´í„°ë¥¼ ìµœëŒ€í•œ í™œìš©í•  ìˆ˜ ìˆê²Œ ë  ê²ƒì´ë¼ê³  ë°œí‘œ</li>
</ul>
<h2 id="Arcee-ai-Arcee-Spark-ì¶œì‹œ"><a href="#Arcee-ai-Arcee-Spark-ì¶œì‹œ" class="headerlink" title="Arcee.ai, Arcee-Spark ì¶œì‹œ"></a>Arcee.ai, Arcee-Spark ì¶œì‹œ</h2><h3 id="Arcee-Spark-ì¶œì‹œ"><a href="#Arcee-Spark-ì¶œì‹œ" class="headerlink" title="Arcee-Spark ì¶œì‹œ"></a>Arcee-Spark ì¶œì‹œ</h3><p><a target="_blank" rel="noopener" href="https://huggingface.co/arcee-ai/Arcee-Spark">ë§í¬</a>, 2024ë…„ 6ì›”,<br>Arcee.ai</p>
<ul>
<li>Qwen2 7B ê¸°ë°˜ì˜ ì»¤ìŠ¤í…€ ëª¨ë¸ Arcee-Spark ì¶œì‹œ</li>
<li>1.8ë°±ë§Œ ìƒ˜í”Œë¡œ ë¯¸ì„¸ ì¡°ì • í›„ Qwen2-7B-Instructì™€ ë³‘í•©</li>
<li>Direct Preference Optimization (DPO)ë¡œ ì¶”ê°€ í›ˆë ¨</li>
<li>AGIEval 51.11, MT-Bench 8.46, BigBenchHard 45.78, EQ-Bench 71.4 ì ìˆ˜ ë‹¬ì„±</li>
<li>ì‘ì€ í¬ê¸°ì—ë„ ë¶ˆêµ¬í•˜ê³  ë›°ì–´ë‚œ ì„±ëŠ¥ ì œê³µ</li>
<li>ì‹¤ì‹œê°„ ì• í”Œë¦¬ì¼€ì´ì…˜, ì—£ì§€ ì»´í“¨íŒ…, ë¹„ìš© íš¨ìœ¨ì ì¸ ìŠ¤ì¼€ì¼ë§ ë“±ì— ì´ìƒì </li>
<li>GPT-3.5ë³´ë‹¤ ë§ì€ ì‘ì—…ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì„</li>
<li>ëŒ€í™”ì˜ ë§ì€ íšŒì „ì´ í•„ìš”í•œ ì‘ì—…ì´ë‚˜ ëŒ€ëŸ‰ì˜ í…ìŠ¤íŠ¸ ì‘ì—…ì— ì í•©í•œ 128k í† í°ì˜ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œê³µ</li>
</ul>
<h2 id="Nous-Research-Hermes-2-Theta-70B-ë°œí‘œ"><a href="#Nous-Research-Hermes-2-Theta-70B-ë°œí‘œ" class="headerlink" title="Nous Research, Hermes-2 Theta 70B ë°œí‘œ"></a>Nous Research, Hermes-2 Theta 70B ë°œí‘œ</h2><h3 id="Hermes-2-Theta-70B-ë°œí‘œ"><a href="#Hermes-2-Theta-70B-ë°œí‘œ" class="headerlink" title="Hermes-2 Theta 70B ë°œí‘œ"></a>Hermes-2 Theta 70B ë°œí‘œ</h3><p><a target="_blank" rel="noopener" href="https://huggingface.co/NousResearch/Hermes-2-Theta-Llama-3-70B">ë§í¬</a>, 2024ë…„ 6ì›”,<br>Nous Research</p>
<ul>
<li>Hermes-2 Î˜ (Theta) 70B ëª¨ë¸ ë°œí‘œ</li>
<li>Hermes 2 Pro ëª¨ë¸ê³¼ Metaì˜ Llama-3 Instruct ëª¨ë¸ì„ í†µí•©í•˜ì—¬ ê°œë°œ</li>
<li>ê°•í™” í•™ìŠµì„ í†µí•´ ì„±ëŠ¥ í–¥ìƒ</li>
<li>ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ Llama-3 Instruct 70Bë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ì…ì¦</li>
<li>Nous Researchì™€ Charles Goddard, Arcee AI íŒ€ì˜ í˜‘ë ¥ìœ¼ë¡œ ê°œë°œ</li>
</ul>
<h2 id="AIê°€-ì¸ê°„ì˜-ì¼ìë¦¬ì—-ë¯¸ì¹˜ëŠ”-ì˜í–¥"><a href="#AIê°€-ì¸ê°„ì˜-ì¼ìë¦¬ì—-ë¯¸ì¹˜ëŠ”-ì˜í–¥" class="headerlink" title="AIê°€ ì¸ê°„ì˜ ì¼ìë¦¬ì— ë¯¸ì¹˜ëŠ” ì˜í–¥"></a>AIê°€ ì¸ê°„ì˜ ì¼ìë¦¬ì— ë¯¸ì¹˜ëŠ” ì˜í–¥</h2><h3 id="AIê°€-ì¸ê°„ì˜-ì¼ìë¦¬ì—-ë¯¸ì¹˜ëŠ”-ì˜í–¥-1"><a href="#AIê°€-ì¸ê°„ì˜-ì¼ìë¦¬ì—-ë¯¸ì¹˜ëŠ”-ì˜í–¥-1" class="headerlink" title="AIê°€ ì¸ê°„ì˜ ì¼ìë¦¬ì— ë¯¸ì¹˜ëŠ” ì˜í–¥"></a>AIê°€ ì¸ê°„ì˜ ì¼ìë¦¬ì— ë¯¸ì¹˜ëŠ” ì˜í–¥</h3><p><a target="_blank" rel="noopener" href="https://www.bbc.com/future/article/20240612-the-people-making-ai-sound-more-human">ë§í¬</a>, 2024ë…„ 6ì›” 16ì¼,<br>BBC</p>
<ul>
<li>AI ìë™í™” ë„ì… í›„ 60ëª… ì¤‘ 59ëª… í•´ê³  ì‚¬ë¡€ ë³´ê³ </li>
<li>ë§ˆì§€ë§‰ ë‚¨ì€ í•œ ëª…ë„ ë‚˜ì¤‘ì— í•´ê³ ë¨</li>
<li>AIê°€ ì‘ì„±í•œ ë¬¸ì„œë¥¼ ì¸ê°„ì´ ìˆ˜ì •í•˜ëŠ” ì‘ì—… ì¦ê°€</li>
<li>Benjamin Millerì˜ ì‚¬ë¡€ë¥¼ í†µí•´ AI ë„ì…ìœ¼ë¡œ ì¸í•œ ì¼ìë¦¬ ê°ì†Œ ì‚¬ë¡€ ì†Œê°œ</li>
<li>AIì™€ ì¸ê°„ì˜ í˜‘ì—…ì´ ìƒˆë¡œìš´ ì¼ìë¦¬ ì°½ì¶œ ê°€ëŠ¥ì„± ì œì‹œ</li>
<li>ì´ˆê¸° ë‹¨ê³„ì˜ AI ë„ì…ìœ¼ë¡œ ì¸í•´ ì¸ê°„ì˜ ì¼ìë¦¬ê°€ ê°ì†Œí–ˆìœ¼ë‚˜, í–¥í›„ í˜‘ì—…ì˜ ê°€ëŠ¥ì„±ë„ ì¡´ì¬</li>
<li>ì €ì„ê¸ˆìœ¼ë¡œ AIê°€ ì‘ì„±í•œ ê¸€ì„ ìˆ˜ì •í•˜ëŠ” ìƒˆë¡œìš´ ì§ì—… ë“±ì¥</li>
</ul>
<h2 id="GenQA-ë‹¤ì–‘í•œ-ì£¼ì œì—-ëŒ€í•œ-ìë™-ì§ˆë¬¸-ìƒì„±"><a href="#GenQA-ë‹¤ì–‘í•œ-ì£¼ì œì—-ëŒ€í•œ-ìë™-ì§ˆë¬¸-ìƒì„±" class="headerlink" title="GenQA: ë‹¤ì–‘í•œ ì£¼ì œì— ëŒ€í•œ ìë™ ì§ˆë¬¸ ìƒì„±"></a>GenQA: ë‹¤ì–‘í•œ ì£¼ì œì— ëŒ€í•œ ìë™ ì§ˆë¬¸ ìƒì„±</h2><h3 id="GenQA-ë°ì´í„°ì…‹-ê³µê°œ"><a href="#GenQA-ë°ì´í„°ì…‹-ê³µê°œ" class="headerlink" title="GenQA ë°ì´í„°ì…‹ ê³µê°œ"></a>GenQA ë°ì´í„°ì…‹ ê³µê°œ</h3><p><a target="_blank" rel="noopener" href="https://huggingface.co/papers/2406.10323">ë§í¬</a>, 2024ë…„ 6ì›” 15ì¼,<br>GenQA</p>
<ul>
<li>10ë°±ë§Œ ê°œ ì´ìƒì˜ ì²­ì†Œ ë° ì¤‘ë³µ ì œê±°ëœ ëª…ë ¹ì–´ ë°ì´í„°ì…‹ ê³µê°œ</li>
<li>ë‹¤ì–‘í•œ ì£¼ì œì— ëŒ€í•´ ìë™ìœ¼ë¡œ ì§ˆë¬¸ê³¼ ë‹µë³€ ìƒì„±</li>
<li>Gemini Pro 1.0ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ìƒì„±</li>
<li>AlpacaEval 2.0ê³¼ MT-Benchì—ì„œ UltraChatê³¼ WizardLMë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ ë‹¬ì„±</li>
<li>ë°ì´í„°ì…‹, ìƒì„±ê¸° í”„ë¡¬í”„íŠ¸ ë° ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê³µê°œ</li>
<li>ì£¼ì œ ë‹¤ì–‘ì„±ì„ ë†’ì´ê¸° ìœ„í•´ â€œbe creativeâ€, â€œbe smartâ€ ë“±ì˜ ì ‘ë¯¸ì‚¬ë¥¼ ì¶”ê°€í•˜ì—¬ ë°ì´í„° ìƒì„±</li>
</ul>
<h2 id="MOFA-Video-ì»¨íŠ¸ë¡¤-ê°€ëŠ¥í•œ-ì´ë¯¸ì§€-ì• ë‹ˆë©”ì´ì…˜"><a href="#MOFA-Video-ì»¨íŠ¸ë¡¤-ê°€ëŠ¥í•œ-ì´ë¯¸ì§€-ì• ë‹ˆë©”ì´ì…˜" class="headerlink" title="MOFA-Video: ì»¨íŠ¸ë¡¤ ê°€ëŠ¥í•œ ì´ë¯¸ì§€ ì• ë‹ˆë©”ì´ì…˜"></a>MOFA-Video: ì»¨íŠ¸ë¡¤ ê°€ëŠ¥í•œ ì´ë¯¸ì§€ ì• ë‹ˆë©”ì´ì…˜</h2><h3 id="MOFA-Video-ë°œí‘œ"><a href="#MOFA-Video-ë°œí‘œ" class="headerlink" title="MOFA-Video ë°œí‘œ"></a>MOFA-Video ë°œí‘œ</h3><p><a target="_blank" rel="noopener" href="https://myniuuu.github.io/MOFA_Video/">ë§í¬</a>, 2024ë…„ 6ì›” 2ì¼,<br>Muyao Niu ì™¸</p>
<ul>
<li>MOFA-VideoëŠ” ì£¼ì–´ì§„ ì´ë¯¸ì§€ì—ì„œ ë‹¤ì–‘í•œ ì¶”ê°€ ì‹ í˜¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ë””ì˜¤ë¥¼ ìƒì„±í•˜ëŠ” ê¸°ìˆ  ë°œí‘œ</li>
<li>ì¸ê°„ ëœë“œë§ˆí¬ ì°¸ì¡°, ìˆ˜ë™ ê²½ë¡œ ë° ë‹¤ë¥¸ ì œê³µëœ ë¹„ë””ì˜¤ ë“±ì˜ ì‹ í˜¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ë””ì˜¤ ìƒì„± ê°€ëŠ¥</li>
<li>ë‹¤ì–‘í•œ ëª¨ì…˜ ë„ë©”ì¸ì—ì„œ ì‘ë™í•˜ë©° ê°•ë ¥í•œ ì œì–´ ê¸°ëŠ¥ ì œê³µ</li>
<li>MOFA-ì–´ëŒ‘í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ë””ì˜¤ ìƒì„± íŒŒì´í”„ë¼ì¸ì—ì„œ ìƒì„±ëœ ëª¨ì…˜ ì œì–´</li>
<li>ìˆ˜ë™ ê²½ë¡œ ë° ì¸ê°„ ëœë“œë§ˆí¬ë¥¼ ìœ„í•œ ë‘ ê°œì˜ ëª¨ì…˜ ì–´ëŒ‘í„° ê°œë³„ í›ˆë ¨</li>
<li>MOFA-ì–´ëŒ‘í„°ê°€ ë‹¤ì–‘í•œ ë„ë©”ì¸ì—ì„œ í•¨ê»˜ ì‘ë™ ê°€ëŠ¥</li>
</ul>
<h2 id="MARS5-TTS-ê³ ë„ì˜-í”„ë¡œì†Œë””-ì œì–´-ìŒì„±-í•©ì„±"><a href="#MARS5-TTS-ê³ ë„ì˜-í”„ë¡œì†Œë””-ì œì–´-ìŒì„±-í•©ì„±" class="headerlink" title="MARS5 TTS: ê³ ë„ì˜ í”„ë¡œì†Œë”” ì œì–´ ìŒì„± í•©ì„±"></a>MARS5 TTS: ê³ ë„ì˜ í”„ë¡œì†Œë”” ì œì–´ ìŒì„± í•©ì„±</h2><h3 id="MARS5-TTS-ë°œí‘œ"><a href="#MARS5-TTS-ë°œí‘œ" class="headerlink" title="MARS5 TTS ë°œí‘œ"></a>MARS5 TTS ë°œí‘œ</h3><p><a target="_blank" rel="noopener" href="https://github.com/Camb-ai/MARS5-TTS">ë§í¬</a>, 2024ë…„ 6ì›”,<br>CAMB.AI</p>
<ul>
<li>MARS5 TTSëŠ” ë›°ì–´ë‚œ í”„ë¡œì†Œë”” ì œì–´ ê¸°ëŠ¥ì„ ê°–ì¶˜ ì˜¤í”ˆ ì†ŒìŠ¤ í…ìŠ¤íŠ¸ ìŒì„± ë³€í™˜(TTS) ëª¨ë¸ ë°œí‘œ</li>
<li>5ì´ˆ ì´í•˜ì˜ ìŒì„±ìœ¼ë¡œ ìŒì„± í´ë¡œë‹ ê°€ëŠ¥</li>
<li>ì´ì¤‘ ë‹¨ê³„ Auto-Regressive(750M) + Non-Auto Regressive(450M) ëª¨ë¸ ì•„í‚¤í…ì²˜</li>
<li>êµ¬ë‘ì , ë©ˆì¶¤ ë“±ì„ ì œì–´í•  ìˆ˜ ìˆëŠ” BPE í† í¬ë‚˜ì´ì € ì‚¬ìš©</li>
<li>AR ëª¨ë¸ì´ L0 ì½”ìŠ¤ í† í°ì„ ì˜ˆì¸¡í•˜ê³ , NAR DDPM ëª¨ë¸ì´ ì´ë¥¼ ì„¸ë°€í•˜ê²Œ ì¡°ì •í•œ í›„ ë³´ì½”ë”ë¥¼ í†µí•´ ìµœì¢… ì˜¤ë””ì˜¤ ìƒì„±</li>
<li>í…ìŠ¤íŠ¸ì™€ ì°¸ì¡° ì˜¤ë””ì˜¤ë¥¼ í•¨ê»˜ ì‚¬ìš©í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ë°œìŒ ë° ì–µì–‘ ì œì–´ ê°€ëŠ¥</li>
<li>ìŠ¤í¬ì¸  í•´ì„¤, ì• ë‹ˆë©”ì´ì…˜ ë“± ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ ë°œíœ˜</li>
</ul>
<details>
  <summary>Sources</summary>

<p>This GPT assists users by creating a detailed daily newspaper in Korean based on provided links. It follows these steps: read the content, summarize each content with detailed points, and write a report. The report format is:</p>
<h1 id="todayâ€™s-date-in-ë…„-ì›”-ì¼-AI-ì†Œì‹"><a href="#todayâ€™s-date-in-ë…„-ì›”-ì¼-AI-ì†Œì‹" class="headerlink" title="(todayâ€™s date in ë…„ ì›” ì¼) AI ì†Œì‹,"></a>(todayâ€™s date in ë…„ ì›” ì¼) AI ì†Œì‹,</h1><h2 id="Summary-1"><a href="#Summary-1" class="headerlink" title="Summary"></a>Summary</h2><p>(overall short summary, make summary with good details. for Summary section, explain the details starting with company name, e.g. OpenAIì—ì„œëŠ” ~~~ë¥¼ ë°œí‘œí•˜ì˜€ìŠµë‹ˆë‹¤.)</p>
<h2 id="Title"><a href="#Title" class="headerlink" title="Title,"></a>Title,</h2><h3 id="í•œê¸€ì œëª©"><a href="#í•œê¸€ì œëª©" class="headerlink" title="í•œê¸€ì œëª©"></a>í•œê¸€ì œëª©</h3><p><a href="link">ë§í¬</a>, date,<br>company name</p>
<ul>
<li>detailed summary1, (ê°œì¡°ì‹ ë¬¸ì²´ ì‚¬ìš©)</li>
<li>detailed summary2, (ê°œì¡°ì‹ ë¬¸ì²´ ì‚¬ìš©)<br>â€¦</li>
<li>detailed summary N, (ê°œì¡°ì‹ ë¬¸ì²´ ì‚¬ìš©)</li>
</ul>
<h2 id="Title-1"><a href="#Title-1" class="headerlink" title="Title,"></a>Title,</h2><h3 id="í•œê¸€ì œëª©-1"><a href="#í•œê¸€ì œëª©-1" class="headerlink" title="í•œê¸€ì œëª©"></a>í•œê¸€ì œëª©</h3><p><a href="link">ë§í¬</a>, date,<br>company name</p>
<ul>
<li>detailed summary1, (ê°œì¡°ì‹ ë¬¸ì²´ ì‚¬ìš©)</li>
<li>detailed summary2, (ê°œì¡°ì‹ ë¬¸ì²´ ì‚¬ìš©)<br>â€¦</li>
<li>detailed summary N, (ê°œì¡°ì‹ ë¬¸ì²´ ì‚¬ìš©)<br>â€¦</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br></pre></td><td class="code"><pre><span class="line">###</span><br><span class="line">https://openai.com/index/openai-acquires-rockset/</span><br><span class="line">June 21, 2024</span><br><span class="line"></span><br><span class="line">OpenAI acquires Rockset</span><br><span class="line">Enhancing our retrieval infrastructure to make AI more helpful</span><br><span class="line"></span><br><span class="line">image (1)</span><br><span class="line">AI has the opportunity to transform how people and organizations leverage their own data. Thatâ€™s why weâ€™ve acquired Rockset, a leading real-time analytics database that provides world-class data indexing and querying capabilities.</span><br><span class="line"></span><br><span class="line">Rockset enables users, developers, and enterprises to better leverage their own data and access real-time information as they use AI products and build more intelligent applications.</span><br><span class="line"></span><br><span class="line">We will integrate Rocksetâ€™s technology to power our retrieval infrastructure across products, and members of Rocksetâ€™s world-class team will join OpenAI.</span><br><span class="line"></span><br><span class="line">â€œRocksetâ€™s infrastructure empowers companies to transform their data into actionable intelligence. Weâ€™re excited to bring these benefits to our customers by integrating Rocksetâ€™s foundation into OpenAI products,â€ said Brad Lightcap, OpenAI COO.</span><br><span class="line"></span><br><span class="line">â€œWeâ€™re excited to be joining OpenAI to empower users, enterprises and developers to fully leverage their data by bringing powerful retrieval to AI,â€ said Venkat Venkataramani, CEO of Rockset.</span><br><span class="line"></span><br><span class="line">Stay tuned for more updates as we get to work integrating Rocksetâ€™s capabilities.</span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">https://huggingface.co/arcee-ai/Arcee-Spark</span><br><span class="line">Qwen2 has a lot of potential! ğŸ‘€ Arcee.ai released Arcee-Spark their first Qwen2 7B based custom model, outperforming Meta Llama 3 8B instruct on AGIEval and OpenAI GPT-3.5 on MT-Bench.</span><br><span class="line">&gt; Fine-tuned Qwen2 Base on 1.8 million samples</span><br><span class="line">&gt; Merged with Qwen2-7B-Instruct using mergekit</span><br><span class="line">&gt; Further post trained using DPO</span><br><span class="line">&gt; AGIEval 51.11; MT-Bench 8.46; BigBenchHard 45.78; EQ-Bench: 71.4</span><br><span class="line">&gt; Apache 2.0 license</span><br><span class="line">Arcee Spark</span><br><span class="line">Arcee Spark is a powerful 7B parameter language model that punches well above its weight class. Initialized from Qwen2, this model underwent a sophisticated training process:</span><br><span class="line"></span><br><span class="line">Fine-tuned on 1.8 million samples</span><br><span class="line">Merged with Qwen2-7B-Instruct using Arcee&#x27;s mergekit</span><br><span class="line">Further refined using Direct Preference Optimization (DPO)</span><br><span class="line">This meticulous process results in exceptional performance, with Arcee Spark achieving the highest score on MT-Bench for models of its size, outperforming even GPT-3.5 on many tasks.</span><br><span class="line"></span><br><span class="line">Key Features</span><br><span class="line">7B parameters</span><br><span class="line">State-of-the-art performance for its size</span><br><span class="line">Initialized from Qwen2</span><br><span class="line">Advanced training process including fine-tuning, merging, and DPO</span><br><span class="line">Highest MT-Bench score in the 7B class</span><br><span class="line">Outperforms GPT-3.5 on many tasks</span><br><span class="line">Has a context length of 128k tokens, making it ideal for tasks requiring many conversation turns or working with large amounts of text.</span><br><span class="line">Business Use Cases</span><br><span class="line">Arcee Spark offers a compelling solution for businesses looking to leverage advanced AI capabilities without the hefty computational requirements of larger models. Its unique combination of small size and high performance makes it ideal for:</span><br><span class="line"></span><br><span class="line">Real-time applications: Deploy Arcee Spark for chatbots, customer service automation, and interactive systems where low latency is crucial.</span><br><span class="line"></span><br><span class="line">Edge computing: Run sophisticated AI tasks on edge devices or in resource-constrained environments.</span><br><span class="line"></span><br><span class="line">Cost-effective scaling: Implement advanced language AI across your organization without breaking the bank on infrastructure or API costs.</span><br><span class="line"></span><br><span class="line">Rapid prototyping: Quickly develop and iterate on AI-powered features and products.</span><br><span class="line"></span><br><span class="line">On-premise deployment: Easily host Arcee Spark on local infrastructure for enhanced data privacy and security.</span><br><span class="line"></span><br><span class="line">Performance and Efficiency</span><br><span class="line">Arcee Spark demonstrates that bigger isn&#x27;t always better in the world of language models. By leveraging advanced training techniques and architectural optimizations, it delivers:</span><br><span class="line"></span><br><span class="line">Speed: Blazing fast inference times, often 10-100x faster than larger models.</span><br><span class="line">Efficiency: Significantly lower computational requirements, reducing both costs and environmental impact.</span><br><span class="line">Flexibility: Easy to fine-tune or adapt for specific domains or tasks.</span><br><span class="line">Despite its compact size, Arcee Spark offers deep reasoning capabilities, making it suitable for a wide range of complex tasks including:</span><br><span class="line"></span><br><span class="line">Advanced text generation</span><br><span class="line">Detailed question answering</span><br><span class="line">Nuanced sentiment analysis</span><br><span class="line">Complex problem-solving</span><br><span class="line">Code generation and analysis</span><br><span class="line">Model Availability</span><br><span class="line">Quants: Arcee Spark GGUF</span><br><span class="line">FP32: For those looking to squeeze every bit of performance out of the model, we offer an FP32 version that scores slightly higher on all benchmarks.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">https://huggingface.co/NousResearch/Hermes-2-Theta-Llama-3-70B</span><br><span class="line">Hermes 2 Theta Llama-3 70B Model Card</span><br><span class="line">image/png</span><br><span class="line">Introducing Hermes 2 Theta 70B!</span><br><span class="line"></span><br><span class="line">Hermes 2 Theta is smarter, more creative, and capable of more then ever before.</span><br><span class="line"></span><br><span class="line">It takes a strong lead over Llama-3 Instruct 70B across a wide variety of benchmarks, and is a continuation of our collaboration with</span><br><span class="line">Model Description</span><br><span class="line">Hermes-2 Î˜ (Theta) 70B is the continuation of our experimental merged model released by Nous Research, in collaboration with Charles Goddard and Arcee AI, the team behind MergeKit.</span><br><span class="line"></span><br><span class="line">Hermes-2 Î˜ is a merged and then further RLHF&#x27;ed version our excellent Hermes 2 Pro model and Meta&#x27;s Llama-3 Instruct model to form a new model, Hermes-2 Î˜, combining the best of both worlds of each model.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">https://www.bbc.com/future/article/20240612-the-people-making-ai-sound-more-human</span><br><span class="line">AI took their jobs. Now they get paid to make it sound human</span><br><span class="line">16 June 2024</span><br><span class="line">By Thomas Germain,</span><br><span class="line"></span><br><span class="line">1. 60ëª…ìœ¼ë¡œ êµ¬ì„±ëœ ì½˜í…ì¸  íŒ€, AI ìë™í™” ë„ì… í›„ 59ëª… í•´ê³ .</span><br><span class="line">ë§ˆì§€ë§‰ ë‚¨ì€ í•œ ëª…ë„ ë‚˜ì¤‘ì— í•´ê³ í–ˆë‹¤ê³  í•œë‹¤.</span><br><span class="line"></span><br><span class="line">Share</span><br><span class="line">Serenity Strull/BBC/Getty Images Hands typing on a typewriter (Credit: Serenity Strull/BBC/Getty Images)Serenity Strull/BBC/Getty Images</span><br><span class="line">(Credit: Serenity Strull/BBC/Getty Images)</span><br><span class="line">If you&#x27;re worried about how AI will affect your job, the world of copywriters may offer a glimpse of the future.</span><br><span class="line"></span><br><span class="line">Writer Benjamin Miller â€“ not his real name â€“ was thriving in early 2023. He led a team of more than 60 writers and editors, publishing blog posts and articles to promote a tech company that packages and resells data on everything from real estate to used cars. &quot;It was really engaging work,&quot; Miller says, a chance to flex his creativity and collaborate with experts on a variety of subjects. But one day, Miller&#x27;s manager told him about a new project. &quot;They wanted to use AI to cut down on costs,&quot; he says. (Miller signed a non-disclosure agreement, and asked the BBC to withhold his and the company&#x27;s name.)</span><br><span class="line">A month later, the business introduced an automated system. Miller&#x27;s manager would plug a headline for an article into an online form, an AI model would generate an outline based on that title, and Miller would get an alert on his computer. Instead of coming up with their own ideas, his writers would create articles around those outlines, and Miller would do a final edit before the stories were published. Miller only had a few months to adapt before he got news of a second layer of automation. Going forward, ChatGPT would write the articles in their entirety, and most of his team was fired. The few people remaining were left with an even less creative task: editing ChatGPT&#x27;s subpar text to make it sound more human.</span><br><span class="line">By 2024, the company laid off the rest of Miller&#x27;s team, and he was alone. &quot;All of a sudden I was just doing everyone&#x27;s job,&quot; Miller says. Every day, he&#x27;d open the AI-written documents to fix the robot&#x27;s formulaic mistakes, churning out the work that used to employ dozens of people.</span><br><span class="line">In numerous industries, AI is being used to produce work that was once the exclusive domain of the human mind</span><br><span class="line">&quot;Mostly, it was just about cleaning things up and making the writing sound less awkward, cutting out weirdly formal or over-enthusiastic language,&quot; Miller says. &quot;It was more editing than I had to do with human writers, but it was always the exact same kinds of edits. The real problem was it was just so repetitive and boring. It started to feel like I was the robot.&quot;</span><br><span class="line">Miller&#x27;s experience reflects a broader shift. In numerous industries, AI is being used to produce work that was once the exclusive domain of the human mind. AI is often less expensive than a person, but early adopters are quick to learn it can&#x27;t always perform on the same level. Now, people like Miller are finding themselves being asked to team up with the same robots that are stealing their jobs to give the algorithms a bit of humanity â€“ a hidden army making AI seem better than it really is.</span><br><span class="line">If AI gets dramatically more effective, this will be a temporary solution. If it doesn&#x27;t, Miller&#x27;s story could be a preview of what&#x27;s coming to other professions.</span><br><span class="line">Serenity Strull/BBC/Getty Images Copywriters are at the forefront of a new line of work: human-AI collaboration (Credit: Serenity Strull/BBC/Getty Images)Serenity Strull/BBC/Getty Images</span><br><span class="line">Copywriters are at the forefront of a new line of work: human-AI collaboration (Credit: Serenity Strull/BBC/Getty Images)</span><br><span class="line">Will AI steal your job? It&#x27;s hard to say. We&#x27;re at an unsettling crossroads, where some experts warn that super intelligent robots will soon replace most human work, while others believe the technology may never even approach that point. There are also some who argue we are heading towards a future of AI and human collaboration rather than competition.</span><br><span class="line">But on a much smaller scale, some workers already face distressing consequences. If there&#x27;s one thing the large language models powered by generative AI can do, it&#x27;s string together words and paragraphs, putting some writers on the frontline.</span><br><span class="line">The fear of losing work to AI-powered writing tools was one of the main issues that led to the screen writers strike in the US last year. And other creative industries face similar concerns about their future with the arrival of AI tools capable of generating images, audio and video from scratch.</span><br><span class="line">We&#x27;re adding the &#x27;human touch&#x27;, but that often requires a deep, developmental edit on a piece of writing â€“ Catrina Cowart</span><br><span class="line">The impact is already being felt among copywriters â€“ the people who write marketing material and other content for businesses. In some corners of the copywriting business, AI is a blessing. It can be a useful tool that speeds up work and enhances creativity. But other copywriters, especially those early in their careers, say AI is making it harder to find jobs.</span><br><span class="line">But some have also noticed a new type of gig is emerging, one that pays a lot less: fixing the robots&#x27; shoddy writing.</span><br><span class="line">&quot;We&#x27;re adding the human touch, but that often requires a deep, developmental edit on a piece of writing,&quot; says Catrina Cowart, a copywriter based in Lexington, Kentucky, US, who&#x27;s done work editing AI text.&quot;The grammar and word choice just sound weird. You&#x27;re always cutting out flowery words like &#x27;therefore&#x27; and &#x27;nevertheless&#x27; that don&#x27;t fit in casual writing. Plus, you have to fact-check the whole thing because AI just makes things up, which takes forever because it&#x27;s not just big ideas. AI hallucinates these flippant little things in throwaway lines that you&#x27;d never notice.&quot;</span><br><span class="line">Cowart says the AI-humanising often takes longer than writing a piece from scratch, but the pay is worse. &quot;On the job platforms where you find this work, it usually maxes out around 10 cents (Â£0.08) a word. But that&#x27;s when you&#x27;re writing, This is considered an editing job, so typically you&#x27;re only getting one to five cents (Â£0.008-Â£0.04) a word,&quot; she says.</span><br><span class="line">&quot;It&#x27;s tedious, horrible work, and they pay you next to nothing for it,&quot; Cowart says.</span><br><span class="line">Other industries have seen similar examples of lower-paid human beings quietly powering the machines, from stepping in to help with automated ordering systems to labelling the images used to train AI vision systems in the first place.</span><br><span class="line">It&#x27;s been an incredible co-creative partner â€“ Rebecca Dugas</span><br><span class="line">But for some in the copywriting world, whether the arrival of AI is a good or bad thing depends on how people approach it, and how far along people are in their careers. Some writers say working the tools into their creative process can even improve their work.</span><br><span class="line">The American Writers and Artists Institute (AWAI), an organisation that offers training and resources for freelance writers, hosts a variety of courses on artificial intelligence for its members. AWAI president Rebecca Matter says AI classes are now the institute&#x27;s most popular offering by far. &quot;It&#x27;s an incredible tool,&quot; Matter says. &quot;For people who make copywriting a career, the risk isn&#x27;t AI taking their jobs, it&#x27;s that they have to adapt. That can be uncomfortable, but I think it&#x27;s a huge opportunity.&quot;</span><br><span class="line">Matter says the transition to the AI world has been smooth for most of the writers she knows. In fact, it&#x27;s become such an inherent part of the copywriting process that many writers now add personal &quot;AI policies&quot; to their professional websites to explain how they use the technology.</span><br><span class="line">Rebecca Dugas, a copywriter with nine years of experience, says AI has been a &quot;godsend&quot; that lets her turn out the same high-quality work in a fraction of the time.</span><br><span class="line">&quot;I use AI whenever my clients are comfortable with it,&quot; she says. &quot;Whether it&#x27;s brainstorming, market research, reworking paragraphs when I&#x27;m banging my head against the wall, it&#x27;s been an incredible co-creative partner.&quot;</span><br><span class="line">AI makes life easier for some writers, but for others, it adds insult to injury (Serenity Strull/BBC/Getty Images)</span><br><span class="line">AI makes life easier for some writers, but for others, it adds insult to injury (Serenity Strull/BBC/Getty Images)</span><br><span class="line">But Dugas understands that clients may have reservations about the technology. Her own AI policy explains that Dugas is happy to forgo AI for those who prefer it â€“ but you can expect to pay more. The extra time and mental energy required means her AI-free projects come with a higher price tag.</span><br><span class="line">As AI gets better, Dugas expects that some businesses will turn to ChatGPT and other tools for their writing needs instead of hiring human beings. &quot;But I think even now we&#x27;re getting to the point where companies are realising that if you don&#x27;t understand copywriting, you can&#x27;t judge the effectiveness of what the AI produces,&quot; she says. According to Dugas, that means there will always be well-paying work for talented, established writers.</span><br><span class="line">Miller&#x27;s time humanising AI ended abruptly</span><br><span class="line">But copywriters on the lower end of the career spectrum may not be so lucky. Today, many in that position find themselves in the middle of a distinctly modern set of contradictions.</span><br><span class="line">A great deal of copywriting work comes from website owners who want articles that will generate more traffic from Google. However, Google made a number of dramatic announcements in the last year about its effort to remove &quot;unhelpful&quot; content from search results. That sparked fears that the tech giant may penalise websites that host AI-generated content.  Google maintains that AI-writing is fine if the content is high quality, but these reassurances haven&#x27;t dissuaded concerns.</span><br><span class="line">As a result, it&#x27;s become a common practice in some parts of the copywriting world to run text through AI detection software. Over the last year, a wave of writers even say they&#x27;ve lost jobs over false accusations from AI detectors.</span><br><span class="line">According to Cowart, many of the same freelance writing platforms that have AI detection software in place are simultaneously hiring people to edit content produced by chatbots. That means in some corners of the copywriting ecosystem, almost everything revolves around efforts to avoid the appearance of artificial intelligence.</span><br><span class="line">&quot;They&#x27;re selling AI content and paying you to fix it, and at the same time they&#x27;re sending you emails about how to write like a human so you don&#x27;t trigger their AI detector,&quot; Cowart says. &quot;It&#x27;s so insulting.&quot; Worse, the detectors are regularly updated to keep up with ongoing changes from the companies who make AI chatbots, which means the rules about what might get your writing flagged as AI constantly shift. &quot;It&#x27;s frustrating, because there are a million ways to say the same thing in English, but which one is more human? I don&#x27;t like the guessing,&quot; she says.</span><br><span class="line">Miller&#x27;s time humanising AI ended abruptly. After months of repetitive editing work, He got called in to an unexpected meeting. On 5 April 2024, the same day a historic earthquake shook his hometown of New York, he was laid off. The company decided that Miller was just another unnecessary layer of human intervention.</span><br><span class="line">&quot;I more or less got automated out of a job,&quot; Miller says.</span><br><span class="line">You might also like:</span><br><span class="line"></span><br><span class="line">â€¢ This is what happens when you ask an algorithm for relationship advice</span><br><span class="line"></span><br><span class="line">â€¢ How AI is testing the boundaries of human intelligence</span><br><span class="line"></span><br><span class="line">â€¢ The chatbots that say they can feel emotions</span><br><span class="line"></span><br><span class="line">Fortunately, it wasn&#x27;t long before Miller found a new, if rather ironic, opportunity. He got a job at Undetectable AI, a technology company that builds software to make AI writing harder to identify. In other words, Miller is helping a company that&#x27;s using AI to do the work he was forced into after AI took his job in the first place.</span><br><span class="line">Bars Juhasz, chief technology officer of Undetectable AI, says tools like the ones his company produces are certain to have some negative effects on the labour market, but he&#x27;s optimistic about the future of work. &quot;When the automobile was first introduced in an era of horses and carts, people reacted like this was the end of days. But society always adapts,&quot; Juhasz says. &quot;I think we&#x27;re going to see a lot of jobs being replaced, and freelancers will be the hardest hit. I do feel for them. But these people who are getting paid to humanise AI are fantastic opportunists. Sure, it&#x27;s not a great job, but they have effectively recognised a new seat at a moment when we&#x27;re redefining the idea of productivity. People who can learn to work with the technology are going to be OK.&quot;</span><br><span class="line">Miller doesn&#x27;t look back fondly on his time in the AI-humanisation mines. &quot;I contributed to a lot of the garbage that&#x27;s filling the internet and destroying it,&quot; he says. &quot;Nobody was even reading this stuff by the time I left because it&#x27;s just trash.&quot; Ultimately, Miller assumes the company will just take down the AI articles he worked on. &quot;It&#x27;ll be like it never even happened.&quot;</span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">https://huggingface.co/papers/2406.10323</span><br><span class="line">New Instruction dataset! GenQA consists of over 10M cleaned and deduplicated instructions. GenQA used generator prompts to create a diverse list of topics (Generate 30 topics on X) and then randomly select one to generate questions and answers or dialogue pairs. It doesnâ€™t require any human oversight. ğŸ‘€</span><br><span class="line">TL;DR;</span><br><span class="line">ğŸ’» 10M samples split into 9 domains including, code, math, writingâ€¦</span><br><span class="line">âš–ï¸ Rebalanced version with 6.47M samples, performs better than raw (10M)</span><br><span class="line">ğŸ¤– Used Gemini Pro 1.0 for data generation</span><br><span class="line">ğŸ† Outperforms UltraChat and WizardLM on AlpacaEval 2.0 and MT-Bench</span><br><span class="line">ğŸ“„ Paper explores best ways to create a diverse set of topics</span><br><span class="line">âœ¨ Adding suffix â€œbe creativeâ€, â€œbe smartâ€ increased diversity</span><br><span class="line">ğŸ”“ Dataset, generator prompts, and model checkpoints released</span><br><span class="line"></span><br><span class="line">GenQA: Generating Millions of Instructions from a Handful of Prompts</span><br><span class="line">Published on Jun 15</span><br><span class="line">Authors:</span><br><span class="line">Jiuhai Chen</span><br><span class="line">,</span><br><span class="line">Rifaa Qadri</span><br><span class="line">,</span><br><span class="line">Yuxin Wen</span><br><span class="line">,</span><br><span class="line"></span><br><span class="line">Neel Jain</span><br><span class="line">,</span><br><span class="line">John Kirchenbauer</span><br><span class="line">,</span><br><span class="line">Tianyi Zhou</span><br><span class="line">,</span><br><span class="line">Tom Goldstein</span><br><span class="line">Abstract</span><br><span class="line">Most public instruction finetuning datasets are relatively small compared to the closed source datasets used to train industry models. To study questions about finetuning at scale, such as curricula and learning rate cooldown schedules, there is a need for industrial-scale datasets. However, this scale necessitates a data generation process that is almost entirely automated. In this work, we study methods for generating large instruction datasets from a single prompt. With little human oversight, we get LLMs to write diverse sets of instruction examples ranging from simple completion tasks to complex multi-turn dialogs across a variety of subject areas. When finetuning a Llama-3 8B base model, our dataset meets or exceeds both WizardLM and Ultrachat on both knowledge-intensive leaderboard tasks as well as conversational evaluations. We release our dataset, the &quot;generator&quot; prompts that created it, and our finetuned model checkpoints.</span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">https://huggingface.co/papers/2402.03300</span><br><span class="line">What is Group Relative Policy Optimization (GRPO)? Deepseek Coder v2 is the best open Code LLM rivaling GPT-4 on coding tasks. As part of the technical report, GRPO is mentioned as RLHF method, but what is it? ğŸ¤”</span><br><span class="line">GRPO was introduced in the DeepSeekMath Paper earlier this year and is method in designed to improve improve mathematical reasoning capabilities with less memory consumption.</span><br><span class="line">Implementation</span><br><span class="line">1ï¸âƒ£ Generate multiple outputs for each input question using the current Policy</span><br><span class="line">2ï¸âƒ£ Score these outputs using a reward model</span><br><span class="line">3ï¸âƒ£ Average the rewards and use it as a baseline to compute the advantages</span><br><span class="line">4ï¸âƒ£ Update the Policy to maximize the GRPO objective, which includes the advantages and a KL term</span><br><span class="line">Insights</span><br><span class="line">ğŸ’¡ GRPO doesn&#x27;t need value function model, reducing memory and complexity</span><br><span class="line">ğŸ”—  GPRO adds the KL term directly to the loss rather than in the reward</span><br><span class="line">ğŸ“ˆ GPRO improved GSM8K and MATH ~5%</span><br><span class="line">ğŸ‘‰ GPRO looks similar to RLOO method (available in TRL)</span><br><span class="line">ğŸ” Used Iterative Approach to train new Reward Models</span><br><span class="line">ğŸ“Š RL data consisted of 144k CoT prompts from SFT dataset</span><br><span class="line">ğŸ§  Reward Model was trained using â€œMath-Shepherdâ€ process</span><br><span class="line">RL is â€œboosting the correct response from TopK rather than the enhancement of fundamental capabilities.â€</span><br><span class="line"></span><br><span class="line">DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models</span><br><span class="line">Published on Feb 6</span><br><span class="line">Â·</span><br><span class="line">Submitted by</span><br><span class="line">akhaliq</span><br><span class="line">on Feb 6</span><br><span class="line">#1 Paper of the day</span><br><span class="line">Authors:</span><br><span class="line"></span><br><span class="line">Zhihong Shao</span><br><span class="line">,</span><br><span class="line"></span><br><span class="line">Peiyi Wang</span><br><span class="line">,</span><br><span class="line"></span><br><span class="line">Qihao Zhu</span><br><span class="line">,</span><br><span class="line">Runxin Xu</span><br><span class="line">,</span><br><span class="line"></span><br><span class="line">Junxiao Song</span><br><span class="line">,</span><br><span class="line">Mingchuan Zhang</span><br><span class="line">,</span><br><span class="line">Y. K. Li</span><br><span class="line">,</span><br><span class="line">Y. Wu</span><br><span class="line">,</span><br><span class="line"></span><br><span class="line">Daya Guo</span><br><span class="line">Abstract</span><br><span class="line">Mathematical reasoning poses a significant challenge for language models due to its complex and structured nature. In this paper, we introduce DeepSeekMath 7B, which continues pre-training DeepSeek-Coder-Base-v1.5 7B with 120B math-related tokens sourced from Common Crawl, together with natural language and code data. DeepSeekMath 7B has achieved an impressive score of 51.7% on the competition-level MATH benchmark without relying on external toolkits and voting techniques, approaching the performance level of Gemini-Ultra and GPT-4. Self-consistency over 64 samples from DeepSeekMath 7B achieves 60.9% on MATH. The mathematical reasoning capability of DeepSeekMath is attributed to two key factors: First, we harness the significant potential of publicly available web data through a meticulously engineered data selection pipeline. Second, we introduce Group Relative Policy Optimization (GRPO), a variant of Proximal Policy Optimization (PPO), that enhances mathematical reasoning abilities while concurrently optimizing the memory usage of PPO.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">https://huggingface.co/papers/2406.13542</span><br><span class="line">Generate verifiable instruction following data with AutoIF! AutoIF validates instructions by following the generated code to check their correctness. In self-alignment and strong-to-weak distillation settings, it can improve models up to 15% on IFEval ğŸ‘€</span><br><span class="line">Implementation</span><br><span class="line">1ï¸âƒ£ Create a set of hand-written seed instructions with single atomic constraints.</span><br><span class="line">2ï¸âƒ£ Perform self-instruct to generate more instructions.</span><br><span class="line">3ï¸âƒ£ Generate verification functions and test cases for each instruction using LLM.</span><br><span class="line">4ï¸âƒ£ Back-translate verification functions into instructions to ensure semantic consistency.</span><br><span class="line">5ï¸âƒ£ Augment queries by concatenating with ShareGPT samples.</span><br><span class="line">6ï¸âƒ£ Generate multiple responses for each query &amp; verify responses using functions.</span><br><span class="line">7ï¸âƒ£ Score instructions, queries, and responses and filter out low-scoring samples.</span><br><span class="line">Insights</span><br><span class="line">ğŸš€ Using GPT-4 as supervision improves performance ~15% on IFEval for Qwen2 7B.</span><br><span class="line">ğŸ“ˆ On-policy Learning is more effective: Online DPO &gt; Offline DPO.</span><br><span class="line">ğŸ“Š Larger models relatively improve more.</span><br><span class="line">ğŸ” Used n-gram probing for IFEval decontamination.</span><br><span class="line">ğŸŒŸ Llama 3 70B first open LLM to achieve 90% on loose instruction in IFEval.</span><br><span class="line">ğŸ˜” Code and scripts released, dataset not.</span><br><span class="line"></span><br><span class="line">Self-play with Execution Feedback: Improving Instruction-following Capabilities of Large Language Models</span><br><span class="line">Published on Jun 19</span><br><span class="line">Â·</span><br><span class="line">Submitted by</span><br><span class="line">davanstrien</span><br><span class="line">on Jun 21</span><br><span class="line">Authors:</span><br><span class="line"></span><br><span class="line">Guanting Dong</span><br><span class="line">,</span><br><span class="line"></span><br><span class="line">Keming Lu</span><br><span class="line">,</span><br><span class="line"></span><br><span class="line">Chengpeng Li</span><br><span class="line">,</span><br><span class="line">Tingyu Xia</span><br><span class="line">,</span><br><span class="line"></span><br><span class="line">Bowen Yu</span><br><span class="line">,</span><br><span class="line">Chang Zhou</span><br><span class="line">,</span><br><span class="line"></span><br><span class="line">Jingren Zhou</span><br><span class="line">Abstract</span><br><span class="line">One core capability of large language models (LLMs) is to follow natural language instructions. However, the issue of automatically constructing high-quality training data to enhance the complex instruction-following abilities of LLMs without manual annotation remains unresolved. In this paper, we introduce AutoIF, the first scalable and reliable method for automatically generating instruction-following training data. AutoIF transforms the validation of instruction-following data quality into code verification, requiring LLMs to generate instructions, the corresponding code to check the correctness of the instruction responses, and unit test samples to verify the code&#x27;s correctness. Then, execution feedback-based rejection sampling can generate data for Supervised Fine-Tuning (SFT) and Reinforcement Learning from Human Feedback (RLHF) training. AutoIF achieves significant improvements across three training algorithms, SFT, Offline DPO, and Online DPO, when applied to the top open-source LLMs, Qwen2 and LLaMA3, in self-alignment and strong-to-weak distillation settings. Our code is publicly available at https://github.com/QwenLM/AutoIF.</span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">https://myniuuu.github.io/MOFA_Video/</span><br><span class="line">[Submitted on 30 May 2024 (v1), last revised 2 Jun 2024 (this version, v2)]</span><br><span class="line">MOFA-Video: Controllable Image Animation via Generative Motion Field Adaptions in Frozen Image-to-Video Diffusion Model</span><br><span class="line">Muyao Niu, Xiaodong Cun, Xintao Wang, Yong Zhang, Ying Shan, Yinqiang Zheng</span><br><span class="line">We present MOFA-Video, an advanced controllable image animation method that generates video from the given image using various additional controllable signals (such as human landmarks reference, manual trajectories, and another even provided video) or their combinations. This is different from previous methods which only can work on a specific motion domain or show weak control abilities with diffusion prior. To achieve our goal, we design several domain-aware motion field adapters (\ie, MOFA-Adapters) to control the generated motions in the video generation pipeline. For MOFA-Adapters, we consider the temporal motion consistency of the video and generate the dense motion flow from the given sparse control conditions first, and then, the multi-scale features of the given image are wrapped as a guided feature for stable video diffusion generation. We naively train two motion adapters for the manual trajectories and the human landmarks individually since they both contain sparse information about the control. After training, the MOFA-Adapters in different domains can also work together for more controllable video generation. Project Page: this https URL</span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">https://github.com/Camb-ai/MARS5-TTS</span><br><span class="line">MARS5 TTS: Open Source Text to Speech with insane prosodic control! ğŸ”¥</span><br><span class="line">&gt; Voice cloning with less than 5 seconds of audio</span><br><span class="line">&gt; Two stage Auto-Regressive (750M) + Non-Auto Regressive (450M) model architecture</span><br><span class="line">&gt; Used BPE tokenizer to enable control over punctuations, pauses, stops etc.</span><br><span class="line">&gt; AR model predicts L0 coarse tokens, refined further by the NAR DDPM model followed by the vocoder</span><br><span class="line"></span><br><span class="line">Approach</span><br><span class="line">This is the repo for the MARS5 English speech model (TTS) from CAMB.AI.</span><br><span class="line"></span><br><span class="line">The model follows a two-stage AR-NAR pipeline with a distinctively novel NAR component (see more info in the Architecture).</span><br><span class="line"></span><br><span class="line">With just 5 seconds of audio and a snippet of text, MARS5 can generate speech even for prosodically hard and diverse scenarios like sports commentary, anime and more. Check out our demo:</span><br><span class="line"></span><br><span class="line"> intro_vid_camb.mp4</span><br><span class="line">Watch full video here: Youtube</span><br><span class="line"></span><br><span class="line">Mars 5 simplified diagram</span><br><span class="line"></span><br><span class="line">Figure: The high-level architecture flow of MARS5. Given text and a reference audio, coarse (L0) encodec speech features are obtained through an autoregressive transformer model. Then, the text, reference, and coarse features are refined in a multinomial DDPM model to produce the remaining encodec codebook values. The output of the DDPM is then vocoded to produce the final audio.</span><br><span class="line"></span><br><span class="line">Because the model is trained on raw audio together with byte-pair-encoded text, it can be steered with things like punctuation and capitalization. E.g. To add a pause, add a comma to that part in the transcript. Or, to emphasize a word, put it in capital letters in the transcript. This enables a fairly natural way for guiding the prosody of the generated output.</span><br><span class="line"></span><br><span class="line">Speaker identity is specified using an audio reference file between 2-12 seconds, with lengths around 6s giving optimal results. Further, by providing the transcript of the reference, MARS5 enables one to do a &#x27;deep clone&#x27; which improves the quality of the cloning and output, at the cost of taking a bit longer to produce the audio. For more details on this and other performance and model details, please see the</span><br><span class="line"></span><br></pre></td></tr></table></figure>

</details>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2024-06-25</span><i class="fa fa-tag"></i><a class="tag" href="/tags/AI-NEWS/" title="AI_NEWS">AI_NEWS </a></div></div></div></div><div class="share"><div class="evernote"><a class="fa fa-bookmark" href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank"></a></div><div class="twitter"><a class="fa fa-twitter" target="_blank" rel="noopener" href="http://twitter.com/home?status=,https://dongyoungkim2.github.io/2024/06/25/2024-6-25-AI-NEWS/,TECH BLOG  by Dongyoung Kim   Ph.D.,2024ë…„ 6ì›” 25ì¼ AI ì†Œì‹,;"></a></div></div><div class="pagination"><ul class="clearfix"><li class="next pagbuttons"><a class="btn" role="navigation" href="/2024/06/21/2024-6-21-AI-NEWS/" title="2024ë…„ 6ì›” 21ì¼ AI ì†Œì‹">Next</a></li></ul></div></div></div></div></div><script src="/js/jquery.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script></body></html>