<!DOCTYPE html><html lang="ko-KR"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author"><title>2024년 6월 28일 AI 소식 · TECH BLOG  by Dongyoung Kim   Ph.D.</title><meta name="description" content="Summary오늘의 AI 소식에서는 Google Research의 새로운 대형 언어 모델인 Gemma 2 출시, Meta의 Meta LLM Compiler 발표, OpenAI와 TIME의 전략적 콘텐츠 파트너십, OpenAI의 Voice Mode 업데이트, Anthro"><meta name="keywords"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><!-- Google tag (gtag.js)--><script async src="https://www.googletagmanager.com/gtag/js?id=G-Y36E4JYRDG"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-Y36E4JYRDG');</script><meta name="generator" content="Hexo 7.2.0"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:157px;"><h3 title=""><a href="/">TECH BLOG  by Dongyoung Kim   Ph.D.</a></h3></div></div><ul class="social-links"></ul><div class="footer"><a target="_blank" href="/"></a><div class="by_farbox"><a href="https://dykim.dev/" target="_blank">© Dongyoung Kim, Ph.D. </a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">Home</a></li><li><a href="/about">Curriculum Vitae</a></li><li><a href="/archives">Archive</a></li></div><div class="information"><div class="back_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"> </a></li></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>2024년 6월 28일 AI 소식</a></h3></div><div class="post-content"><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>오늘의 AI 소식에서는 Google Research의 새로운 대형 언어 모델인 Gemma 2 출시, Meta의 Meta LLM Compiler 발표, OpenAI와 TIME의 전략적 콘텐츠 파트너십, OpenAI의 Voice Mode 업데이트, Anthropic의 Claude 프로젝트 기능 도입, Hugging Face의 새로운 Open LLM Leaderboard, FineWeb 데이터셋 소개, 그리고 RAGFlow의 오픈 소스 RAG 엔진 출시 소식을 다룹니다.</p>
<h2 id="Google-Gemma-2-출시"><a href="#Google-Gemma-2-출시" class="headerlink" title="Google, Gemma 2 출시"></a>Google, Gemma 2 출시</h2><h3 id="구글-Gemma-2-출시"><a href="#구글-Gemma-2-출시" class="headerlink" title="구글, Gemma 2 출시"></a>구글, Gemma 2 출시</h3><p><a target="_blank" rel="noopener" href="https://huggingface.co/collections/google/gemma-2-release-667d6600fd5220e7b967f315">링크</a>, 2024년 6월 28일,<br>Google Research</p>
<ul>
<li>Gemma 2는 9B 및 27B 크기로 출시</li>
<li>27B 모델은 Meta Llama 3 70B와 성능이 비슷</li>
<li>13조 토큰으로 훈련된 27B 모델과 8조 토큰으로 훈련된 9B 모델</li>
<li>상업적 사용 가능</li>
<li>Hugging Face에서 사용 가능하며 Google Cloud로의 원클릭 배포 지원</li>
</ul>
<h2 id="Meta-Meta-LLM-Compiler-발표"><a href="#Meta-Meta-LLM-Compiler-발표" class="headerlink" title="Meta, Meta LLM Compiler 발표"></a>Meta, Meta LLM Compiler 발표</h2><h3 id="메타-Meta-LLM-Compiler-발표"><a href="#메타-Meta-LLM-Compiler-발표" class="headerlink" title="메타, Meta LLM Compiler 발표"></a>메타, Meta LLM Compiler 발표</h3><p><a target="_blank" rel="noopener" href="https://huggingface.co/collections/facebook/llm-compiler-667c5b05557fe99a9edd25cb">링크</a>, 2024년 6월 28일,<br>Meta</p>
<ul>
<li>Meta LLM Compiler는 코드 최적화 및 컴파일러 기능을 갖춘 모델</li>
<li>GPT-4를 능가하는 코드 크기 개선 및 디스어셈블리 성능</li>
<li>상업적 사용 허가</li>
<li>CodeLLaMa 기반으로 구축</li>
</ul>
<h2 id="OpenAI-TIME과-전략적-콘텐츠-파트너십-체결"><a href="#OpenAI-TIME과-전략적-콘텐츠-파트너십-체결" class="headerlink" title="OpenAI, TIME과 전략적 콘텐츠 파트너십 체결"></a>OpenAI, TIME과 전략적 콘텐츠 파트너십 체결</h2><h3 id="오픈AI-TIME과-전략적-콘텐츠-파트너십-체결"><a href="#오픈AI-TIME과-전략적-콘텐츠-파트너십-체결" class="headerlink" title="오픈AI, TIME과 전략적 콘텐츠 파트너십 체결"></a>오픈AI, TIME과 전략적 콘텐츠 파트너십 체결</h3><p><a target="_blank" rel="noopener" href="https://openai.com/index/strategic-content-partnership-with-time/">링크</a>, 2024년 6월 27일,<br>OpenAI</p>
<ul>
<li>TIME의 101년 간의 아카이브 콘텐츠에 접근 가능</li>
<li>OpenAI의 제품에서 TIME 콘텐츠를 활용하여 사용자 문의에 응답</li>
<li>TIME의 정확하고 신뢰할 수 있는 정보 제공 확대를 목표로 함</li>
<li>OpenAI 기술을 활용해 새로운 제품 개발 가능</li>
</ul>
<h2 id="OpenAI-Voice-Mode-업데이트"><a href="#OpenAI-Voice-Mode-업데이트" class="headerlink" title="OpenAI, Voice Mode 업데이트"></a>OpenAI, Voice Mode 업데이트</h2><h3 id="오픈AI-Voice-Mode-업데이트"><a href="#오픈AI-Voice-Mode-업데이트" class="headerlink" title="오픈AI, Voice Mode 업데이트"></a>오픈AI, Voice Mode 업데이트</h3><p>2024년 6월 26일,<br>OpenAI</p>
<ul>
<li>ChatGPT의 고급 음성 모드 업데이트 연기</li>
<li>모델의 감정 및 비언어적 신호 인식 능력 향상 작업 중</li>
<li>사용자 경험 개선 및 인프라 확장 준비 중</li>
<li>알파 테스트를 소수 사용자 그룹과 시작하여 피드백 수집 예정</li>
</ul>
<h2 id="Anthropic-Claude-프로젝트-기능-도입"><a href="#Anthropic-Claude-프로젝트-기능-도입" class="headerlink" title="Anthropic, Claude 프로젝트 기능 도입"></a>Anthropic, Claude 프로젝트 기능 도입</h2><h3 id="앤트로픽-Claude-프로젝트-기능-도입"><a href="#앤트로픽-Claude-프로젝트-기능-도입" class="headerlink" title="앤트로픽, Claude 프로젝트 기능 도입"></a>앤트로픽, Claude 프로젝트 기능 도입</h3><p><a target="_blank" rel="noopener" href="https://www.anthropic.com/news/projects">링크</a>, 2024년 6월 26일,<br>Anthropic</p>
<ul>
<li>Claude.ai Pro 및 Team 사용자는 이제 프로젝트로 채팅을 구성 가능</li>
<li>각 프로젝트는 최대 20만 단어의 문맥 창을 제공</li>
<li>사용자는 맞춤형 지침을 정의하여 Claude의 응답을 조정 가능</li>
<li>공유된 프로젝트 활동 피드를 통해 팀원 간 협력 강화</li>
</ul>
<h2 id="Hugging-Face-새로운-Open-LLM-Leaderboard-출시"><a href="#Hugging-Face-새로운-Open-LLM-Leaderboard-출시" class="headerlink" title="Hugging Face, 새로운 Open LLM Leaderboard 출시"></a>Hugging Face, 새로운 Open LLM Leaderboard 출시</h2><h3 id="허깅페이스-새로운-Open-LLM-Leaderboard-출시"><a href="#허깅페이스-새로운-Open-LLM-Leaderboard-출시" class="headerlink" title="허깅페이스, 새로운 Open LLM Leaderboard 출시"></a>허깅페이스, 새로운 Open LLM Leaderboard 출시</h3><p><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard">링크</a>, 2024년 6월 26일,<br>Hugging Face</p>
<ul>
<li>MMLU-Pro, GPQA, MuSR, MATH, IFEval 및 BBH 등의 새로운 벤치마크 추가</li>
<li>향상된 순위 시스템 및 커뮤니티 투표 시스템 도입</li>
<li>Qwen2 72B Instruct 모델이 Meta Llama 3 70B Instruct를 능가</li>
</ul>
<h2 id="FineWeb-데이터셋-발표"><a href="#FineWeb-데이터셋-발표" class="headerlink" title="FineWeb 데이터셋 발표"></a>FineWeb 데이터셋 발표</h2><h3 id="FineWeb-데이터셋-발표-1"><a href="#FineWeb-데이터셋-발표-1" class="headerlink" title="FineWeb 데이터셋 발표"></a>FineWeb 데이터셋 발표</h3><p><a target="_blank" rel="noopener" href="https://huggingface.co/papers/2406.17557">링크</a>, 2024년 6월 25일,<br>Hugging Face</p>
<ul>
<li>96개의 Common Crawl 스냅샷에서 추출된 15조 토큰 데이터셋</li>
<li>고품질의 사전 훈련 데이터셋으로 LLM 성능 향상</li>
<li>FineWeb-Edu: 교육 텍스트로 구성된 1.3조 토큰 컬렉션</li>
<li>데이터 큐레이션 코드베이스와 모델 공개</li>
</ul>
<h2 id="RAGFlow의-오픈-소스-RAG-엔진-출시"><a href="#RAGFlow의-오픈-소스-RAG-엔진-출시" class="headerlink" title="RAGFlow의 오픈 소스 RAG 엔진 출시"></a>RAGFlow의 오픈 소스 RAG 엔진 출시</h2><h3 id="RAGFlow의-오픈-소스-RAG-엔진-출시-1"><a href="#RAGFlow의-오픈-소스-RAG-엔진-출시-1" class="headerlink" title="RAGFlow의 오픈 소스 RAG 엔진 출시"></a>RAGFlow의 오픈 소스 RAG 엔진 출시</h3><p><a target="_blank" rel="noopener" href="https://github.com/infiniflow/ragflow">링크</a>, 2024년 6월 26일,<br>RAGFlow</p>
<ul>
<li>복잡한 형식의 데이터를 이해하는 능력을 갖춘 지식 추출 기능</li>
<li>다양한 템플릿을 제공하는 템플릿 기반 청킹</li>
<li>인용 근거가 뚜렷한 신뢰할 수 있는 응답 제공</li>
<li>다양한 데이터 소스와 호환 가능</li>
<li>직관적인 API를 통해 비즈니스에 원활하게 통합 가능</li>
</ul>
<details>
  <summary>Sources</summary>

<p>This GPT assists users by creating a detailed daily newspaper in Korean based on provided links. It follows these steps: read the content, summarize each content with detailed points, and write a report. The report format is:</p>
<h1 id="today’s-date-in-년-월-일-AI-소식"><a href="#today’s-date-in-년-월-일-AI-소식" class="headerlink" title="(today’s date in 년 월 일) AI 소식,"></a>(today’s date in 년 월 일) AI 소식,</h1><h2 id="Summary-1"><a href="#Summary-1" class="headerlink" title="Summary"></a>Summary</h2><p>(overall short summary, make summary with good details. for Summary section, explain the details starting with company name, e.g. OpenAI에서는 ~~~를 발표하였습니다.)</p>
<h2 id="Title"><a href="#Title" class="headerlink" title="Title,"></a>Title,</h2><h3 id="한글제목"><a href="#한글제목" class="headerlink" title="한글제목"></a>한글제목</h3><p><a href="link">링크</a>, date,<br>company name</p>
<ul>
<li>detailed summary1, (개조식 문체 사용)</li>
<li>detailed summary2, (개조식 문체 사용)<br>…</li>
<li>detailed summary N, (개조식 문체 사용)</li>
</ul>
<h2 id="Title-1"><a href="#Title-1" class="headerlink" title="Title,"></a>Title,</h2><h3 id="한글제목-1"><a href="#한글제목-1" class="headerlink" title="한글제목"></a>한글제목</h3><p><a href="link">링크</a>, date,<br>company name</p>
<ul>
<li>detailed summary1, (개조식 문체 사용)</li>
<li>detailed summary2, (개조식 문체 사용)<br>…</li>
<li>detailed summary N, (개조식 문체 사용)<br>…</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br></pre></td><td class="code"><pre><span class="line">###</span><br><span class="line">https://huggingface.co/collections/google/gemma-2-release-667d6600fd5220e7b967f315</span><br><span class="line">June 28, 2024</span><br><span class="line">Google Research</span><br><span class="line">Gemma 2 released! Google just released the next iteration of its open LLM! Gemma 2 comes in two sizes, 9B &amp; 27B, trained on 13T tokens. Gemma 2 27B approaches Meta Llama 3 70B performance! First Chatbot Arena evals place Gemma2 27B around Anthropic Claude 3 Sonnet, Llama 3 70B, and OpenAI GPT-4. 🤯</span><br><span class="line">What&#x27;s new with Gemma 2:</span><br><span class="line">🧮 9B &amp; 27B Instruction and base version with 8192 context window</span><br><span class="line">🔠 Trained on 13T tokens (27B) and 8T tokens (9B)</span><br><span class="line">🆕 Sliding window attention, logit soft-capping and Grouped-Query Attention (GQA)</span><br><span class="line">🥇 9B scores 71.3 MMLU; 52.8 AGIEval; 40.2 HumanEval</span><br><span class="line">🏆 27B scores 75.2 MMLU; 55.1 AGIEval; 51.8 HumanEval</span><br><span class="line">✅ Commercial use allowed</span><br><span class="line">🧬 Used SFT, Distillation, RLHF &amp; Model Merging.</span><br><span class="line">🧠 Trained on Google TPUv5e</span><br><span class="line">🤗 Available on Hugging Face</span><br><span class="line">🔜 1-click deployment to Google Cloud from Hugging Face</span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">https://huggingface.co/collections/facebook/llm-compiler-667c5b05557fe99a9edd25cb</span><br><span class="line">June 28, 2024</span><br><span class="line">META</span><br><span class="line">Today we’re releasing Meta LLM Compiler, a family of models built on Meta Code Llama with additional code optimization and compiler capabilities. The models achieve state-of-the-art results on optimization of code size and disassembly tasks.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">LLM Compiler can emulate the compiler, predict optimal passes for code size, and disassemble code. It can be fine-tuned for new optimizations and compiler tasks. This work shows that AI is learning to optimize code and can assist compiler experts in identifying opportunities to apply optimizations. We believe this work could have an impact ranging from use in optimization for individual developer environments to inclusion in a compiler such as LLVM.</span><br><span class="line">We’re releasing LLM Compiler 7B &amp; 13B models under a permissive license for both research and commercial use in the hopes of making it easier for developers and researchers alike to leverage this in their work and carry forward new research in this highly impactful space.</span><br><span class="line"></span><br><span class="line">WAIT, it&#x27;s not over; Meta just dropped the LLM Compiler! 🧑‍💻</span><br><span class="line">&gt; Beats GPT-4 on code size improvement and disassembly</span><br><span class="line">&gt; Achieves 77% of the optimising potential of an autotuning search and 45% disassembly round trip 🔥</span><br><span class="line">&gt; Built on top of CodeLLaMa with improved code optimisation and compiler reasoning.</span><br><span class="line">&gt; Allows commercial use</span><br><span class="line">Two model types:</span><br><span class="line">&gt; LLM Compiler: the foundational models, pre-trained on over 500B tokens of LLVM-IR, x86_84, ARM, and CUDA assembly codes and trained to predict the effect of LLVM optimisations</span><br><span class="line">&gt;LLM Compiler FTD, which is further fine-tuned to predict the best optimisations for code in LLVM assembly to reduce code size and disassemble assembly code to LLVM-IR</span><br><span class="line">&gt; Perfectly emulating the compiler 20% of the time ⚡</span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">https://openai.com/index/strategic-content-partnership-with-time/</span><br><span class="line">June 27, 2024</span><br><span class="line">OpenAI</span><br><span class="line">Strategic Content Partnership with TIME</span><br><span class="line">New access to current and historic content from TIME&#x27;s extensive archives from the last 101 years to enhance OpenAI products and display in response to user inquiries.</span><br><span class="line"></span><br><span class="line">Time &gt; Hero &gt; Media &gt; Asset</span><br><span class="line">Today, TIME and OpenAI announced a multi-year content deal and strategic partnership to bring TIME&#x27;s trusted journalism to OpenAI’s products, including ChatGPT.</span><br><span class="line"></span><br><span class="line">Through this collaboration, OpenAI will gain access to current and historic content from TIME&#x27;s extensive archives from the last 101 years to enhance its products and display in response to user inquiries—featuring a citation and link back to the original source on Time.com. The new partnership furthers TIME’s commitment to expanding global access to accurate and trusted information.</span><br><span class="line"></span><br><span class="line">&quot;Throughout our 101-year history, TIME has embraced innovation to ensure that the delivery of our trusted journalism evolves alongside technology,&quot; said TIME Chief Operating Officer Mark Howard.  &quot;This partnership with OpenAI advances our mission to expand access to trusted information globally as we continue to embrace innovative new ways of bringing TIME’s journalism to audiences globally.”</span><br><span class="line"></span><br><span class="line">“We’re partnering with TIME to make it easier for people to access news content through our AI tools, and to support reputable journalism by providing proper attribution to original sources,” said Brad Lightcap, Chief Operating Officer of OpenAI.</span><br><span class="line"></span><br><span class="line">The partnership will also enable TIME to gain access to OpenAI&#x27;s technology to develop new products for its audiences, along with the opportunity to provide vital feedback and share practical applications to refine and enhance the delivery of journalism in ChatGPT and other OpenAI products and shape the future of news experiences.</span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">OpenAI</span><br><span class="line">June 26, 2024</span><br><span class="line">We&#x27;re sharing an update on the advanced Voice Mode we demoed during our Spring Update, which we remain very excited about:</span><br><span class="line">We had planned to start rolling this out in alpha to a small group of ChatGPT Plus users in late June, but need one more month to reach our bar to launch. For example, we’re improving the model’s ability to detect and refuse certain content. We’re also working on improving the user experience and preparing our infrastructure to scale to millions while maintaining real-time responses.</span><br><span class="line">As part of our iterative deployment strategy, we&#x27;ll start the alpha with a small group of users to gather feedback and expand based on what we learn. We are planning for all Plus users to have access in the fall. Exact timelines depend on meeting our high safety and reliability bar. We are also working on rolling out the new video and screen sharing capabilities we demoed separately, and will keep you posted on that timeline.</span><br><span class="line">ChatGPT’s advanced Voice Mode can understand and respond with emotions and non-verbal cues, moving us closer to real-time, natural conversations with AI. Our mission is to bring these new experiences to you thoughtfully.</span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">https://www.anthropic.com/news/projects</span><br><span class="line">Collaborate with Claude on Projects</span><br><span class="line">2024년 6월 26일</span><br><span class="line">Anthorphic</span><br><span class="line">●</span><br><span class="line">3 min read</span><br><span class="line">Illustration of individuals collaborating around Claude logo</span><br><span class="line">Our vision for Claude has always been to create AI systems that work alongside people and meaningfully enhance their workflows. As a step in this direction, Claude.ai Pro and Team users can now organize their chats into Projects, bringing together curated sets of knowledge and chat activity in one place—with the ability to make their best chats with Claude viewable by teammates. With this new functionality, Claude can enable idea generation, more strategic decision-making, and exceptional results.</span><br><span class="line"></span><br><span class="line">Projects are available on Claude.ai for all Pro and Team customers, and can be powered by Claude 3.5 Sonnet, our latest release which outperforms its peers on a wide variety of benchmarks. Each project includes a 200K context window, the equivalent of a 500-page book, so users can add all of the relevant documents, code, and insights to enhance Claude’s effectiveness.</span><br><span class="line"></span><br><span class="line">Avoid the cold start problem</span><br><span class="line">Projects allow you to ground Claude’s outputs in your internal knowledge—be it style guides, codebases, interview transcripts, or past work. This added context enables Claude to provide expert assistance across tasks, from writing emails like your marketing team to writing SQL queries like a data analyst.</span><br><span class="line"></span><br><span class="line">App screen showing a user uploading docs to Claude.ai</span><br><span class="line">In addition, you can define custom instructions for each Project to further tailor Claude’s responses, including instructing Claude to use a more formal tone or answer questions from the perspective of a specific role or industry. With Projects, you can get started much faster and extend your skills further for any task.</span><br><span class="line"></span><br><span class="line">App screen showing custom instructions</span><br><span class="line">Create side-by-side with Claude</span><br><span class="line">Artifacts help you better work with Claude by helping you see, edit, and build with Claude. Simply ask Claude to generate content like code snippets, text documents, graphics, diagrams, or website designs, and Artifacts appear in a dedicated window alongside your conversation.</span><br><span class="line"></span><br><span class="line">Artifacts especially enhance Claude’s coding capabilities for developers, offering a larger code window and live previews for frontends that streamline reviews. Join the feature preview for Artifacts in Claude.ai via the account menu on the left-side panel.</span><br><span class="line"></span><br><span class="line">App screen that shows the Artifacts panel alongside the user chat</span><br><span class="line">Spark inspiration through sharing</span><br><span class="line">Claude Team users can also share snapshots of their best conversations with Claude into your team’s shared project activity feed. Activity feeds help each teammate get inspired around different ways to work with Claude, and helps the entire team uplevel their skills working with AI.</span><br><span class="line"></span><br><span class="line">App screen showing shared chats within a Project</span><br><span class="line">Sharing work products that were co-created with Claude can improve innovation in areas like product development and research, where bringing together organizational knowledge from across the company can produce higher-quality outputs.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Customer spotlight: North Highland</span><br><span class="line">At North Highland, a leading change and transformation consultancy, hundreds of employees across consulting, business development, and marketing teams use Claude to work better. From writing proposals to analyzing complex documents like 10-Ks, teams use Claude to enhance and scale their expert services.</span><br><span class="line"></span><br><span class="line">The Claude Team plan is transforming our way of working at North Highland. Claude is a truly exceptional writer that has helped our team complete content creation and analysis tasks up to 5x faster than before—turning what was once two weeks of writing and research into minutes of work. With Claude, we’re future-proofing our workforce, finding more excitement in daily challenges, and leaping into the future of AI-assisted collaboration and creativity.</span><br><span class="line">Luka Anic, Senior Director of Technical AI Program and Product Manager at North Highland</span><br><span class="line"></span><br><span class="line">The future of work with Claude</span><br><span class="line">These latest features around shared knowledge and collaboration integrate Claude into your existing team processes, enabling you to save time and elevate your work. By harnessing Claude’s accuracy and advanced coding and writing capabilities, Projects can amplify your team’s potential. Additionally, as part of our commitment to user privacy, any data or chats shared within Projects will not be used to train our generative models without a user’s explicit consent.</span><br><span class="line"></span><br><span class="line">In the coming months, we’ll continue making Claude easier to use while expanding the types of project knowledge you can bring to Claude via native integrations with popular applications and tools. We’re excited to see how your team works with Claude.</span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard</span><br><span class="line">Open LLM Leaderboard 2 released! Evaluating LLMs is not easy. Finding new ways to compare LLM fairly, transparently, and reproducibly is important! Benchmarks are not perfect, but they give us a first understanding of how well models perform and where their strengths are.</span><br><span class="line">What&#x27;s new?!</span><br><span class="line">📈 New benchmarks with MMLU-Pro, GPQA, MuSR, MATH, IFEval and BBH.</span><br><span class="line">📊 Improved ranking with normalized scores adjusted to baselines</span><br><span class="line">🏆 Qwen2 72B Instruct &gt; Meta Llama 3 70B Instruct &gt; Cohere Command R+</span><br><span class="line">⚡ Faster, simpler Interface with a new Gradio component.</span><br><span class="line">🛠️ Enhanced reproducibility with support for delta weights and chat templates</span><br><span class="line">⭐ Introduction of &quot;maintainer&#x27;s highlight&quot; and “community voting system”</span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">https://huggingface.co/papers/2406.17557</span><br><span class="line">The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale</span><br><span class="line">Published on Jun 25</span><br><span class="line">·</span><br><span class="line">Submitted by</span><br><span class="line">philschmid</span><br><span class="line">on Jun 26</span><br><span class="line">#1 Paper of the day</span><br><span class="line">Authors:</span><br><span class="line"></span><br><span class="line">Guilherme Penedo</span><br><span class="line">,</span><br><span class="line"></span><br><span class="line">Hynek Kydlíček</span><br><span class="line">,</span><br><span class="line"></span><br><span class="line">Loubna Ben allal</span><br><span class="line">,</span><br><span class="line"></span><br><span class="line">Anton Lozhkov</span><br><span class="line">,</span><br><span class="line"></span><br><span class="line">Margaret Mitchell</span><br><span class="line">,</span><br><span class="line"></span><br><span class="line">Colin Raffel</span><br><span class="line">,</span><br><span class="line"></span><br><span class="line">Leandro Von Werra</span><br><span class="line">,</span><br><span class="line"></span><br><span class="line">Thomas Wolf</span><br><span class="line">Abstract</span><br><span class="line">The performance of a large language model (LLM) depends heavily on the quality and size of its pretraining dataset. However, the pretraining datasets for state-of-the-art open LLMs like Llama 3 and Mixtral are not publicly available and very little is known about how they were created. In this work, we introduce FineWeb, a 15-trillion token dataset derived from 96 Common Crawl snapshots that produces better-performing LLMs than other open pretraining datasets. To advance the understanding of how best to curate high-quality pretraining datasets, we carefully document and ablate all of the design choices used in FineWeb, including in-depth investigations of deduplication and filtering strategies. In addition, we introduce FineWeb-Edu, a 1.3-trillion token collection of educational text filtered from FineWeb. LLMs pretrained on FineWeb-Edu exhibit dramatically better performance on knowledge- and reasoning-intensive benchmarks like MMLU and ARC. Along with our datasets, we publicly release our data curation codebase and all of the models trained during our ablation experiments.</span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">https://github.com/infiniflow/ragflow</span><br><span class="line">💡 What is RAGFlow?</span><br><span class="line">RAGFlow is an open-source RAG (Retrieval-Augmented Generation) engine based on deep document understanding. It offers a streamlined RAG workflow for businesses of any scale, combining LLM (Large Language Models) to provide truthful question-answering capabilities, backed by well-founded citations from various complex formatted data.</span><br><span class="line"></span><br><span class="line">🌟 Key Features</span><br><span class="line">🍭 &quot;Quality in, quality out&quot;</span><br><span class="line">Deep document understanding-based knowledge extraction from unstructured data with complicated formats.</span><br><span class="line">Finds &quot;needle in a data haystack&quot; of literally unlimited tokens.</span><br><span class="line">🍱 Template-based chunking</span><br><span class="line">Intelligent and explainable.</span><br><span class="line">Plenty of template options to choose from.</span><br><span class="line">🌱 Grounded citations with reduced hallucinations</span><br><span class="line">Visualization of text chunking to allow human intervention.</span><br><span class="line">Quick view of the key references and traceable citations to support grounded answers.</span><br><span class="line">🍔 Compatibility with heterogeneous data sources</span><br><span class="line">Supports Word, slides, excel, txt, images, scanned copies, structured data, web pages, and more.</span><br><span class="line">🛀 Automated and effortless RAG workflow</span><br><span class="line">Streamlined RAG orchestration catered to both personal and large businesses.</span><br><span class="line">Configurable LLMs as well as embedding models.</span><br><span class="line">Multiple recall paired with fused re-ranking.</span><br><span class="line">Intuitive APIs for seamless integration with business.</span><br><span class="line"></span><br></pre></td></tr></table></figure>

</details>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2024-06-28</span><i class="fa fa-tag"></i><a class="tag" href="/tags/AI-NEWS/" title="AI_NEWS">AI_NEWS </a></div></div></div></div><div class="share"><div class="evernote"><a class="fa fa-bookmark" href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank"></a></div><div class="twitter"><a class="fa fa-twitter" target="_blank" rel="noopener" href="http://twitter.com/home?status=,https://dongyoungkim2.github.io/2024/06/28/2024-6-28-AI-NEWS/,TECH BLOG  by Dongyoung Kim   Ph.D.,2024년 6월 28일 AI 소식,;"></a></div></div><div class="pagination"><ul class="clearfix"><li class="next pagbuttons"><a class="btn" role="navigation" href="/2024/06/25/2024-6-25-AI-NEWS/" title="2024년 6월 25일 AI 소식">Next</a></li></ul></div></div></div></div></div><script src="/js/jquery.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script></body></html>