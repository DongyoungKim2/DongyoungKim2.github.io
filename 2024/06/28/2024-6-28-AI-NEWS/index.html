<!DOCTYPE html><html lang="ko-KR"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author"><title>2024ë…„ 6ì›” 28ì¼ AI ì†Œì‹ Â· TECH BLOG  by Dongyoung Kim   Ph.D.</title><meta name="description" content="Summaryì˜¤ëŠ˜ì˜ AI ì†Œì‹ì—ì„œëŠ” Google Researchì˜ ìƒˆë¡œìš´ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì¸ Gemma 2 ì¶œì‹œ, Metaì˜ Meta LLM Compiler ë°œí‘œ, OpenAIì™€ TIMEì˜ ì „ëµì  ì½˜í…ì¸  íŒŒíŠ¸ë„ˆì‹­, OpenAIì˜ Voice Mode ì—…ë°ì´íŠ¸, Anthro"><meta name="keywords"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><!-- Google tag (gtag.js)--><script async src="https://www.googletagmanager.com/gtag/js?id=G-Y36E4JYRDG"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-Y36E4JYRDG');</script><meta name="generator" content="Hexo 7.2.0"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:157px;"><h3 title=""><a href="/">TECH BLOG  by Dongyoung Kim   Ph.D.</a></h3></div></div><ul class="social-links"></ul><div class="footer"><a target="_blank" href="/"></a><div class="by_farbox"><a href="https://dykim.dev/" target="_blank">Â© Dongyoung Kim, Ph.D. </a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">Home</a></li><li><a href="/about">Curriculum Vitae</a></li><li><a href="/archives">Archive</a></li></div><div class="information"><div class="back_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"> </a></li></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>2024ë…„ 6ì›” 28ì¼ AI ì†Œì‹</a></h3></div><div class="post-content"><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>ì˜¤ëŠ˜ì˜ AI ì†Œì‹ì—ì„œëŠ” Google Researchì˜ ìƒˆë¡œìš´ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì¸ Gemma 2 ì¶œì‹œ, Metaì˜ Meta LLM Compiler ë°œí‘œ, OpenAIì™€ TIMEì˜ ì „ëµì  ì½˜í…ì¸  íŒŒíŠ¸ë„ˆì‹­, OpenAIì˜ Voice Mode ì—…ë°ì´íŠ¸, Anthropicì˜ Claude í”„ë¡œì íŠ¸ ê¸°ëŠ¥ ë„ì…, Hugging Faceì˜ ìƒˆë¡œìš´ Open LLM Leaderboard, FineWeb ë°ì´í„°ì…‹ ì†Œê°œ, ê·¸ë¦¬ê³  RAGFlowì˜ ì˜¤í”ˆ ì†ŒìŠ¤ RAG ì—”ì§„ ì¶œì‹œ ì†Œì‹ì„ ë‹¤ë£¹ë‹ˆë‹¤.</p>
<h2 id="Google-Gemma-2-ì¶œì‹œ"><a href="#Google-Gemma-2-ì¶œì‹œ" class="headerlink" title="Google, Gemma 2 ì¶œì‹œ"></a>Google, Gemma 2 ì¶œì‹œ</h2><h3 id="êµ¬ê¸€-Gemma-2-ì¶œì‹œ"><a href="#êµ¬ê¸€-Gemma-2-ì¶œì‹œ" class="headerlink" title="êµ¬ê¸€, Gemma 2 ì¶œì‹œ"></a>êµ¬ê¸€, Gemma 2 ì¶œì‹œ</h3><p><a target="_blank" rel="noopener" href="https://huggingface.co/collections/google/gemma-2-release-667d6600fd5220e7b967f315">ë§í¬</a>, 2024ë…„ 6ì›” 28ì¼,<br>Google Research</p>
<ul>
<li>Gemma 2ëŠ” 9B ë° 27B í¬ê¸°ë¡œ ì¶œì‹œ</li>
<li>27B ëª¨ë¸ì€ Meta Llama 3 70Bì™€ ì„±ëŠ¥ì´ ë¹„ìŠ·</li>
<li>13ì¡° í† í°ìœ¼ë¡œ í›ˆë ¨ëœ 27B ëª¨ë¸ê³¼ 8ì¡° í† í°ìœ¼ë¡œ í›ˆë ¨ëœ 9B ëª¨ë¸</li>
<li>ìƒì—…ì  ì‚¬ìš© ê°€ëŠ¥</li>
<li>Hugging Faceì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•˜ë©° Google Cloudë¡œì˜ ì›í´ë¦­ ë°°í¬ ì§€ì›</li>
</ul>
<h2 id="Meta-Meta-LLM-Compiler-ë°œí‘œ"><a href="#Meta-Meta-LLM-Compiler-ë°œí‘œ" class="headerlink" title="Meta, Meta LLM Compiler ë°œí‘œ"></a>Meta, Meta LLM Compiler ë°œí‘œ</h2><h3 id="ë©”íƒ€-Meta-LLM-Compiler-ë°œí‘œ"><a href="#ë©”íƒ€-Meta-LLM-Compiler-ë°œí‘œ" class="headerlink" title="ë©”íƒ€, Meta LLM Compiler ë°œí‘œ"></a>ë©”íƒ€, Meta LLM Compiler ë°œí‘œ</h3><p><a target="_blank" rel="noopener" href="https://huggingface.co/collections/facebook/llm-compiler-667c5b05557fe99a9edd25cb">ë§í¬</a>, 2024ë…„ 6ì›” 28ì¼,<br>Meta</p>
<ul>
<li>Meta LLM CompilerëŠ” ì½”ë“œ ìµœì í™” ë° ì»´íŒŒì¼ëŸ¬ ê¸°ëŠ¥ì„ ê°–ì¶˜ ëª¨ë¸</li>
<li>GPT-4ë¥¼ ëŠ¥ê°€í•˜ëŠ” ì½”ë“œ í¬ê¸° ê°œì„  ë° ë””ìŠ¤ì–´ì…ˆë¸”ë¦¬ ì„±ëŠ¥</li>
<li>ìƒì—…ì  ì‚¬ìš© í—ˆê°€</li>
<li>CodeLLaMa ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¶•</li>
</ul>
<h2 id="OpenAI-TIMEê³¼-ì „ëµì -ì½˜í…ì¸ -íŒŒíŠ¸ë„ˆì‹­-ì²´ê²°"><a href="#OpenAI-TIMEê³¼-ì „ëµì -ì½˜í…ì¸ -íŒŒíŠ¸ë„ˆì‹­-ì²´ê²°" class="headerlink" title="OpenAI, TIMEê³¼ ì „ëµì  ì½˜í…ì¸  íŒŒíŠ¸ë„ˆì‹­ ì²´ê²°"></a>OpenAI, TIMEê³¼ ì „ëµì  ì½˜í…ì¸  íŒŒíŠ¸ë„ˆì‹­ ì²´ê²°</h2><h3 id="ì˜¤í”ˆAI-TIMEê³¼-ì „ëµì -ì½˜í…ì¸ -íŒŒíŠ¸ë„ˆì‹­-ì²´ê²°"><a href="#ì˜¤í”ˆAI-TIMEê³¼-ì „ëµì -ì½˜í…ì¸ -íŒŒíŠ¸ë„ˆì‹­-ì²´ê²°" class="headerlink" title="ì˜¤í”ˆAI, TIMEê³¼ ì „ëµì  ì½˜í…ì¸  íŒŒíŠ¸ë„ˆì‹­ ì²´ê²°"></a>ì˜¤í”ˆAI, TIMEê³¼ ì „ëµì  ì½˜í…ì¸  íŒŒíŠ¸ë„ˆì‹­ ì²´ê²°</h3><p><a target="_blank" rel="noopener" href="https://openai.com/index/strategic-content-partnership-with-time/">ë§í¬</a>, 2024ë…„ 6ì›” 27ì¼,<br>OpenAI</p>
<ul>
<li>TIMEì˜ 101ë…„ ê°„ì˜ ì•„ì¹´ì´ë¸Œ ì½˜í…ì¸ ì— ì ‘ê·¼ ê°€ëŠ¥</li>
<li>OpenAIì˜ ì œí’ˆì—ì„œ TIME ì½˜í…ì¸ ë¥¼ í™œìš©í•˜ì—¬ ì‚¬ìš©ì ë¬¸ì˜ì— ì‘ë‹µ</li>
<li>TIMEì˜ ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´ ì œê³µ í™•ëŒ€ë¥¼ ëª©í‘œë¡œ í•¨</li>
<li>OpenAI ê¸°ìˆ ì„ í™œìš©í•´ ìƒˆë¡œìš´ ì œí’ˆ ê°œë°œ ê°€ëŠ¥</li>
</ul>
<h2 id="OpenAI-Voice-Mode-ì—…ë°ì´íŠ¸"><a href="#OpenAI-Voice-Mode-ì—…ë°ì´íŠ¸" class="headerlink" title="OpenAI, Voice Mode ì—…ë°ì´íŠ¸"></a>OpenAI, Voice Mode ì—…ë°ì´íŠ¸</h2><h3 id="ì˜¤í”ˆAI-Voice-Mode-ì—…ë°ì´íŠ¸"><a href="#ì˜¤í”ˆAI-Voice-Mode-ì—…ë°ì´íŠ¸" class="headerlink" title="ì˜¤í”ˆAI, Voice Mode ì—…ë°ì´íŠ¸"></a>ì˜¤í”ˆAI, Voice Mode ì—…ë°ì´íŠ¸</h3><p>2024ë…„ 6ì›” 26ì¼,<br>OpenAI</p>
<ul>
<li>ChatGPTì˜ ê³ ê¸‰ ìŒì„± ëª¨ë“œ ì—…ë°ì´íŠ¸ ì—°ê¸°</li>
<li>ëª¨ë¸ì˜ ê°ì • ë° ë¹„ì–¸ì–´ì  ì‹ í˜¸ ì¸ì‹ ëŠ¥ë ¥ í–¥ìƒ ì‘ì—… ì¤‘</li>
<li>ì‚¬ìš©ì ê²½í—˜ ê°œì„  ë° ì¸í”„ë¼ í™•ì¥ ì¤€ë¹„ ì¤‘</li>
<li>ì•ŒíŒŒ í…ŒìŠ¤íŠ¸ë¥¼ ì†Œìˆ˜ ì‚¬ìš©ì ê·¸ë£¹ê³¼ ì‹œì‘í•˜ì—¬ í”¼ë“œë°± ìˆ˜ì§‘ ì˜ˆì •</li>
</ul>
<h2 id="Anthropic-Claude-í”„ë¡œì íŠ¸-ê¸°ëŠ¥-ë„ì…"><a href="#Anthropic-Claude-í”„ë¡œì íŠ¸-ê¸°ëŠ¥-ë„ì…" class="headerlink" title="Anthropic, Claude í”„ë¡œì íŠ¸ ê¸°ëŠ¥ ë„ì…"></a>Anthropic, Claude í”„ë¡œì íŠ¸ ê¸°ëŠ¥ ë„ì…</h2><h3 id="ì•¤íŠ¸ë¡œí”½-Claude-í”„ë¡œì íŠ¸-ê¸°ëŠ¥-ë„ì…"><a href="#ì•¤íŠ¸ë¡œí”½-Claude-í”„ë¡œì íŠ¸-ê¸°ëŠ¥-ë„ì…" class="headerlink" title="ì•¤íŠ¸ë¡œí”½, Claude í”„ë¡œì íŠ¸ ê¸°ëŠ¥ ë„ì…"></a>ì•¤íŠ¸ë¡œí”½, Claude í”„ë¡œì íŠ¸ ê¸°ëŠ¥ ë„ì…</h3><p><a target="_blank" rel="noopener" href="https://www.anthropic.com/news/projects">ë§í¬</a>, 2024ë…„ 6ì›” 26ì¼,<br>Anthropic</p>
<ul>
<li>Claude.ai Pro ë° Team ì‚¬ìš©ìëŠ” ì´ì œ í”„ë¡œì íŠ¸ë¡œ ì±„íŒ…ì„ êµ¬ì„± ê°€ëŠ¥</li>
<li>ê° í”„ë¡œì íŠ¸ëŠ” ìµœëŒ€ 20ë§Œ ë‹¨ì–´ì˜ ë¬¸ë§¥ ì°½ì„ ì œê³µ</li>
<li>ì‚¬ìš©ìëŠ” ë§ì¶¤í˜• ì§€ì¹¨ì„ ì •ì˜í•˜ì—¬ Claudeì˜ ì‘ë‹µì„ ì¡°ì • ê°€ëŠ¥</li>
<li>ê³µìœ ëœ í”„ë¡œì íŠ¸ í™œë™ í”¼ë“œë¥¼ í†µí•´ íŒ€ì› ê°„ í˜‘ë ¥ ê°•í™”</li>
</ul>
<h2 id="Hugging-Face-ìƒˆë¡œìš´-Open-LLM-Leaderboard-ì¶œì‹œ"><a href="#Hugging-Face-ìƒˆë¡œìš´-Open-LLM-Leaderboard-ì¶œì‹œ" class="headerlink" title="Hugging Face, ìƒˆë¡œìš´ Open LLM Leaderboard ì¶œì‹œ"></a>Hugging Face, ìƒˆë¡œìš´ Open LLM Leaderboard ì¶œì‹œ</h2><h3 id="í—ˆê¹…í˜ì´ìŠ¤-ìƒˆë¡œìš´-Open-LLM-Leaderboard-ì¶œì‹œ"><a href="#í—ˆê¹…í˜ì´ìŠ¤-ìƒˆë¡œìš´-Open-LLM-Leaderboard-ì¶œì‹œ" class="headerlink" title="í—ˆê¹…í˜ì´ìŠ¤, ìƒˆë¡œìš´ Open LLM Leaderboard ì¶œì‹œ"></a>í—ˆê¹…í˜ì´ìŠ¤, ìƒˆë¡œìš´ Open LLM Leaderboard ì¶œì‹œ</h3><p><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard">ë§í¬</a>, 2024ë…„ 6ì›” 26ì¼,<br>Hugging Face</p>
<ul>
<li>MMLU-Pro, GPQA, MuSR, MATH, IFEval ë° BBH ë“±ì˜ ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ ì¶”ê°€</li>
<li>í–¥ìƒëœ ìˆœìœ„ ì‹œìŠ¤í…œ ë° ì»¤ë®¤ë‹ˆí‹° íˆ¬í‘œ ì‹œìŠ¤í…œ ë„ì…</li>
<li>Qwen2 72B Instruct ëª¨ë¸ì´ Meta Llama 3 70B Instructë¥¼ ëŠ¥ê°€</li>
</ul>
<h2 id="FineWeb-ë°ì´í„°ì…‹-ë°œí‘œ"><a href="#FineWeb-ë°ì´í„°ì…‹-ë°œí‘œ" class="headerlink" title="FineWeb ë°ì´í„°ì…‹ ë°œí‘œ"></a>FineWeb ë°ì´í„°ì…‹ ë°œí‘œ</h2><h3 id="FineWeb-ë°ì´í„°ì…‹-ë°œí‘œ-1"><a href="#FineWeb-ë°ì´í„°ì…‹-ë°œí‘œ-1" class="headerlink" title="FineWeb ë°ì´í„°ì…‹ ë°œí‘œ"></a>FineWeb ë°ì´í„°ì…‹ ë°œí‘œ</h3><p><a target="_blank" rel="noopener" href="https://huggingface.co/papers/2406.17557">ë§í¬</a>, 2024ë…„ 6ì›” 25ì¼,<br>Hugging Face</p>
<ul>
<li>96ê°œì˜ Common Crawl ìŠ¤ëƒ…ìƒ·ì—ì„œ ì¶”ì¶œëœ 15ì¡° í† í° ë°ì´í„°ì…‹</li>
<li>ê³ í’ˆì§ˆì˜ ì‚¬ì „ í›ˆë ¨ ë°ì´í„°ì…‹ìœ¼ë¡œ LLM ì„±ëŠ¥ í–¥ìƒ</li>
<li>FineWeb-Edu: êµìœ¡ í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±ëœ 1.3ì¡° í† í° ì»¬ë ‰ì…˜</li>
<li>ë°ì´í„° íë ˆì´ì…˜ ì½”ë“œë² ì´ìŠ¤ì™€ ëª¨ë¸ ê³µê°œ</li>
</ul>
<h2 id="RAGFlowì˜-ì˜¤í”ˆ-ì†ŒìŠ¤-RAG-ì—”ì§„-ì¶œì‹œ"><a href="#RAGFlowì˜-ì˜¤í”ˆ-ì†ŒìŠ¤-RAG-ì—”ì§„-ì¶œì‹œ" class="headerlink" title="RAGFlowì˜ ì˜¤í”ˆ ì†ŒìŠ¤ RAG ì—”ì§„ ì¶œì‹œ"></a>RAGFlowì˜ ì˜¤í”ˆ ì†ŒìŠ¤ RAG ì—”ì§„ ì¶œì‹œ</h2><h3 id="RAGFlowì˜-ì˜¤í”ˆ-ì†ŒìŠ¤-RAG-ì—”ì§„-ì¶œì‹œ-1"><a href="#RAGFlowì˜-ì˜¤í”ˆ-ì†ŒìŠ¤-RAG-ì—”ì§„-ì¶œì‹œ-1" class="headerlink" title="RAGFlowì˜ ì˜¤í”ˆ ì†ŒìŠ¤ RAG ì—”ì§„ ì¶œì‹œ"></a>RAGFlowì˜ ì˜¤í”ˆ ì†ŒìŠ¤ RAG ì—”ì§„ ì¶œì‹œ</h3><p><a target="_blank" rel="noopener" href="https://github.com/infiniflow/ragflow">ë§í¬</a>, 2024ë…„ 6ì›” 26ì¼,<br>RAGFlow</p>
<ul>
<li>ë³µì¡í•œ í˜•ì‹ì˜ ë°ì´í„°ë¥¼ ì´í•´í•˜ëŠ” ëŠ¥ë ¥ì„ ê°–ì¶˜ ì§€ì‹ ì¶”ì¶œ ê¸°ëŠ¥</li>
<li>ë‹¤ì–‘í•œ í…œí”Œë¦¿ì„ ì œê³µí•˜ëŠ” í…œí”Œë¦¿ ê¸°ë°˜ ì²­í‚¹</li>
<li>ì¸ìš© ê·¼ê±°ê°€ ëšœë ·í•œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì‘ë‹µ ì œê³µ</li>
<li>ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì™€ í˜¸í™˜ ê°€ëŠ¥</li>
<li>ì§ê´€ì ì¸ APIë¥¼ í†µí•´ ë¹„ì¦ˆë‹ˆìŠ¤ì— ì›í™œí•˜ê²Œ í†µí•© ê°€ëŠ¥</li>
</ul>
<details>
  <summary>Sources</summary>

<p>This GPT assists users by creating a detailed daily newspaper in Korean based on provided links. It follows these steps: read the content, summarize each content with detailed points, and write a report. The report format is:</p>
<h1 id="todayâ€™s-date-in-ë…„-ì›”-ì¼-AI-ì†Œì‹"><a href="#todayâ€™s-date-in-ë…„-ì›”-ì¼-AI-ì†Œì‹" class="headerlink" title="(todayâ€™s date in ë…„ ì›” ì¼) AI ì†Œì‹,"></a>(todayâ€™s date in ë…„ ì›” ì¼) AI ì†Œì‹,</h1><h2 id="Summary-1"><a href="#Summary-1" class="headerlink" title="Summary"></a>Summary</h2><p>(overall short summary, make summary with good details. for Summary section, explain the details starting with company name, e.g. OpenAIì—ì„œëŠ” ~~~ë¥¼ ë°œí‘œí•˜ì˜€ìŠµë‹ˆë‹¤.)</p>
<h2 id="Title"><a href="#Title" class="headerlink" title="Title,"></a>Title,</h2><h3 id="í•œê¸€ì œëª©"><a href="#í•œê¸€ì œëª©" class="headerlink" title="í•œê¸€ì œëª©"></a>í•œê¸€ì œëª©</h3><p><a href="link">ë§í¬</a>, date,<br>company name</p>
<ul>
<li>detailed summary1, (ê°œì¡°ì‹ ë¬¸ì²´ ì‚¬ìš©)</li>
<li>detailed summary2, (ê°œì¡°ì‹ ë¬¸ì²´ ì‚¬ìš©)<br>â€¦</li>
<li>detailed summary N, (ê°œì¡°ì‹ ë¬¸ì²´ ì‚¬ìš©)</li>
</ul>
<h2 id="Title-1"><a href="#Title-1" class="headerlink" title="Title,"></a>Title,</h2><h3 id="í•œê¸€ì œëª©-1"><a href="#í•œê¸€ì œëª©-1" class="headerlink" title="í•œê¸€ì œëª©"></a>í•œê¸€ì œëª©</h3><p><a href="link">ë§í¬</a>, date,<br>company name</p>
<ul>
<li>detailed summary1, (ê°œì¡°ì‹ ë¬¸ì²´ ì‚¬ìš©)</li>
<li>detailed summary2, (ê°œì¡°ì‹ ë¬¸ì²´ ì‚¬ìš©)<br>â€¦</li>
<li>detailed summary N, (ê°œì¡°ì‹ ë¬¸ì²´ ì‚¬ìš©)<br>â€¦</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br></pre></td><td class="code"><pre><span class="line">###</span><br><span class="line">https://huggingface.co/collections/google/gemma-2-release-667d6600fd5220e7b967f315</span><br><span class="line">June 28, 2024</span><br><span class="line">Google Research</span><br><span class="line">Gemma 2 released! Google just released the next iteration of its open LLM! Gemma 2 comes in two sizes, 9B &amp; 27B, trained on 13T tokens. Gemma 2 27B approaches Meta Llama 3 70B performance! First Chatbot Arena evals place Gemma2 27B around Anthropic Claude 3 Sonnet, Llama 3 70B, and OpenAI GPT-4. ğŸ¤¯</span><br><span class="line">What&#x27;s new with Gemma 2:</span><br><span class="line">ğŸ§® 9B &amp; 27B Instruction and base version with 8192 context window</span><br><span class="line">ğŸ”  Trained on 13T tokens (27B) and 8T tokens (9B)</span><br><span class="line">ğŸ†• Sliding window attention, logit soft-capping and Grouped-Query Attention (GQA)</span><br><span class="line">ğŸ¥‡ 9B scores 71.3 MMLU; 52.8 AGIEval; 40.2 HumanEval</span><br><span class="line">ğŸ† 27B scores 75.2 MMLU; 55.1 AGIEval; 51.8 HumanEval</span><br><span class="line">âœ… Commercial use allowed</span><br><span class="line">ğŸ§¬ Used SFT, Distillation, RLHF &amp; Model Merging.</span><br><span class="line">ğŸ§  Trained on Google TPUv5e</span><br><span class="line">ğŸ¤— Available on Hugging Face</span><br><span class="line">ğŸ”œ 1-click deployment to Google Cloud from Hugging Face</span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">https://huggingface.co/collections/facebook/llm-compiler-667c5b05557fe99a9edd25cb</span><br><span class="line">June 28, 2024</span><br><span class="line">META</span><br><span class="line">Today weâ€™re releasing Meta LLM Compiler, a family of models built on Meta Code Llama with additional code optimization and compiler capabilities. The models achieve state-of-the-art results on optimization of code size and disassembly tasks.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">LLM Compiler can emulate the compiler, predict optimal passes for code size, and disassemble code. It can be fine-tuned for new optimizations and compiler tasks. This work shows that AI is learning to optimize code and can assist compiler experts in identifying opportunities to apply optimizations. We believe this work could have an impact ranging from use in optimization for individual developer environments to inclusion in a compiler such as LLVM.</span><br><span class="line">Weâ€™re releasing LLM Compiler 7B &amp; 13B models under a permissive license for both research and commercial use in the hopes of making it easier for developers and researchers alike to leverage this in their work and carry forward new research in this highly impactful space.</span><br><span class="line"></span><br><span class="line">WAIT, it&#x27;s not over; Meta just dropped the LLM Compiler! ğŸ§‘â€ğŸ’»</span><br><span class="line">&gt; Beats GPT-4 on code size improvement and disassembly</span><br><span class="line">&gt; Achieves 77% of the optimising potential of an autotuning search and 45% disassembly round trip ğŸ”¥</span><br><span class="line">&gt; Built on top of CodeLLaMa with improved code optimisation and compiler reasoning.</span><br><span class="line">&gt; Allows commercial use</span><br><span class="line">Two model types:</span><br><span class="line">&gt; LLM Compiler: the foundational models, pre-trained on over 500B tokens of LLVM-IR, x86_84, ARM, and CUDA assembly codes and trained to predict the effect of LLVM optimisations</span><br><span class="line">&gt;LLM Compiler FTD, which is further fine-tuned to predict the best optimisations for code in LLVM assembly to reduce code size and disassemble assembly code to LLVM-IR</span><br><span class="line">&gt; Perfectly emulating the compiler 20% of the time âš¡</span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">https://openai.com/index/strategic-content-partnership-with-time/</span><br><span class="line">June 27, 2024</span><br><span class="line">OpenAI</span><br><span class="line">Strategic Content Partnership with TIME</span><br><span class="line">New access to current and historic content from TIME&#x27;s extensive archives from the last 101 years to enhance OpenAI products and display in response to user inquiries.</span><br><span class="line"></span><br><span class="line">Time &gt; Hero &gt; Media &gt; Asset</span><br><span class="line">Today, TIME and OpenAI announced a multi-year content deal and strategic partnership to bring TIME&#x27;s trusted journalism to OpenAIâ€™s products, including ChatGPT.</span><br><span class="line"></span><br><span class="line">Through this collaboration, OpenAI will gain access to current and historic content from TIME&#x27;s extensive archives from the last 101 years to enhance its products and display in response to user inquiriesâ€”featuring a citation and link back to the original source on Time.com. The new partnership furthers TIMEâ€™s commitment to expanding global access to accurate and trusted information.</span><br><span class="line"></span><br><span class="line">&quot;Throughout our 101-year history, TIME has embraced innovation to ensure that the delivery of our trusted journalism evolves alongside technology,&quot; said TIME Chief Operating Officer Mark Howard.  &quot;This partnership with OpenAI advances our mission to expand access to trusted information globally as we continue to embrace innovative new ways of bringing TIMEâ€™s journalism to audiences globally.â€</span><br><span class="line"></span><br><span class="line">â€œWeâ€™re partnering with TIME to make it easier for people to access news content through our AI tools, and to support reputable journalism by providing proper attribution to original sources,â€ said Brad Lightcap, Chief Operating Officer of OpenAI.</span><br><span class="line"></span><br><span class="line">The partnership will also enable TIME to gain access to OpenAI&#x27;s technology to develop new products for its audiences, along with the opportunity to provide vital feedback and share practical applications to refine and enhance the delivery of journalism in ChatGPT and other OpenAI products and shape the future of news experiences.</span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">OpenAI</span><br><span class="line">June 26, 2024</span><br><span class="line">We&#x27;re sharing an update on the advanced Voice Mode we demoed during our Spring Update, which we remain very excited about:</span><br><span class="line">We had planned to start rolling this out in alpha to a small group of ChatGPT Plus users in late June, but need one more month to reach our bar to launch. For example, weâ€™re improving the modelâ€™s ability to detect and refuse certain content. Weâ€™re also working on improving the user experience and preparing our infrastructure to scale to millions while maintaining real-time responses.</span><br><span class="line">As part of our iterative deployment strategy, we&#x27;ll start the alpha with a small group of users to gather feedback and expand based on what we learn. We are planning for all Plus users to have access in the fall. Exact timelines depend on meeting our high safety and reliability bar. We are also working on rolling out the new video and screen sharing capabilities we demoed separately, and will keep you posted on that timeline.</span><br><span class="line">ChatGPTâ€™s advanced Voice Mode can understand and respond with emotions and non-verbal cues, moving us closer to real-time, natural conversations with AI. Our mission is to bring these new experiences to you thoughtfully.</span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">https://www.anthropic.com/news/projects</span><br><span class="line">Collaborate with Claude on Projects</span><br><span class="line">2024ë…„ 6ì›” 26ì¼</span><br><span class="line">Anthorphic</span><br><span class="line">â—</span><br><span class="line">3 min read</span><br><span class="line">Illustration of individuals collaborating around Claude logo</span><br><span class="line">Our vision for Claude has always been to create AI systems that work alongside people and meaningfully enhance their workflows. As a step in this direction, Claude.ai Pro and Team users can now organize their chats into Projects, bringing together curated sets of knowledge and chat activity in one placeâ€”with the ability to make their best chats with Claude viewable by teammates. With this new functionality, Claude can enable idea generation, more strategic decision-making, and exceptional results.</span><br><span class="line"></span><br><span class="line">Projects are available on Claude.ai for all Pro and Team customers, and can be powered by Claude 3.5 Sonnet, our latest release which outperforms its peers on a wide variety of benchmarks. Each project includes a 200K context window, the equivalent of a 500-page book, so users can add all of the relevant documents, code, and insights to enhance Claudeâ€™s effectiveness.</span><br><span class="line"></span><br><span class="line">Avoid the cold start problem</span><br><span class="line">Projects allow you to ground Claudeâ€™s outputs in your internal knowledgeâ€”be it style guides, codebases, interview transcripts, or past work. This added context enables Claude to provide expert assistance across tasks, from writing emails like your marketing team to writing SQL queries like a data analyst.</span><br><span class="line"></span><br><span class="line">App screen showing a user uploading docs to Claude.ai</span><br><span class="line">In addition, you can define custom instructions for each Project to further tailor Claudeâ€™s responses, including instructing Claude to use a more formal tone or answer questions from the perspective of a specific role or industry. With Projects, you can get started much faster and extend your skills further for any task.</span><br><span class="line"></span><br><span class="line">App screen showing custom instructions</span><br><span class="line">Create side-by-side with Claude</span><br><span class="line">Artifacts help you better work with Claude by helping you see, edit, and build with Claude. Simply ask Claude to generate content like code snippets, text documents, graphics, diagrams, or website designs, and Artifacts appear in a dedicated window alongside your conversation.</span><br><span class="line"></span><br><span class="line">Artifacts especially enhance Claudeâ€™s coding capabilities for developers, offering a larger code window and live previews for frontends that streamline reviews. Join the feature preview for Artifacts in Claude.ai via the account menu on the left-side panel.</span><br><span class="line"></span><br><span class="line">App screen that shows the Artifacts panel alongside the user chat</span><br><span class="line">Spark inspiration through sharing</span><br><span class="line">Claude Team users can also share snapshots of their best conversations with Claude into your teamâ€™s shared project activity feed. Activity feeds help each teammate get inspired around different ways to work with Claude, and helps the entire team uplevel their skills working with AI.</span><br><span class="line"></span><br><span class="line">App screen showing shared chats within a Project</span><br><span class="line">Sharing work products that were co-created with Claude can improve innovation in areas like product development and research, where bringing together organizational knowledge from across the company can produce higher-quality outputs.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Customer spotlight: North Highland</span><br><span class="line">At North Highland, a leading change and transformation consultancy, hundreds of employees across consulting, business development, and marketing teams use Claude to work better. From writing proposals to analyzing complex documents like 10-Ks, teams use Claude to enhance and scale their expert services.</span><br><span class="line"></span><br><span class="line">The Claude Team plan is transforming our way of working at North Highland. Claude is a truly exceptional writer that has helped our team complete content creation and analysis tasks up to 5x faster than beforeâ€”turning what was once two weeks of writing and research into minutes of work. With Claude, weâ€™re future-proofing our workforce, finding more excitement in daily challenges, and leaping into the future of AI-assisted collaboration and creativity.</span><br><span class="line">Luka Anic, Senior Director of Technical AI Program and Product Manager at North Highland</span><br><span class="line"></span><br><span class="line">The future of work with Claude</span><br><span class="line">These latest features around shared knowledge and collaboration integrate Claude into your existing team processes, enabling you to save time and elevate your work. By harnessing Claudeâ€™s accuracy and advanced coding and writing capabilities, Projects can amplify your teamâ€™s potential. Additionally, as part of our commitment to user privacy, any data or chats shared within Projects will not be used to train our generative models without a userâ€™s explicit consent.</span><br><span class="line"></span><br><span class="line">In the coming months, weâ€™ll continue making Claude easier to use while expanding the types of project knowledge you can bring to Claude via native integrations with popular applications and tools. Weâ€™re excited to see how your team works with Claude.</span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard</span><br><span class="line">Open LLM Leaderboard 2 released! Evaluating LLMs is not easy. Finding new ways to compare LLM fairly, transparently, and reproducibly is important! Benchmarks are not perfect, but they give us a first understanding of how well models perform and where their strengths are.</span><br><span class="line">What&#x27;s new?!</span><br><span class="line">ğŸ“ˆ New benchmarks with MMLU-Pro, GPQA, MuSR, MATH, IFEval and BBH.</span><br><span class="line">ğŸ“Š Improved ranking with normalized scores adjusted to baselines</span><br><span class="line">ğŸ† Qwen2 72B Instruct &gt; Meta Llama 3 70B Instruct &gt; Cohere Command R+</span><br><span class="line">âš¡ Faster, simpler Interface with a new Gradio component.</span><br><span class="line">ğŸ› ï¸ Enhanced reproducibility with support for delta weights and chat templates</span><br><span class="line">â­ Introduction of &quot;maintainer&#x27;s highlight&quot; and â€œcommunity voting systemâ€</span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">https://huggingface.co/papers/2406.17557</span><br><span class="line">The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale</span><br><span class="line">Published on Jun 25</span><br><span class="line">Â·</span><br><span class="line">Submitted by</span><br><span class="line">philschmid</span><br><span class="line">on Jun 26</span><br><span class="line">#1 Paper of the day</span><br><span class="line">Authors:</span><br><span class="line"></span><br><span class="line">Guilherme Penedo</span><br><span class="line">,</span><br><span class="line"></span><br><span class="line">Hynek KydlÃ­Äek</span><br><span class="line">,</span><br><span class="line"></span><br><span class="line">Loubna Ben allal</span><br><span class="line">,</span><br><span class="line"></span><br><span class="line">Anton Lozhkov</span><br><span class="line">,</span><br><span class="line"></span><br><span class="line">Margaret Mitchell</span><br><span class="line">,</span><br><span class="line"></span><br><span class="line">Colin Raffel</span><br><span class="line">,</span><br><span class="line"></span><br><span class="line">Leandro Von Werra</span><br><span class="line">,</span><br><span class="line"></span><br><span class="line">Thomas Wolf</span><br><span class="line">Abstract</span><br><span class="line">The performance of a large language model (LLM) depends heavily on the quality and size of its pretraining dataset. However, the pretraining datasets for state-of-the-art open LLMs like Llama 3 and Mixtral are not publicly available and very little is known about how they were created. In this work, we introduce FineWeb, a 15-trillion token dataset derived from 96 Common Crawl snapshots that produces better-performing LLMs than other open pretraining datasets. To advance the understanding of how best to curate high-quality pretraining datasets, we carefully document and ablate all of the design choices used in FineWeb, including in-depth investigations of deduplication and filtering strategies. In addition, we introduce FineWeb-Edu, a 1.3-trillion token collection of educational text filtered from FineWeb. LLMs pretrained on FineWeb-Edu exhibit dramatically better performance on knowledge- and reasoning-intensive benchmarks like MMLU and ARC. Along with our datasets, we publicly release our data curation codebase and all of the models trained during our ablation experiments.</span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">https://github.com/infiniflow/ragflow</span><br><span class="line">ğŸ’¡ What is RAGFlow?</span><br><span class="line">RAGFlow is an open-source RAG (Retrieval-Augmented Generation) engine based on deep document understanding. It offers a streamlined RAG workflow for businesses of any scale, combining LLM (Large Language Models) to provide truthful question-answering capabilities, backed by well-founded citations from various complex formatted data.</span><br><span class="line"></span><br><span class="line">ğŸŒŸ Key Features</span><br><span class="line">ğŸ­ &quot;Quality in, quality out&quot;</span><br><span class="line">Deep document understanding-based knowledge extraction from unstructured data with complicated formats.</span><br><span class="line">Finds &quot;needle in a data haystack&quot; of literally unlimited tokens.</span><br><span class="line">ğŸ± Template-based chunking</span><br><span class="line">Intelligent and explainable.</span><br><span class="line">Plenty of template options to choose from.</span><br><span class="line">ğŸŒ± Grounded citations with reduced hallucinations</span><br><span class="line">Visualization of text chunking to allow human intervention.</span><br><span class="line">Quick view of the key references and traceable citations to support grounded answers.</span><br><span class="line">ğŸ” Compatibility with heterogeneous data sources</span><br><span class="line">Supports Word, slides, excel, txt, images, scanned copies, structured data, web pages, and more.</span><br><span class="line">ğŸ›€ Automated and effortless RAG workflow</span><br><span class="line">Streamlined RAG orchestration catered to both personal and large businesses.</span><br><span class="line">Configurable LLMs as well as embedding models.</span><br><span class="line">Multiple recall paired with fused re-ranking.</span><br><span class="line">Intuitive APIs for seamless integration with business.</span><br><span class="line"></span><br></pre></td></tr></table></figure>

</details>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2024-06-28</span><i class="fa fa-tag"></i><a class="tag" href="/tags/AI-NEWS/" title="AI_NEWS">AI_NEWS </a></div></div></div></div><div class="share"><div class="evernote"><a class="fa fa-bookmark" href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank"></a></div><div class="twitter"><a class="fa fa-twitter" target="_blank" rel="noopener" href="http://twitter.com/home?status=,https://dongyoungkim2.github.io/2024/06/28/2024-6-28-AI-NEWS/,TECH BLOG  by Dongyoung Kim   Ph.D.,2024ë…„ 6ì›” 28ì¼ AI ì†Œì‹,;"></a></div></div><div class="pagination"><ul class="clearfix"><li class="next pagbuttons"><a class="btn" role="navigation" href="/2024/06/25/2024-6-25-AI-NEWS/" title="2024ë…„ 6ì›” 25ì¼ AI ì†Œì‹">Next</a></li></ul></div></div></div></div></div><script src="/js/jquery.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script></body></html>